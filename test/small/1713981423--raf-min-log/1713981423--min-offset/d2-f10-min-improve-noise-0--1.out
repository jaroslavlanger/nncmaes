args = Namespace(dim=2, fun=10, inst=None, crit='mean')
(3_w,6)-aCMA-ES (mu_w=2.0,w_1=63%) in dimension 2 (seed=1, Wed Apr 24 18:59:13 2024)
=== iohexp--d-2--f-10--i-1--b-500__pycma--init-pop-6__(Surrogate(model=Raf(data_noise=0.0), subset=ClosestToEachTestPoint(Mahalanobis, n_max_coef=20), x_tf=ShiftAndScaleByEs, y_tf=MinAdjustedLog), EvaluateUntilKendallThreshold(mean_criterion, tau_threshold=0.85, offset=True), n_min_fn=get_dim)
subset-max-norm=1.306599897541423 | norm-max=12.13941703508117
subset-idx-size=6

NN: 0
epoch: 200 , mse_ 0.006 , loss_anch 0.006 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 1
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 12.101 , loss_anch 12.101 tau-train= 0.87
epoch: 400 , mse_ 1.228 , loss_anch 1.228 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 3
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=0.9999999999999999
tau-archive=0.9999999999999999
eval=1 | not-eval=5 | tau= 0.90 | n_kendall= 7 | std(means)/mean(stds)=  0.36 | std(means)=1.01e+06 | mean(stds)=2.83e+06
delta_f=2.3e+05
tau-population= 0.07 | tau-pop-offset= 0.07 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) 1735 	    def __call__(
1736 	        self, *, model: Model, points: XPop, problem: Problem, archive: Archive
1737 	    ) -> ValuesAndEvaluatedIdx:
1738 	        archive_size = archive.y.shape[0]
1739 	        dim = problem.dimension
1740 	        n_points = points.shape[0]
1741 	        max_model_size = max(n_points, dim * (dim + 3) + 2)
1742 	        model_size = min(archive_size, max_model_size)
1743 	        pred = model(points)
1744 	
1745 	        # TODO: evaluate the max size, and take the subsets later
1746 	        # <https://github.com/CMA-ES/pycma/blob/r3.3.0/cma/fitness_models.py#L296-L297>
1747 	        n_evaluated = int(
1748 	            1
1749 	            + max(
1750 	                n_points * self.min_evals_percent / 100,
1751 	                3 / self.truncation_ratio - model_size,
1752 	            )
1753 	        )
1754 	        try:
1755 	            n_evaluated = min(n_evaluated, problem.evals_left)  # type: ignore[assignment, type-var]
1756 	        except:  # noqa: E722
1757 	            pass
1758 	        if __debug__:
1759 	            if (
1760 	                _n_archive := min(self.n_for_tau(n_points, n_evaluated), model_size)
1761 	                - n_evaluated
1762 	            ) > 0:
1763 	                print(
1764 	                    "tau-archive={}".format(
1765 	                        kendalltau(
1766 	                            archive.y[-_n_archive:], model(archive.x[-_n_archive:]).mean
1767 	                        ).statistic
1768 	                    )
1769 	                )
1770 	                # TODO test Kendall weighted
1771 	
1772 	        eval_order_idx = (
1773 	            self.__criterion(pred).argsort(axis=0).astype(np.uint).squeeze()
1774 	        )
1775 	
1776 	        tau = np.nan
1777 	        n_kendall = None
1778 	        (values := np.empty((n_points, 1))).fill(np.nan)
1779 	        evaluated = ~(not_evaluated := np.isnan(values.squeeze()))
1780 	        while not_evaluated.any():
1781 	            for i in (idx := eval_order_idx[:n_evaluated])[not_evaluated[idx]]:
1782 	                values[i] = (
1783 	                    problem(points[i])
1784 	                    if not problem.final_target_hit
1785 	                    else np.float64(np.nan)
1786 	                )
1787 	            evaluated = ~(not_evaluated := np.isnan(values.squeeze()))
1788 	            model_size = min(archive_size + n_evaluated, max_model_size)
1789 	            n_kendall = min(self.n_for_tau(n_points, n_evaluated), model_size)
1790 	            n_kendall_archive = max(n_kendall - n_evaluated, 0)
1791 	            # <https://github.com/CMA-ES/pycma/blob/r3.3.0/cma/fitness_models.py#L780-L794>
1792 	            tau = (
1793 	                kendalltau(
1794 	                    np.concatenate([archive.y[-n_kendall_archive:], values[evaluated]]),
1795 	                    model(
1796 	                        np.concatenate(
1797 	                            [archive.x[-n_kendall_archive:], points[evaluated]]
1798 	                        )
1799 	                    ).mean,
1800 	                ).statistic
1801 	                if n_kendall >= 2
1802 	                else np.nan
1803 	            )  # noqa: F841
1804 	            if (
1805 	                tau >= self.__tau_thold
1806 	                or problem.all_evals_used
1807 	                or problem.final_target_hit
1808 	            ):
1809 	                pred_mean_not_evaluated = pred.mean[not_evaluated]
1810 	                if self.__offset_non_evaluated and pred_mean_not_evaluated.size > 0:
1811 	                    eval_min = np.nanmin(values[evaluated])
1812 	                    values[not_evaluated] = (
1813 	                        pred_mean_not_evaluated
1814 	                        - pred_mean_not_evaluated.min()
1815 	                        + eval_min
1816 	                        + np.spacing(eval_min)
1817 	                    )
1818 	                else:
1819 	                    values[not_evaluated] = pred_mean_not_evaluated
1820 	                break
1821 	            eval_next = math.ceil(n_evaluated / 2)
1822 	            try:
1823 	                eval_next = min(eval_next, problem.evals_left)  # type: ignore[assignment, type-var]
1824 	            except:  # noqa: E722
1825 	                pass
1826 	            n_evaluated += eval_next
1827 	
1828 	        # Uncomment for diagnostics, comment out for performance
1829 	        std_of_means = pred.mean.std()
1830 	        mean_of_stds = pred.std.mean()
1831 	        if self.__verbose:
1832 	            print(
1833 	                " | ".join(
1834 	                    [
1835 	                        f"eval={evaluated.sum()}",
1836 	                        f"not-eval={not_evaluated.sum()}",
1837 	                        f"{tau=:>5.2f}",
1838 	                        f"{n_kendall=:>2}",
1839 	                        f"std(means)/mean(stds)={std_of_means/mean_of_stds:>6.2f}",
1840 	                        f"std(means)={std_of_means:.2e}",
1841 	                        f"mean(stds)={mean_of_stds:.2e}",
1842 	                    ]
1843 	                )
1844 	            )
1845 	        if __debug__ and self.__debug:
1846 	            if hasattr(problem, "delta_to_optimum"):
1847 	                print(f"delta_f={problem.delta_to_optimum:.1e}")
1848 	            try:
1849 	                _values_true = np.array([PROBLEM_DEBUG(p) for p in points])
1850 	                _tau_pop = kendalltau(_values_true, model(points).mean).statistic
1851 	                _tau_pop_off = kendalltau(_values_true, values).statistic
1852 	                print(f"tau-population={_tau_pop:>5.2f} | tau-pop-offset={_tau_pop_off:>5.2f} | final-target-hit={problem.final_target_hit}")
1853 	                if _tau_pop < 0.25:
1854 	                    breakpoint()
1855 ->	                _preds = model(points)
1856 	            except:  # noqa: E722
1857 	                pass
1858 	        return ValuesAndEvaluatedIdx(values, np.flatnonzero(evaluated).astype(np.uint))
(Pdb) array([ 723885.84059343,  483309.20770035, 3052439.95850061,
       1716778.94645124, 1342900.32809894, 3224585.20827304])
(Pdb) array([[ 723885.84059343],
       [ 483309.20770035],
       [3052439.95850061],
       [1716778.94645124],
       [1342900.32809894],
       [3224585.20827304]])
(Pdb) array([[2767740.06092243],
       [-175131.39680427],
       [ 976412.19919681],
       [2654070.36203637],
       [1223927.09857918],
       [1338029.55624903]])
(Pdb) subset-max-norm=1.22726010053474 | norm-max=12.13941703508117
subset-idx-size=7

NN: 0
epoch: 200 , mse_ 5.018 , loss_anch 5.018 tau-train= 1.00
epoch: 400 , mse_ 1.05 , loss_anch 1.05 tau-train= 1.00
epoch: 600 , mse_ 0.018 , loss_anch 0.018 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 1
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 5.151 , loss_anch 5.151 tau-train= 1.00
epoch: 400 , mse_ 2.779 , loss_anch 2.779 tau-train= 1.00
epoch: 600 , mse_ 1.356 , loss_anch 1.356 tau-train= 1.00
epoch: 800 , mse_ 0.558 , loss_anch 0.558 tau-train= 1.00
epoch: 1000 , mse_ 0.188 , loss_anch 0.188 tau-train= 1.00

NN: 3
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=1.0
tau-archive=0.9999999999999999
eval=1 | not-eval=5 | tau= 0.93 | n_kendall= 8 | std(means)/mean(stds)=  0.23 | std(means)=5.56e+05 | mean(stds)=2.38e+06
delta_f=3.3e+04
tau-population= 0.60 | tau-pop-offset= 0.60 | final-target-hit=False
subset-max-norm=2.891692616349697 | norm-max=12.13941703508117
subset-idx-size=8

NN: 0
epoch: 200 , mse_ 1.929 , loss_anch 1.929 tau-train= 1.00
epoch: 400 , mse_ 0.252 , loss_anch 0.252 tau-train= 1.00
epoch: 600 , mse_ 0.012 , loss_anch 0.012 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 1
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 0.753 , loss_anch 0.753 tau-train= 1.00
epoch: 400 , mse_ 0.014 , loss_anch 0.014 tau-train= 1.00
epoch: 600 , mse_ 11.691 , loss_anch 11.691 tau-train= 0.93
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 3
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=0.9999999999999998
tau-archive=1.0
eval=1 | not-eval=5 | tau= 1.00 | n_kendall= 9 | std(means)/mean(stds)=  0.04 | std(means)=1.37e+06 | mean(stds)=3.06e+07
delta_f=3.3e+04
tau-population= 0.47 | tau-pop-offset= 0.47 | final-target-hit=False
subset-max-norm=3.763196171532137 | norm-max=12.13941703508117
subset-idx-size=9

NN: 0
epoch: 200 , mse_ 2.279 , loss_anch 2.279 tau-train= 0.94
epoch: 400 , mse_ 0.017 , loss_anch 0.017 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 1
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 0.038 , loss_anch 0.038 tau-train= 1.00
epoch: 400 , mse_ 0.001 , loss_anch 0.001 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 3
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 0.107 , loss_anch 0.107 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=1.0
tau-archive=0.9999999999999998
eval=6 | not-eval=0 | tau= 0.11 | n_kendall=12 | std(means)/mean(stds)=  0.00 | std(means)=1.41e+05 | mean(stds)=3.70e+07
delta_f=2.2e+04
tau-population=-0.33 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) array([[  28891.69014528],
       [ 186580.03505708],
       [3983052.75938805],
       [ 324793.066639  ],
       [ 482536.96582281],
       [  21572.68535554]])
(Pdb) Prediction(mean=array([[ 72851.17121803],
       [116829.98913202],
       [ 20422.29507829],
       [ 38963.71152481],
       [437698.01154803],
       [169965.6974071 ]]), std=array([[2.34109778e+06],
       [1.43936800e+06],
       [2.11470288e+08],
       [3.27197257e+06],
       [1.43554840e+06],
       [2.20955641e+06]]))
(Pdb) array([[2.34109778e+06],
       [1.43936800e+06],
       [2.11470288e+08],
       [3.27197257e+06],
       [1.43554840e+06],
       [2.20955641e+06]])
(Pdb) array([[ 72851.17121803],
       [116829.98913202],
       [ 20422.29507829],
       [ 38963.71152481],
       [437698.01154803],
       [169965.6974071 ]])
(Pdb) array([[  28891.69014528],
       [ 186580.03505708],
       [3983052.75938805],
       [ 324793.066639  ],
       [ 482536.96582281],
       [  21572.68535554]])
(Pdb) subset-max-norm=3.8507046568869088 | norm-max=12.13941703508117
subset-idx-size=15

NN: 0
epoch: 200 , mse_ 276.978 , loss_anch 276.978 tau-train= 0.75
epoch: 400 , mse_ 58.667 , loss_anch 58.667 tau-train= 0.93
epoch: 600 , mse_ 11.188 , loss_anch 11.188 tau-train= 0.96
epoch: 800 , mse_ 4.756 , loss_anch 4.756 tau-train= 1.00
epoch: 1000 , mse_ 2.954 , loss_anch 2.954 tau-train= 1.00

NN: 1
epoch: 200 , mse_ 1.1 , loss_anch 1.1 tau-train= 0.96
epoch: 400 , mse_ 0.043 , loss_anch 0.043 tau-train= 0.96
epoch: 600 , mse_ 0.003 , loss_anch 0.003 tau-train= 0.96
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 0.96
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 13.313 , loss_anch 13.313 tau-train= 0.96
epoch: 400 , mse_ 6.355 , loss_anch 6.355 tau-train= 1.00
epoch: 600 , mse_ 2.863 , loss_anch 2.863 tau-train= 1.00
epoch: 800 , mse_ 1.015 , loss_anch 1.015 tau-train= 1.00
epoch: 1000 , mse_ 0.265 , loss_anch 0.265 tau-train= 1.00

NN: 3
epoch: 200 , mse_ 0.139 , loss_anch 0.139 tau-train= 0.96
epoch: 400 , mse_ 0.001 , loss_anch 0.001 tau-train= 0.96
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 0.164 , loss_anch 0.164 tau-train= 0.96
epoch: 400 , mse_ 0.001 , loss_anch 0.001 tau-train= 0.96
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 0.97 | n_kendall=12 | std(means)/mean(stds)=  0.09 | std(means)=1.85e+06 | mean(stds)=2.07e+07
delta_f=2.2e+04
tau-population= 0.47 | tau-pop-offset= 0.47 | final-target-hit=False
subset-max-norm=4.6910523755424824 | norm-max=12.13941703508117
subset-idx-size=16

NN: 0
epoch: 200 , mse_ 45.071 , loss_anch 45.071 tau-train= 0.85
epoch: 400 , mse_ 5.547 , loss_anch 5.547 tau-train= 0.96
epoch: 600 , mse_ 1.859 , loss_anch 1.859 tau-train= 0.96
epoch: 800 , mse_ 0.796 , loss_anch 0.796 tau-train= 0.96
epoch: 1000 , mse_ 0.452 , loss_anch 0.452 tau-train= 0.96

NN: 1
epoch: 200 , mse_ 0.059 , loss_anch 0.059 tau-train= 0.96
epoch: 400 , mse_ 0.003 , loss_anch 0.003 tau-train= 0.96
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 0.96
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 9.112 , loss_anch 9.112 tau-train= 0.96
epoch: 400 , mse_ 0.87 , loss_anch 0.87 tau-train= 0.96
epoch: 600 , mse_ 0.359 , loss_anch 0.359 tau-train= 0.96
epoch: 800 , mse_ 0.133 , loss_anch 0.133 tau-train= 0.96
epoch: 1000 , mse_ 0.066 , loss_anch 0.066 tau-train= 0.96

NN: 3
epoch: 200 , mse_ 1.792 , loss_anch 1.792 tau-train= 0.96
epoch: 400 , mse_ 0.355 , loss_anch 0.355 tau-train= 0.96
epoch: 600 , mse_ 0.065 , loss_anch 0.065 tau-train= 0.96
epoch: 800 , mse_ 0.006 , loss_anch 0.006 tau-train= 0.96
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 0.96

NN: 4
epoch: 200 , mse_ 0.569 , loss_anch 0.569 tau-train= 0.96
epoch: 400 , mse_ 0.035 , loss_anch 0.035 tau-train= 0.96
epoch: 600 , mse_ 0.001 , loss_anch 0.001 tau-train= 0.96
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=0.9636363636363636
tau-archive=0.9636363636363636
eval=1 | not-eval=5 | tau= 0.91 | n_kendall=12 | std(means)/mean(stds)=  0.08 | std(means)=6.32e+04 | mean(stds)=7.47e+05
delta_f=2.2e+04
tau-population= 0.33 | tau-pop-offset= 0.33 | final-target-hit=False
subset-max-norm=10.026959540680226 | norm-max=12.13941703508117
subset-idx-size=17

NN: 0
epoch: 200 , mse_ 35.203 , loss_anch 35.203 tau-train= 0.89
epoch: 400 , mse_ 4.937 , loss_anch 4.937 tau-train= 0.96
epoch: 600 , mse_ 2.311 , loss_anch 2.311 tau-train= 0.96
epoch: 800 , mse_ 1.227 , loss_anch 1.227 tau-train= 0.96
epoch: 1000 , mse_ 0.559 , loss_anch 0.559 tau-train= 0.96

NN: 1
epoch: 200 , mse_ 0.045 , loss_anch 0.045 tau-train= 0.96
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 43.752 , loss_anch 43.752 tau-train= 0.85
epoch: 400 , mse_ 7.897 , loss_anch 7.897 tau-train= 0.93
epoch: 600 , mse_ 2.384 , loss_anch 2.384 tau-train= 0.96
epoch: 800 , mse_ 1.443 , loss_anch 1.443 tau-train= 1.00
epoch: 1000 , mse_ 1.047 , loss_anch 1.047 tau-train= 1.00

NN: 3
epoch: 200 , mse_ 0.013 , loss_anch 0.013 tau-train= 0.96
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 0.003 , loss_anch 0.003 tau-train= 0.96
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 0.97 | n_kendall=12 | std(means)/mean(stds)=  0.00 | std(means)=1.17e+06 | mean(stds)=3.62e+09
delta_f=2.1e+02
tau-population= 0.60 | tau-pop-offset= 0.60 | final-target-hit=False
subset-max-norm=11.341516950431402 | norm-max=12.13941703508117
subset-idx-size=15

NN: 0
epoch: 200 , mse_ 32.36 , loss_anch 32.36 tau-train= 0.85
epoch: 400 , mse_ 15.671 , loss_anch 15.671 tau-train= 0.96
epoch: 600 , mse_ 7.042 , loss_anch 7.042 tau-train= 0.96
epoch: 800 , mse_ 2.711 , loss_anch 2.711 tau-train= 0.96
epoch: 1000 , mse_ 0.89 , loss_anch 0.89 tau-train= 1.00

NN: 1
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 2.074 , loss_anch 2.074 tau-train= 1.00
epoch: 400 , mse_ 0.918 , loss_anch 0.918 tau-train= 1.00
epoch: 600 , mse_ 0.374 , loss_anch 0.374 tau-train= 1.00
epoch: 800 , mse_ 0.126 , loss_anch 0.126 tau-train= 1.00
epoch: 1000 , mse_ 0.034 , loss_anch 0.034 tau-train= 1.00

NN: 3
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 0.001 , loss_anch 0.001 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 0.91 | n_kendall=12 | std(means)/mean(stds)=  0.20 | std(means)=6.23e+04 | mean(stds)=3.15e+05
delta_f=2.1e+02
tau-population= 0.73 | tau-pop-offset= 0.73 | final-target-hit=False
subset-max-norm=12.029388110836749 | norm-max=12.13941703508117
subset-idx-size=16

NN: 0
epoch: 200 , mse_ 32.856 , loss_anch 32.856 tau-train= 0.89
epoch: 400 , mse_ 11.792 , loss_anch 11.792 tau-train= 0.96
epoch: 600 , mse_ 5.178 , loss_anch 5.178 tau-train= 1.00
epoch: 800 , mse_ 2.598 , loss_anch 2.598 tau-train= 1.00
epoch: 1000 , mse_ 1.48 , loss_anch 1.48 tau-train= 1.00

NN: 1
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 42.408 , loss_anch 42.408 tau-train= 0.85
epoch: 400 , mse_ 21.276 , loss_anch 21.276 tau-train= 0.89
epoch: 600 , mse_ 12.954 , loss_anch 12.954 tau-train= 0.93
epoch: 800 , mse_ 8.225 , loss_anch 8.225 tau-train= 0.96
epoch: 1000 , mse_ 5.178 , loss_anch 5.178 tau-train= 0.96

NN: 3
epoch: 200 , mse_ 0.548 , loss_anch 0.548 tau-train= 1.00
epoch: 400 , mse_ 0.004 , loss_anch 0.004 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 0.121 , loss_anch 0.121 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 1.00 | n_kendall=12 | std(means)/mean(stds)=  0.18 | std(means)=4.53e+04 | mean(stds)=2.59e+05
delta_f=2.1e+02
tau-population= 0.87 | tau-pop-offset= 0.87 | final-target-hit=False
subset-max-norm=11.753014163372566 | norm-max=12.13941703508117
subset-idx-size=20

NN: 0
epoch: 200 , mse_ 530.163 , loss_anch 530.163 tau-train= 0.93
epoch: 400 , mse_ 77.117 , loss_anch 77.117 tau-train= 0.93
epoch: 600 , mse_ 15.557 , loss_anch 15.557 tau-train= 0.96
epoch: 800 , mse_ 8.201 , loss_anch 8.201 tau-train= 1.00
epoch: 1000 , mse_ 8.145 , loss_anch 8.145 tau-train= 1.00

NN: 1
epoch: 200 , mse_ 7.125 , loss_anch 7.125 tau-train= 1.00
epoch: 400 , mse_ 3.392 , loss_anch 3.392 tau-train= 1.00
epoch: 600 , mse_ 0.861 , loss_anch 0.861 tau-train= 1.00
epoch: 800 , mse_ 0.115 , loss_anch 0.115 tau-train= 1.00
epoch: 1000 , mse_ 0.008 , loss_anch 0.008 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 411.071 , loss_anch 411.071 tau-train= 0.93
epoch: 400 , mse_ 162.464 , loss_anch 162.464 tau-train= 0.89
epoch: 600 , mse_ 47.859 , loss_anch 47.859 tau-train= 0.93
epoch: 800 , mse_ 15.193 , loss_anch 15.193 tau-train= 0.96
epoch: 1000 , mse_ 9.091 , loss_anch 9.091 tau-train= 1.00

NN: 3
epoch: 200 , mse_ 9.179 , loss_anch 9.179 tau-train= 1.00
epoch: 400 , mse_ 5.982 , loss_anch 5.982 tau-train= 1.00
epoch: 600 , mse_ 3.461 , loss_anch 3.461 tau-train= 1.00
epoch: 800 , mse_ 1.294 , loss_anch 1.294 tau-train= 1.00
epoch: 1000 , mse_ 0.425 , loss_anch 0.425 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 7.0 , loss_anch 7.0 tau-train= 1.00
epoch: 400 , mse_ 2.448 , loss_anch 2.448 tau-train= 1.00
epoch: 600 , mse_ 0.746 , loss_anch 0.746 tau-train= 1.00
epoch: 800 , mse_ 0.141 , loss_anch 0.141 tau-train= 1.00
epoch: 1000 , mse_ 0.016 , loss_anch 0.016 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 1.00 | n_kendall=12 | std(means)/mean(stds)=  0.13 | std(means)=4.85e+04 | mean(stds)=3.60e+05
delta_f=2.1e+02
tau-population= 0.73 | tau-pop-offset= 0.73 | final-target-hit=False
subset-max-norm=11.931383576207693 | norm-max=12.13941703508117
subset-idx-size=19

NN: 0
epoch: 200 , mse_ 860.14 , loss_anch 860.14 tau-train= 0.89
epoch: 400 , mse_ 418.149 , loss_anch 418.149 tau-train= 0.93
epoch: 600 , mse_ 172.493 , loss_anch 172.493 tau-train= 0.93
epoch: 800 , mse_ 70.743 , loss_anch 70.743 tau-train= 0.93
epoch: 1000 , mse_ 33.205 , loss_anch 33.205 tau-train= 0.96

NN: 1
epoch: 200 , mse_ 8.61 , loss_anch 8.61 tau-train= 1.00
epoch: 400 , mse_ 3.772 , loss_anch 3.772 tau-train= 1.00
epoch: 600 , mse_ 1.064 , loss_anch 1.064 tau-train= 1.00
epoch: 800 , mse_ 0.151 , loss_anch 0.151 tau-train= 1.00
epoch: 1000 , mse_ 0.01 , loss_anch 0.01 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 393.603 , loss_anch 393.603 tau-train= 0.89
epoch: 400 , mse_ 118.221 , loss_anch 118.221 tau-train= 0.82
epoch: 600 , mse_ 41.208 , loss_anch 41.208 tau-train= 0.96
epoch: 800 , mse_ 16.511 , loss_anch 16.511 tau-train= 1.00
epoch: 1000 , mse_ 11.005 , loss_anch 11.005 tau-train= 1.00

NN: 3
epoch: 200 , mse_ 7.966 , loss_anch 7.966 tau-train= 1.00
epoch: 400 , mse_ 2.877 , loss_anch 2.877 tau-train= 1.00
epoch: 600 , mse_ 0.951 , loss_anch 0.951 tau-train= 1.00
epoch: 800 , mse_ 0.155 , loss_anch 0.155 tau-train= 1.00
epoch: 1000 , mse_ 0.013 , loss_anch 0.013 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 10.06 , loss_anch 10.06 tau-train= 1.00
epoch: 400 , mse_ 5.791 , loss_anch 5.791 tau-train= 1.00
epoch: 600 , mse_ 2.659 , loss_anch 2.659 tau-train= 1.00
epoch: 800 , mse_ 0.686 , loss_anch 0.686 tau-train= 1.00
epoch: 1000 , mse_ 0.11 , loss_anch 0.11 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 0.97 | n_kendall=12 | std(means)/mean(stds)=  0.10 | std(means)=2.74e+04 | mean(stds)=2.82e+05
delta_f=2.1e+02
tau-population= 0.33 | tau-pop-offset= 0.33 | final-target-hit=False
subset-max-norm=11.57178076945457 | norm-max=12.13941703508117
subset-idx-size=17

NN: 0
epoch: 200 , mse_ 335.938 , loss_anch 335.938 tau-train= 0.85
epoch: 400 , mse_ 35.576 , loss_anch 35.576 tau-train= 0.93
epoch: 600 , mse_ 13.256 , loss_anch 13.256 tau-train= 0.96
epoch: 800 , mse_ 8.433 , loss_anch 8.433 tau-train= 0.96
epoch: 1000 , mse_ 6.84 , loss_anch 6.84 tau-train= 0.96

NN: 1
epoch: 200 , mse_ 7.282 , loss_anch 7.282 tau-train= 0.96
epoch: 400 , mse_ 2.195 , loss_anch 2.195 tau-train= 0.96
epoch: 600 , mse_ 0.317 , loss_anch 0.317 tau-train= 0.96
epoch: 800 , mse_ 0.034 , loss_anch 0.034 tau-train= 0.96
epoch: 1000 , mse_ 0.002 , loss_anch 0.002 tau-train= 0.96

NN: 2
epoch: 200 , mse_ 400.574 , loss_anch 400.574 tau-train= 0.78
epoch: 400 , mse_ 61.923 , loss_anch 61.923 tau-train= 0.78
epoch: 600 , mse_ 20.264 , loss_anch 20.264 tau-train= 0.93
epoch: 800 , mse_ 14.69 , loss_anch 14.69 tau-train= 0.93
epoch: 1000 , mse_ 13.258 , loss_anch 13.258 tau-train= 0.96

NN: 3
epoch: 200 , mse_ 11.683 , loss_anch 11.683 tau-train= 0.96
epoch: 400 , mse_ 3.462 , loss_anch 3.462 tau-train= 0.96
epoch: 600 , mse_ 0.603 , loss_anch 0.603 tau-train= 0.96
epoch: 800 , mse_ 0.073 , loss_anch 0.073 tau-train= 0.96
epoch: 1000 , mse_ 0.005 , loss_anch 0.005 tau-train= 0.96

NN: 4
epoch: 200 , mse_ 4.443 , loss_anch 4.443 tau-train= 0.96
epoch: 400 , mse_ 0.814 , loss_anch 0.814 tau-train= 0.96
epoch: 600 , mse_ 0.083 , loss_anch 0.083 tau-train= 0.96
epoch: 800 , mse_ 0.004 , loss_anch 0.004 tau-train= 0.96
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=0.9636363636363636
tau-archive=0.9636363636363636
eval=1 | not-eval=5 | tau= 0.97 | n_kendall=12 | std(means)/mean(stds)=  0.16 | std(means)=9.71e+03 | mean(stds)=6.00e+04
delta_f=2.1e+02
tau-population= 0.33 | tau-pop-offset= 0.33 | final-target-hit=False
subset-max-norm=5.875787268545944 | norm-max=12.13941703508117
subset-idx-size=17

NN: 0
epoch: 200 , mse_ 127.453 , loss_anch 127.453 tau-train= 0.89
epoch: 400 , mse_ 22.071 , loss_anch 22.071 tau-train= 0.96
epoch: 600 , mse_ 12.503 , loss_anch 12.503 tau-train= 0.96
epoch: 800 , mse_ 9.287 , loss_anch 9.287 tau-train= 0.96
epoch: 1000 , mse_ 7.696 , loss_anch 7.696 tau-train= 0.96

NN: 1
epoch: 200 , mse_ 4.713 , loss_anch 4.713 tau-train= 0.96
epoch: 400 , mse_ 0.15 , loss_anch 0.15 tau-train= 0.96
epoch: 600 , mse_ 0.001 , loss_anch 0.001 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 87.005 , loss_anch 87.005 tau-train= 0.78
epoch: 400 , mse_ 29.469 , loss_anch 29.469 tau-train= 0.93
epoch: 600 , mse_ 19.044 , loss_anch 19.044 tau-train= 0.93
epoch: 800 , mse_ 14.372 , loss_anch 14.372 tau-train= 0.96
epoch: 1000 , mse_ 11.99 , loss_anch 11.99 tau-train= 0.96

NN: 3
epoch: 200 , mse_ 11.118 , loss_anch 11.118 tau-train= 0.96
epoch: 400 , mse_ 1.182 , loss_anch 1.182 tau-train= 0.96
epoch: 600 , mse_ 0.031 , loss_anch 0.031 tau-train= 0.96
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 2.375 , loss_anch 2.375 tau-train= 0.96
epoch: 400 , mse_ 0.019 , loss_anch 0.019 tau-train= 0.96
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=0.9636363636363636
tau-archive=0.9636363636363636
eval=1 | not-eval=5 | tau= 0.91 | n_kendall=12 | std(means)/mean(stds)=  0.37 | std(means)=1.70e+04 | mean(stds)=4.64e+04
delta_f=2.1e+02
tau-population= 0.87 | tau-pop-offset= 0.87 | final-target-hit=False
subset-max-norm=7.322379085068149 | norm-max=12.13941703508117
subset-idx-size=18

NN: 0
epoch: 200 , mse_ 748.197 , loss_anch 748.197 tau-train= 0.78
epoch: 400 , mse_ 372.899 , loss_anch 372.899 tau-train= 0.89
epoch: 600 , mse_ 283.152 , loss_anch 283.152 tau-train= 0.93
epoch: 800 , mse_ 245.883 , loss_anch 245.883 tau-train= 0.89
epoch: 1000 , mse_ 230.37 , loss_anch 230.37 tau-train= 0.89

NN: 1
epoch: 200 , mse_ 154.076 , loss_anch 154.076 tau-train= 0.93
epoch: 400 , mse_ 32.401 , loss_anch 32.401 tau-train= 0.96
epoch: 600 , mse_ 0.764 , loss_anch 0.764 tau-train= 0.96
epoch: 800 , mse_ 0.002 , loss_anch 0.002 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 676.757 , loss_anch 676.757 tau-train= 0.82
epoch: 400 , mse_ 347.338 , loss_anch 347.338 tau-train= 0.89
epoch: 600 , mse_ 275.648 , loss_anch 275.648 tau-train= 0.93
epoch: 800 , mse_ 248.478 , loss_anch 248.478 tau-train= 0.93
epoch: 1000 , mse_ 324.558 , loss_anch 324.558 tau-train= 0.89

NN: 3
epoch: 200 , mse_ 249.268 , loss_anch 249.268 tau-train= 0.89
epoch: 400 , mse_ 78.937 , loss_anch 78.937 tau-train= 0.89
epoch: 600 , mse_ 17.039 , loss_anch 17.039 tau-train= 0.96
epoch: 800 , mse_ 2.095 , loss_anch 2.095 tau-train= 0.96
epoch: 1000 , mse_ 0.16 , loss_anch 0.16 tau-train= 0.96

NN: 4
epoch: 200 , mse_ 137.536 , loss_anch 137.536 tau-train= 0.93
epoch: 400 , mse_ 12.949 , loss_anch 12.949 tau-train= 0.96
epoch: 600 , mse_ 0.188 , loss_anch 0.188 tau-train= 0.96
epoch: 800 , mse_ 0.001 , loss_anch 0.001 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=0.9636363636363636
tau-archive=0.9636363636363636
eval=1 | not-eval=5 | tau= 0.97 | n_kendall=12 | std(means)/mean(stds)=  0.10 | std(means)=1.57e+04 | mean(stds)=1.52e+05
delta_f=2.5e-01
tau-population= 0.87 | tau-pop-offset= 0.73 | final-target-hit=False
subset-max-norm=11.558453313623223 | norm-max=12.13941703508117
subset-idx-size=17

NN: 0
epoch: 200 , mse_ 103.521 , loss_anch 103.521 tau-train= 0.78
epoch: 400 , mse_ 20.211 , loss_anch 20.211 tau-train= 0.96
epoch: 600 , mse_ 8.263 , loss_anch 8.263 tau-train= 0.96
epoch: 800 , mse_ 4.636 , loss_anch 4.636 tau-train= 0.96
epoch: 1000 , mse_ 2.749 , loss_anch 2.749 tau-train= 0.96

NN: 1
epoch: 200 , mse_ 0.016 , loss_anch 0.016 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 161.057 , loss_anch 161.057 tau-train= 0.71
epoch: 400 , mse_ 40.219 , loss_anch 40.219 tau-train= 0.93
epoch: 600 , mse_ 14.531 , loss_anch 14.531 tau-train= 0.93
epoch: 800 , mse_ 7.002 , loss_anch 7.002 tau-train= 0.93
epoch: 1000 , mse_ 3.614 , loss_anch 3.614 tau-train= 0.93

NN: 3
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 0.006 , loss_anch 0.006 tau-train= 0.96
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=0.9636363636363636
tau-archive=0.9636363636363636
eval=6 | not-eval=0 | tau= 0.91 | n_kendall=12 | std(means)/mean(stds)=  0.07 | std(means)=2.94e+03 | mean(stds)=3.94e+04
delta_f=2.5e-01
tau-population= 1.00 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=11.277160484023245 | norm-max=12.13941703508117
subset-idx-size=21

NN: 0
epoch: 200 , mse_ 92.075 , loss_anch 92.075 tau-train= 0.93
epoch: 400 , mse_ 24.003 , loss_anch 24.003 tau-train= 0.96
epoch: 600 , mse_ 8.614 , loss_anch 8.614 tau-train= 0.96
epoch: 800 , mse_ 4.803 , loss_anch 4.803 tau-train= 0.96
epoch: 1000 , mse_ 26.003 , loss_anch 26.003 tau-train= 0.96

NN: 1
epoch: 200 , mse_ 0.087 , loss_anch 0.087 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 98.445 , loss_anch 98.445 tau-train= 0.89
epoch: 400 , mse_ 26.307 , loss_anch 26.307 tau-train= 0.96
epoch: 600 , mse_ 9.08 , loss_anch 9.08 tau-train= 0.93
epoch: 800 , mse_ 4.03 , loss_anch 4.03 tau-train= 0.96
epoch: 1000 , mse_ 2.115 , loss_anch 2.115 tau-train= 0.96

NN: 3
epoch: 200 , mse_ 0.015 , loss_anch 0.015 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 0.009 , loss_anch 0.009 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 1.00 | n_kendall=12 | std(means)/mean(stds)=  0.31 | std(means)=1.88e+03 | mean(stds)=6.02e+03
delta_f=2.5e-01
tau-population= 0.60 | tau-pop-offset= 0.73 | final-target-hit=False
subset-max-norm=11.382315240686792 | norm-max=12.13941703508117
subset-idx-size=20

NN: 0
epoch: 200 , mse_ 80.086 , loss_anch 80.086 tau-train= 0.89
epoch: 400 , mse_ 41.897 , loss_anch 41.897 tau-train= 0.93
epoch: 600 , mse_ 26.026 , loss_anch 26.026 tau-train= 0.96
epoch: 800 , mse_ 16.124 , loss_anch 16.124 tau-train= 0.96
epoch: 1000 , mse_ 10.373 , loss_anch 10.373 tau-train= 1.00

NN: 1
epoch: 200 , mse_ 0.833 , loss_anch 0.833 tau-train= 1.00
epoch: 400 , mse_ 0.017 , loss_anch 0.017 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 109.571 , loss_anch 109.571 tau-train= 0.93
epoch: 400 , mse_ 34.104 , loss_anch 34.104 tau-train= 0.96
epoch: 600 , mse_ 30.196 , loss_anch 30.196 tau-train= 0.96
epoch: 800 , mse_ 14.155 , loss_anch 14.155 tau-train= 1.00
epoch: 1000 , mse_ 1171.887 , loss_anch 1171.887 tau-train= 0.96

NN: 3
epoch: 200 , mse_ 2.322 , loss_anch 2.322 tau-train= 1.00
epoch: 400 , mse_ 0.274 , loss_anch 0.274 tau-train= 1.00
epoch: 600 , mse_ 0.02 , loss_anch 0.02 tau-train= 1.00
epoch: 800 , mse_ 0.001 , loss_anch 0.001 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 0.94 | n_kendall=12 | std(means)/mean(stds)=  0.04 | std(means)=6.52e+02 | mean(stds)=1.68e+04
delta_f=2.5e-01
tau-population= 0.60 | tau-pop-offset= 0.60 | final-target-hit=False
subset-max-norm=6.369816779238265 | norm-max=12.13941703508117
subset-idx-size=20

NN: 0
epoch: 200 , mse_ 95.435 , loss_anch 95.435 tau-train= 0.89
epoch: 400 , mse_ 46.838 , loss_anch 46.838 tau-train= 0.89
epoch: 600 , mse_ 22.88 , loss_anch 22.88 tau-train= 0.93
epoch: 800 , mse_ 13.503 , loss_anch 13.503 tau-train= 0.96
epoch: 1000 , mse_ 8.211 , loss_anch 8.211 tau-train= 1.00

NN: 1
epoch: 200 , mse_ 4.904 , loss_anch 4.904 tau-train= 1.00
epoch: 400 , mse_ 0.51 , loss_anch 0.51 tau-train= 1.00
epoch: 600 , mse_ 0.02 , loss_anch 0.02 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 69.765 , loss_anch 69.765 tau-train= 0.85
epoch: 400 , mse_ 23.84 , loss_anch 23.84 tau-train= 0.96
epoch: 600 , mse_ 12.487 , loss_anch 12.487 tau-train= 1.00
epoch: 800 , mse_ 8.081 , loss_anch 8.081 tau-train= 1.00
epoch: 1000 , mse_ 5.723 , loss_anch 5.723 tau-train= 1.00

NN: 3
epoch: 200 , mse_ 3.146 , loss_anch 3.146 tau-train= 1.00
epoch: 400 , mse_ 0.047 , loss_anch 0.047 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 0.194 , loss_anch 0.194 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 0.94 | n_kendall=12 | std(means)/mean(stds)=  0.36 | std(means)=7.96e+02 | mean(stds)=2.24e+03
delta_f=2.5e-01
tau-population= 0.60 | tau-pop-offset= 0.47 | final-target-hit=False
subset-max-norm=10.619056027816658 | norm-max=12.13941703508117
subset-idx-size=21

NN: 0
epoch: 200 , mse_ 339.469 , loss_anch 339.469 tau-train= 0.82
epoch: 400 , mse_ 106.443 , loss_anch 106.443 tau-train= 0.89
epoch: 600 , mse_ 62.608 , loss_anch 62.608 tau-train= 0.93
epoch: 800 , mse_ 51.001 , loss_anch 51.001 tau-train= 0.93
epoch: 1000 , mse_ 44.364 , loss_anch 44.364 tau-train= 0.93

NN: 1
epoch: 200 , mse_ 6.077 , loss_anch 6.077 tau-train= 1.00
epoch: 400 , mse_ 0.005 , loss_anch 0.005 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.012 , loss_anch 0.012 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 71.992 , loss_anch 71.992 tau-train= 0.85
epoch: 400 , mse_ 46.699 , loss_anch 46.699 tau-train= 0.89
epoch: 600 , mse_ 36.808 , loss_anch 36.808 tau-train= 0.93
epoch: 800 , mse_ 29.829 , loss_anch 29.829 tau-train= 0.93
epoch: 1000 , mse_ 24.914 , loss_anch 24.914 tau-train= 0.93

NN: 3
epoch: 200 , mse_ 13.427 , loss_anch 13.427 tau-train= 0.96
epoch: 400 , mse_ 0.525 , loss_anch 0.525 tau-train= 1.00
epoch: 600 , mse_ 0.017 , loss_anch 0.017 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 1.381 , loss_anch 1.381 tau-train= 1.00
epoch: 400 , mse_ 0.074 , loss_anch 0.074 tau-train= 1.00
epoch: 600 , mse_ 0.001 , loss_anch 0.001 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 1.00 | n_kendall=12 | std(means)/mean(stds)=  0.57 | std(means)=9.06e+02 | mean(stds)=1.59e+03
delta_f=2.5e-01
tau-population= 0.73 | tau-pop-offset= 0.60 | final-target-hit=False
subset-max-norm=7.953086553248839 | norm-max=12.13941703508117
subset-idx-size=17

NN: 0
epoch: 200 , mse_ 179.25 , loss_anch 179.25 tau-train= 0.85
epoch: 400 , mse_ 62.362 , loss_anch 62.362 tau-train= 0.89
epoch: 600 , mse_ 31.566 , loss_anch 31.566 tau-train= 0.96
epoch: 800 , mse_ 22.851 , loss_anch 22.851 tau-train= 0.96
epoch: 1000 , mse_ 18.206 , loss_anch 18.206 tau-train= 0.96

NN: 1
epoch: 200 , mse_ 5.501 , loss_anch 5.501 tau-train= 1.00
epoch: 400 , mse_ 0.762 , loss_anch 0.762 tau-train= 1.00
epoch: 600 , mse_ 0.054 , loss_anch 0.054 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 47.711 , loss_anch 47.711 tau-train= 0.93
epoch: 400 , mse_ 17.919 , loss_anch 17.919 tau-train= 0.96
epoch: 600 , mse_ 13.844 , loss_anch 13.844 tau-train= 1.00
epoch: 800 , mse_ 11.594 , loss_anch 11.594 tau-train= 1.00
epoch: 1000 , mse_ 9.534 , loss_anch 9.534 tau-train= 1.00

NN: 3
epoch: 200 , mse_ 8.986 , loss_anch 8.986 tau-train= 1.00
epoch: 400 , mse_ 1.026 , loss_anch 1.026 tau-train= 1.00
epoch: 600 , mse_ 0.076 , loss_anch 0.076 tau-train= 1.00
epoch: 800 , mse_ 0.001 , loss_anch 0.001 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 400 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.007 , loss_anch 0.007 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 0.97 | n_kendall=12 | std(means)/mean(stds)=  0.14 | std(means)=1.52e+02 | mean(stds)=1.06e+03
delta_f=2.5e-01
tau-population= 0.73 | tau-pop-offset= 0.60 | final-target-hit=False
subset-max-norm=11.004097345874689 | norm-max=12.13941703508117
subset-idx-size=23

NN: 0
epoch: 200 , mse_ 625.192 , loss_anch 625.192 tau-train= 0.71
epoch: 400 , mse_ 284.058 , loss_anch 284.058 tau-train= 0.64
epoch: 600 , mse_ 140.765 , loss_anch 140.765 tau-train= 0.75
epoch: 800 , mse_ 79.953 , loss_anch 79.953 tau-train= 0.82
epoch: 1000 , mse_ 50.477 , loss_anch 50.477 tau-train= 0.82

NN: 1
epoch: 200 , mse_ 3.745 , loss_anch 3.745 tau-train= 1.00
epoch: 400 , mse_ 1.313 , loss_anch 1.313 tau-train= 1.00
epoch: 600 , mse_ 0.358 , loss_anch 0.358 tau-train= 1.00
epoch: 800 , mse_ 0.068 , loss_anch 0.068 tau-train= 1.00
epoch: 1000 , mse_ 0.009 , loss_anch 0.009 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 186.946 , loss_anch 186.946 tau-train= 0.78
epoch: 400 , mse_ 77.302 , loss_anch 77.302 tau-train= 0.82
epoch: 600 , mse_ 45.952 , loss_anch 45.952 tau-train= 0.82
epoch: 800 , mse_ 29.617 , loss_anch 29.617 tau-train= 0.82
epoch: 1000 , mse_ 21.342 , loss_anch 21.342 tau-train= 0.82

NN: 3
epoch: 200 , mse_ 11.773 , loss_anch 11.773 tau-train= 1.00
epoch: 400 , mse_ 2.805 , loss_anch 2.805 tau-train= 1.00
epoch: 600 , mse_ 0.576 , loss_anch 0.576 tau-train= 1.00
epoch: 800 , mse_ 0.005 , loss_anch 0.005 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 3.143 , loss_anch 3.143 tau-train= 1.00
epoch: 400 , mse_ 0.14 , loss_anch 0.14 tau-train= 1.00
epoch: 600 , mse_ 0.006 , loss_anch 0.006 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=6 | not-eval=0 | tau= 0.33 | n_kendall=12 | std(means)/mean(stds)=  0.00 | std(means)=1.39e+03 | mean(stds)=8.43e+05
delta_f=2.5e-01
tau-population= 0.73 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=10.264253129226702 | norm-max=12.13941703508117
subset-idx-size=29

NN: 0
epoch: 200 , mse_ 609.504 , loss_anch 609.504 tau-train= 0.60
epoch: 400 , mse_ 264.426 , loss_anch 264.426 tau-train= 0.75
epoch: 600 , mse_ 167.616 , loss_anch 167.616 tau-train= 0.75
epoch: 800 , mse_ 97.206 , loss_anch 97.206 tau-train= 0.75
epoch: 1000 , mse_ 56.197 , loss_anch 56.197 tau-train= 0.78

NN: 1
epoch: 200 , mse_ 8.835 , loss_anch 8.835 tau-train= 0.96
epoch: 400 , mse_ 2.536 , loss_anch 2.536 tau-train= 1.00
epoch: 600 , mse_ 1.358 , loss_anch 1.358 tau-train= 1.00
epoch: 800 , mse_ 0.722 , loss_anch 0.722 tau-train= 1.00
epoch: 1000 , mse_ 0.472 , loss_anch 0.472 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 471.028 , loss_anch 471.028 tau-train= 0.75
epoch: 400 , mse_ 181.1 , loss_anch 181.1 tau-train= 0.78
epoch: 600 , mse_ 65.636 , loss_anch 65.636 tau-train= 0.78
epoch: 800 , mse_ 27.158 , loss_anch 27.158 tau-train= 0.82
epoch: 1000 , mse_ 16.851 , loss_anch 16.851 tau-train= 0.85

NN: 3
epoch: 200 , mse_ 16.434 , loss_anch 16.434 tau-train= 0.93
epoch: 400 , mse_ 2.915 , loss_anch 2.915 tau-train= 1.00
epoch: 600 , mse_ 0.731 , loss_anch 0.731 tau-train= 1.00
epoch: 800 , mse_ 0.195 , loss_anch 0.195 tau-train= 1.00
epoch: 1000 , mse_ 0.046 , loss_anch 0.046 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 9.093 , loss_anch 9.093 tau-train= 0.93
epoch: 400 , mse_ 3.852 , loss_anch 3.852 tau-train= 0.96
epoch: 600 , mse_ 1.977 , loss_anch 1.977 tau-train= 1.00
epoch: 800 , mse_ 1.022 , loss_anch 1.022 tau-train= 1.00
epoch: 1000 , mse_ 0.497 , loss_anch 0.497 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 0.94 | n_kendall=12 | std(means)/mean(stds)=  0.13 | std(means)=1.04e+02 | mean(stds)=7.89e+02
delta_f=2.5e-01
tau-population= 0.73 | tau-pop-offset= 0.60 | final-target-hit=False
subset-max-norm=11.150967238269475 | norm-max=12.13941703508117
subset-idx-size=29

NN: 0
epoch: 200 , mse_ 1266.849 , loss_anch 1266.849 tau-train= 0.82
epoch: 400 , mse_ 703.513 , loss_anch 703.513 tau-train= 0.82
epoch: 600 , mse_ 399.681 , loss_anch 399.681 tau-train= 0.89
epoch: 800 , mse_ 252.044 , loss_anch 252.044 tau-train= 0.89
epoch: 1000 , mse_ 174.686 , loss_anch 174.686 tau-train= 0.89

NN: 1
epoch: 200 , mse_ 132.345 , loss_anch 132.345 tau-train= 1.00
epoch: 400 , mse_ 84.896 , loss_anch 84.896 tau-train= 1.00
epoch: 600 , mse_ 61.042 , loss_anch 61.042 tau-train= 1.00
epoch: 800 , mse_ 33.478 , loss_anch 33.478 tau-train= 1.00
epoch: 1000 , mse_ 13.781 , loss_anch 13.781 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 430.47 , loss_anch 430.47 tau-train= 0.85
epoch: 400 , mse_ 183.166 , loss_anch 183.166 tau-train= 0.85
epoch: 600 , mse_ 114.066 , loss_anch 114.066 tau-train= 0.93
epoch: 800 , mse_ 85.721 , loss_anch 85.721 tau-train= 1.00
epoch: 1000 , mse_ 72.901 , loss_anch 72.901 tau-train= 1.00

NN: 3
epoch: 200 , mse_ 133.307 , loss_anch 133.307 tau-train= 0.96
epoch: 400 , mse_ 64.699 , loss_anch 64.699 tau-train= 1.00
epoch: 600 , mse_ 30.733 , loss_anch 30.733 tau-train= 1.00
epoch: 800 , mse_ 13.126 , loss_anch 13.126 tau-train= 1.00
epoch: 1000 , mse_ 5.398 , loss_anch 5.398 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 120.914 , loss_anch 120.914 tau-train= 1.00
epoch: 400 , mse_ 82.736 , loss_anch 82.736 tau-train= 1.00
epoch: 600 , mse_ 59.92 , loss_anch 59.92 tau-train= 0.96
epoch: 800 , mse_ 37.248 , loss_anch 37.248 tau-train= 0.96
epoch: 1000 , mse_ 15.941 , loss_anch 15.941 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 0.88 | n_kendall=12 | std(means)/mean(stds)=  0.36 | std(means)=3.22e+02 | mean(stds)=8.84e+02
delta_f=3.1e-02
tau-population= 0.60 | tau-pop-offset= 0.47 | final-target-hit=False
subset-max-norm=11.025096079857088 | norm-max=12.13941703508117
subset-idx-size=29

NN: 0
epoch: 200 , mse_ 2036.617 , loss_anch 2036.617 tau-train= 0.60
epoch: 400 , mse_ 1076.295 , loss_anch 1076.295 tau-train= 0.78
epoch: 600 , mse_ 670.886 , loss_anch 670.886 tau-train= 0.89
epoch: 800 , mse_ 438.992 , loss_anch 438.992 tau-train= 0.93
epoch: 1000 , mse_ 305.328 , loss_anch 305.328 tau-train= 0.93

NN: 1
epoch: 200 , mse_ 278.627 , loss_anch 278.627 tau-train= 1.00
epoch: 400 , mse_ 87.433 , loss_anch 87.433 tau-train= 1.00
epoch: 600 , mse_ 10.508 , loss_anch 10.508 tau-train= 1.00
epoch: 800 , mse_ 0.281 , loss_anch 0.281 tau-train= 1.00
epoch: 1000 , mse_ 0.016 , loss_anch 0.016 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 1343.214 , loss_anch 1343.214 tau-train= 0.78
epoch: 400 , mse_ 558.036 , loss_anch 558.036 tau-train= 0.96
epoch: 600 , mse_ 305.081 , loss_anch 305.081 tau-train= 0.96
epoch: 800 , mse_ 208.235 , loss_anch 208.235 tau-train= 1.00
epoch: 1000 , mse_ 160.702 , loss_anch 160.702 tau-train= 1.00

NN: 3
epoch: 200 , mse_ 390.851 , loss_anch 390.851 tau-train= 0.89
epoch: 400 , mse_ 98.25 , loss_anch 98.25 tau-train= 1.00
epoch: 600 , mse_ 26.79 , loss_anch 26.79 tau-train= 1.00
epoch: 800 , mse_ 3.039 , loss_anch 3.039 tau-train= 1.00
epoch: 1000 , mse_ 0.134 , loss_anch 0.134 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 128.142 , loss_anch 128.142 tau-train= 1.00
epoch: 400 , mse_ 16.538 , loss_anch 16.538 tau-train= 1.00
epoch: 600 , mse_ 0.233 , loss_anch 0.233 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=0.9636363636363636
tau-archive=0.9636363636363636
eval=2 | not-eval=4 | tau= 0.88 | n_kendall=12 | std(means)/mean(stds)=  0.16 | std(means)=1.60e+02 | mean(stds)=1.01e+03
delta_f=3.1e-02
tau-population= 0.73 | tau-pop-offset= 0.33 | final-target-hit=False
subset-max-norm=10.964339942245784 | norm-max=12.13941703508117
subset-idx-size=28

NN: 0
epoch: 200 , mse_ 1411.979 , loss_anch 1411.979 tau-train= 0.85
epoch: 400 , mse_ 871.052 , loss_anch 871.052 tau-train= 0.96
epoch: 600 , mse_ 605.026 , loss_anch 605.026 tau-train= 1.00
epoch: 800 , mse_ 436.14 , loss_anch 436.14 tau-train= 1.00
epoch: 1000 , mse_ 265.21 , loss_anch 265.21 tau-train= 1.00

NN: 1
epoch: 200 , mse_ 272.273 , loss_anch 272.273 tau-train= 1.00
epoch: 400 , mse_ 79.957 , loss_anch 79.957 tau-train= 1.00
epoch: 600 , mse_ 8.453 , loss_anch 8.453 tau-train= 1.00
epoch: 800 , mse_ 0.139 , loss_anch 0.139 tau-train= 1.00
epoch: 1000 , mse_ 0.023 , loss_anch 0.023 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 958.028 , loss_anch 958.028 tau-train= 0.89
epoch: 400 , mse_ 475.968 , loss_anch 475.968 tau-train= 0.96
epoch: 600 , mse_ 139.681 , loss_anch 139.681 tau-train= 0.96
epoch: 800 , mse_ 28.642 , loss_anch 28.642 tau-train= 1.00
epoch: 1000 , mse_ 5.707 , loss_anch 5.707 tau-train= 1.00

NN: 3
epoch: 200 , mse_ 314.656 , loss_anch 314.656 tau-train= 1.00
epoch: 400 , mse_ 70.468 , loss_anch 70.468 tau-train= 1.00
epoch: 600 , mse_ 10.771 , loss_anch 10.771 tau-train= 1.00
epoch: 800 , mse_ 0.803 , loss_anch 0.803 tau-train= 1.00
epoch: 1000 , mse_ 0.035 , loss_anch 0.035 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 188.282 , loss_anch 188.282 tau-train= 1.00
epoch: 400 , mse_ 3.413 , loss_anch 3.413 tau-train= 1.00
epoch: 600 , mse_ 0.014 , loss_anch 0.014 tau-train= 1.00
epoch: 800 , mse_ 0.336 , loss_anch 0.336 tau-train= 1.00
epoch: 1000 , mse_ 1.747 , loss_anch 1.747 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 0.97 | n_kendall=12 | std(means)/mean(stds)=  0.49 | std(means)=2.60e+02 | mean(stds)=5.26e+02
delta_f=3.1e-02
tau-population= 0.87 | tau-pop-offset= 0.73 | final-target-hit=False
subset-max-norm=10.361196889101361 | norm-max=12.13941703508117
subset-idx-size=29

NN: 0
epoch: 200 , mse_ 1059.775 , loss_anch 1059.775 tau-train= 0.89
epoch: 400 , mse_ 713.361 , loss_anch 713.361 tau-train= 0.96
epoch: 600 , mse_ 514.392 , loss_anch 514.392 tau-train= 1.00
epoch: 800 , mse_ 333.377 , loss_anch 333.377 tau-train= 1.00
epoch: 1000 , mse_ 206.347 , loss_anch 206.347 tau-train= 1.00

NN: 1
epoch: 200 , mse_ 252.935 , loss_anch 252.935 tau-train= 0.96
epoch: 400 , mse_ 69.39 , loss_anch 69.39 tau-train= 1.00
epoch: 600 , mse_ 11.197 , loss_anch 11.197 tau-train= 1.00
epoch: 800 , mse_ 1.404 , loss_anch 1.404 tau-train= 1.00
epoch: 1000 , mse_ 0.126 , loss_anch 0.126 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 962.049 , loss_anch 962.049 tau-train= 0.96
epoch: 400 , mse_ 550.573 , loss_anch 550.573 tau-train= 1.00
epoch: 600 , mse_ 294.219 , loss_anch 294.219 tau-train= 1.00
epoch: 800 , mse_ 189.215 , loss_anch 189.215 tau-train= 1.00
epoch: 1000 , mse_ 229.279 , loss_anch 229.279 tau-train= 1.00

NN: 3
epoch: 200 , mse_ 271.966 , loss_anch 271.966 tau-train= 1.00
epoch: 400 , mse_ 43.853 , loss_anch 43.853 tau-train= 1.00
epoch: 600 , mse_ 8.704 , loss_anch 8.704 tau-train= 1.00
epoch: 800 , mse_ 1.396 , loss_anch 1.396 tau-train= 1.00
epoch: 1000 , mse_ 0.099 , loss_anch 0.099 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 111.684 , loss_anch 111.684 tau-train= 1.00
epoch: 400 , mse_ 11.215 , loss_anch 11.215 tau-train= 1.00
epoch: 600 , mse_ 0.734 , loss_anch 0.734 tau-train= 1.00
epoch: 800 , mse_ 0.034 , loss_anch 0.034 tau-train= 1.00
epoch: 1000 , mse_ 0.011 , loss_anch 0.011 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 0.91 | n_kendall=12 | std(means)/mean(stds)=  0.25 | std(means)=1.60e+02 | mean(stds)=6.43e+02
delta_f=2.9e-02
tau-population= 1.00 | tau-pop-offset= 0.87 | final-target-hit=False
subset-max-norm=10.629195117829633 | norm-max=12.13941703508117
subset-idx-size=27

NN: 0
epoch: 200 , mse_ 4636.981 , loss_anch 4636.981 tau-train= 0.82
epoch: 400 , mse_ 3091.466 , loss_anch 3091.466 tau-train= 0.82
epoch: 600 , mse_ 2332.015 , loss_anch 2332.015 tau-train= 0.85
epoch: 800 , mse_ 1794.508 , loss_anch 1794.508 tau-train= 0.93
epoch: 1000 , mse_ 1307.577 , loss_anch 1307.577 tau-train= 0.96

NN: 1
epoch: 200 , mse_ 1263.321 , loss_anch 1263.321 tau-train= 0.93
epoch: 400 , mse_ 58.836 , loss_anch 58.836 tau-train= 1.00
epoch: 600 , mse_ 0.768 , loss_anch 0.768 tau-train= 1.00
epoch: 800 , mse_ 0.005 , loss_anch 0.005 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 3316.757 , loss_anch 3316.757 tau-train= 0.82
epoch: 400 , mse_ 1890.483 , loss_anch 1890.483 tau-train= 0.93
epoch: 600 , mse_ 925.987 , loss_anch 925.987 tau-train= 1.00
epoch: 800 , mse_ 337.394 , loss_anch 337.394 tau-train= 1.00
epoch: 1000 , mse_ 104.247 , loss_anch 104.247 tau-train= 1.00

NN: 3
epoch: 200 , mse_ 1097.763 , loss_anch 1097.763 tau-train= 0.93
epoch: 400 , mse_ 273.592 , loss_anch 273.592 tau-train= 1.00
epoch: 600 , mse_ 49.9 , loss_anch 49.9 tau-train= 1.00
epoch: 800 , mse_ 6.119 , loss_anch 6.119 tau-train= 1.00
epoch: 1000 , mse_ 0.643 , loss_anch 0.643 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 426.844 , loss_anch 426.844 tau-train= 1.00
epoch: 400 , mse_ 22.803 , loss_anch 22.803 tau-train= 1.00
epoch: 600 , mse_ 0.988 , loss_anch 0.988 tau-train= 1.00
epoch: 800 , mse_ 0.031 , loss_anch 0.031 tau-train= 1.00
epoch: 1000 , mse_ 0.001 , loss_anch 0.001 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 0.91 | n_kendall=12 | std(means)/mean(stds)=  0.09 | std(means)=6.03e+01 | mean(stds)=6.43e+02
delta_f=2.9e-02
tau-population= 0.73 | tau-pop-offset= 0.87 | final-target-hit=False
subset-max-norm=10.768049023444725 | norm-max=12.13941703508117
subset-idx-size=27

NN: 0
epoch: 200 , mse_ 5228.857 , loss_anch 5228.857 tau-train= 0.64
epoch: 400 , mse_ 4250.303 , loss_anch 4250.303 tau-train= 0.78
epoch: 600 , mse_ 3465.511 , loss_anch 3465.511 tau-train= 0.82
epoch: 800 , mse_ 2748.279 , loss_anch 2748.279 tau-train= 0.85
epoch: 1000 , mse_ 1926.753 , loss_anch 1926.753 tau-train= 0.93

NN: 1
epoch: 200 , mse_ 1369.681 , loss_anch 1369.681 tau-train= 0.85
epoch: 400 , mse_ 218.382 , loss_anch 218.382 tau-train= 0.89
epoch: 600 , mse_ 5.908 , loss_anch 5.908 tau-train= 0.96
epoch: 800 , mse_ 0.069 , loss_anch 0.069 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 4174.117 , loss_anch 4174.117 tau-train= 0.75
epoch: 400 , mse_ 2165.655 , loss_anch 2165.655 tau-train= 0.89
epoch: 600 , mse_ 754.26 , loss_anch 754.26 tau-train= 0.85
epoch: 800 , mse_ 287.142 , loss_anch 287.142 tau-train= 0.85
epoch: 1000 , mse_ 134.626 , loss_anch 134.626 tau-train= 0.85

NN: 3
epoch: 200 , mse_ 1594.231 , loss_anch 1594.231 tau-train= 0.82
epoch: 400 , mse_ 327.37 , loss_anch 327.37 tau-train= 0.89
epoch: 600 , mse_ 50.784 , loss_anch 50.784 tau-train= 0.93
epoch: 800 , mse_ 3.077 , loss_anch 3.077 tau-train= 1.00
epoch: 1000 , mse_ 1.863 , loss_anch 1.863 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 488.428 , loss_anch 488.428 tau-train= 0.93
epoch: 400 , mse_ 7.672 , loss_anch 7.672 tau-train= 1.00
epoch: 600 , mse_ 0.002 , loss_anch 0.002 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 0.91 | n_kendall=12 | std(means)/mean(stds)=  0.02 | std(means)=2.93e+01 | mean(stds)=1.90e+03
delta_f=2.9e-02
tau-population=-0.07 | tau-pop-offset= 0.07 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) array([[-39.58401504],
       [-27.41330713],
       [-28.3035603 ],
       [-48.10344844],
       [-54.61667592],
       [-54.80950795]])
(Pdb) array([[-54.56027615],
       [-53.32830226],
       [ 25.51216557],
       [-54.5188014 ],
       [-54.5096436 ],
       [-48.07617679]])
(Pdb) --Call--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1555)surrogate_model()
-> @wraps(model)
(Pdb) 1555 ->	        @wraps(model)
1556 	        def surrogate_model(
1557 	            features: np.ndarray[tuple[N, DIM], np.dtype[np.float64]],
1558 	        ) -> Prediction[N]:
1559 	            features_transf = x_transf.transform(features)
1560 	            pred_transf = model(features_transf)
1561 	            return Prediction(
1562 	                y_transf.transform_inv(pred_transf.mean),
1563 	                y_transf.transform_inv_std(pred_transf.std),
1564 	            )
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1559)surrogate_model()
-> features_transf = x_transf.transform(features)
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1560)surrogate_model()
-> pred_transf = model(features_transf)
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1561)surrogate_model()
-> return Prediction(
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1562)surrogate_model()
-> y_transf.transform_inv(pred_transf.mean),
(Pdb) --Call--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1459)transform_inv()
-> def transform_inv(
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1462)transform_inv()
-> return np.e**data * self.__scale - self.__improvement + self.__shift
(Pdb) *** AttributeError: 'MinAdjustedLog' object has no attribute '__shift'
(Pdb) ['_MinAdjustedLog__improvement', '_MinAdjustedLog__min_offset', '_MinAdjustedLog__scale', '_MinAdjustedLog__shift', '__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', 'transform', 'transform_inv', 'transform_inv_std']
(Pdb) -54.910808797001586
(Pdb) 0.0014864041142459428
(Pdb) -54.91229520111583
(Pdb) 2.06115362243856e-09
(Pdb) -54.90268943271936
(Pdb) *** NameError: name 'pred_transf' is not defined
(Pdb) 1459 	    def transform_inv(
1460 	        self, data: np.ndarray[S, dtype[float64]], /
1461 	    ) -> np.ndarray[S, dtype[float64]]:
1462 ->	        return np.e**data * self.__scale - self.__improvement + self.__shift
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1462)transform_inv()->array([[-54.5...48.07617679]])
-> return np.e**data * self.__scale - self.__improvement + self.__shift
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1563)surrogate_model()
-> y_transf.transform_inv_std(pred_transf.std),
(Pdb) 1555 	        @wraps(model)
1556 	        def surrogate_model(
1557 	            features: np.ndarray[tuple[N, DIM], np.dtype[np.float64]],
1558 	        ) -> Prediction[N]:
1559 	            features_transf = x_transf.transform(features)
1560 	            pred_transf = model(features_transf)
1561 	            return Prediction(
1562 	                y_transf.transform_inv(pred_transf.mean),
1563 ->	                y_transf.transform_inv_std(pred_transf.std),
1564 	            )
(Pdb) array([[-6.39867851],
       [-4.89465968],
       [-0.96729015],
       [-6.28729847],
       [-6.26429212],
       [-3.43238843]])
(Pdb) subset-max-norm=10.74942116199258 | norm-max=12.13941703508117
subset-idx-size=28

NN: 0
epoch: 200 , mse_ 4412.255 , loss_anch 4412.255 tau-train= 0.60
epoch: 400 , mse_ 3221.596 , loss_anch 3221.596 tau-train= 0.71
epoch: 600 , mse_ 2211.398 , loss_anch 2211.398 tau-train= 0.75
epoch: 800 , mse_ 1131.298 , loss_anch 1131.298 tau-train= 0.75
epoch: 1000 , mse_ 562.182 , loss_anch 562.182 tau-train= 0.75

NN: 1
epoch: 200 , mse_ 331.824 , loss_anch 331.824 tau-train= 0.89
epoch: 400 , mse_ 0.575 , loss_anch 0.575 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 1.8 , loss_anch 1.8 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 4605.947 , loss_anch 4605.947 tau-train= 0.60
epoch: 400 , mse_ 3371.145 , loss_anch 3371.145 tau-train= 0.75
epoch: 600 , mse_ 2310.202 , loss_anch 2310.202 tau-train= 0.78
epoch: 800 , mse_ 1248.757 , loss_anch 1248.757 tau-train= 0.67
epoch: 1000 , mse_ 456.699 , loss_anch 456.699 tau-train= 0.78

NN: 3
epoch: 200 , mse_ 1083.044 , loss_anch 1083.044 tau-train= 0.85
epoch: 400 , mse_ 265.442 , loss_anch 265.442 tau-train= 0.89
epoch: 600 , mse_ 25.824 , loss_anch 25.824 tau-train= 1.00
epoch: 800 , mse_ 0.606 , loss_anch 0.606 tau-train= 1.00
epoch: 1000 , mse_ 0.017 , loss_anch 0.017 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 556.296 , loss_anch 556.296 tau-train= 0.85
epoch: 400 , mse_ 11.706 , loss_anch 11.706 tau-train= 1.00
epoch: 600 , mse_ 0.003 , loss_anch 0.003 tau-train= 1.00
epoch: 800 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=0.9636363636363636
tau-archive=0.9636363636363636
eval=1 | not-eval=5 | tau= 0.88 | n_kendall=12 | std(means)/mean(stds)=  0.09 | std(means)=1.30e+02 | mean(stds)=1.44e+03
delta_f=2.9e-02
tau-population= 0.47 | tau-pop-offset= 0.60 | final-target-hit=False
subset-max-norm=11.629575840937592 | norm-max=12.13941703508117
subset-idx-size=27

NN: 0
epoch: 200 , mse_ 4035.7 , loss_anch 4035.7 tau-train= 0.67
epoch: 400 , mse_ 3117.742 , loss_anch 3117.742 tau-train= 0.75
epoch: 600 , mse_ 1831.963 , loss_anch 1831.963 tau-train= 0.78
epoch: 800 , mse_ 995.912 , loss_anch 995.912 tau-train= 0.85
epoch: 1000 , mse_ 791.393 , loss_anch 791.393 tau-train= 0.85

NN: 1
epoch: 200 , mse_ 781.154 , loss_anch 781.154 tau-train= 0.82
epoch: 400 , mse_ 151.053 , loss_anch 151.053 tau-train= 0.96
epoch: 600 , mse_ 3.177 , loss_anch 3.177 tau-train= 1.00
epoch: 800 , mse_ 0.007 , loss_anch 0.007 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 3681.088 , loss_anch 3681.088 tau-train= 0.67
epoch: 400 , mse_ 2316.577 , loss_anch 2316.577 tau-train= 0.78
epoch: 600 , mse_ 1348.196 , loss_anch 1348.196 tau-train= 0.78
epoch: 800 , mse_ 721.717 , loss_anch 721.717 tau-train= 0.82
epoch: 1000 , mse_ 306.011 , loss_anch 306.011 tau-train= 0.89

NN: 3
epoch: 200 , mse_ 916.428 , loss_anch 916.428 tau-train= 0.82
epoch: 400 , mse_ 387.472 , loss_anch 387.472 tau-train= 0.85
epoch: 600 , mse_ 103.158 , loss_anch 103.158 tau-train= 0.96
epoch: 800 , mse_ 7.526 , loss_anch 7.526 tau-train= 1.00
epoch: 1000 , mse_ 0.079 , loss_anch 0.079 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 480.464 , loss_anch 480.464 tau-train= 0.89
epoch: 400 , mse_ 1.182 , loss_anch 1.182 tau-train= 1.00
epoch: 600 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
epoch: 800 , mse_ 0.001 , loss_anch 0.001 tau-train= 1.00
epoch: 1000 , mse_ 0.03 , loss_anch 0.03 tau-train= 1.00
tau-train-ens=0.9636363636363636
tau-archive=0.9636363636363636
eval=1 | not-eval=5 | tau= 0.91 | n_kendall=12 | std(means)/mean(stds)=  0.27 | std(means)=5.14e+01 | mean(stds)=1.89e+02
delta_f=2.9e-02
tau-population= 0.60 | tau-pop-offset= 0.47 | final-target-hit=False
subset-max-norm=11.437061496965038 | norm-max=12.13941703508117
subset-idx-size=27

NN: 0
epoch: 200 , mse_ 4304.029 , loss_anch 4304.029 tau-train= 0.45
epoch: 400 , mse_ 3187.826 , loss_anch 3187.826 tau-train= 0.67
epoch: 600 , mse_ 2461.356 , loss_anch 2461.356 tau-train= 0.78
epoch: 800 , mse_ 1827.547 , loss_anch 1827.547 tau-train= 0.78
epoch: 1000 , mse_ 1350.902 , loss_anch 1350.902 tau-train= 0.85

NN: 1
epoch: 200 , mse_ 883.741 , loss_anch 883.741 tau-train= 0.85
epoch: 400 , mse_ 218.011 , loss_anch 218.011 tau-train= 0.89
epoch: 600 , mse_ 12.71 , loss_anch 12.71 tau-train= 1.00
epoch: 800 , mse_ 0.159 , loss_anch 0.159 tau-train= 1.00
epoch: 1000 , mse_ 0.001 , loss_anch 0.001 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 2623.487 , loss_anch 2623.487 tau-train= 0.75
epoch: 400 , mse_ 1308.181 , loss_anch 1308.181 tau-train= 0.82
epoch: 600 , mse_ 740.265 , loss_anch 740.265 tau-train= 0.85
epoch: 800 , mse_ 424.355 , loss_anch 424.355 tau-train= 0.93
epoch: 1000 , mse_ 231.873 , loss_anch 231.873 tau-train= 0.96

NN: 3
epoch: 200 , mse_ 1066.599 , loss_anch 1066.599 tau-train= 0.85
epoch: 400 , mse_ 532.359 , loss_anch 532.359 tau-train= 0.85
epoch: 600 , mse_ 196.441 , loss_anch 196.441 tau-train= 0.93
epoch: 800 , mse_ 28.677 , loss_anch 28.677 tau-train= 1.00
epoch: 1000 , mse_ 1.923 , loss_anch 1.923 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 699.032 , loss_anch 699.032 tau-train= 0.82
epoch: 400 , mse_ 30.759 , loss_anch 30.759 tau-train= 1.00
epoch: 600 , mse_ 0.104 , loss_anch 0.104 tau-train= 1.00
epoch: 800 , mse_ 0.677 , loss_anch 0.677 tau-train= 1.00
epoch: 1000 , mse_ 0.011 , loss_anch 0.011 tau-train= 1.00
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 0.91 | n_kendall=12 | std(means)/mean(stds)=  0.20 | std(means)=2.63e+01 | mean(stds)=1.29e+02
delta_f=2.9e-02
tau-population= 0.87 | tau-pop-offset= 0.73 | final-target-hit=False
subset-max-norm=8.71393313753124 | norm-max=12.13941703508117
subset-idx-size=30

NN: 0
epoch: 200 , mse_ 3829.804 , loss_anch 3829.804 tau-train= 0.31
epoch: 400 , mse_ 3033.837 , loss_anch 3033.837 tau-train= 0.71
epoch: 600 , mse_ 2437.861 , loss_anch 2437.861 tau-train= 0.71
epoch: 800 , mse_ 1860.399 , loss_anch 1860.399 tau-train= 0.78
epoch: 1000 , mse_ 1384.676 , loss_anch 1384.676 tau-train= 0.78

NN: 1
epoch: 200 , mse_ 1300.749 , loss_anch 1300.749 tau-train= 0.75
epoch: 400 , mse_ 296.181 , loss_anch 296.181 tau-train= 0.82
epoch: 600 , mse_ 7.914 , loss_anch 7.914 tau-train= 0.96
epoch: 800 , mse_ 0.026 , loss_anch 0.026 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 3135.419 , loss_anch 3135.419 tau-train= 0.45
epoch: 400 , mse_ 2527.365 , loss_anch 2527.365 tau-train= 0.60
epoch: 600 , mse_ 2195.417 , loss_anch 2195.417 tau-train= 0.67
epoch: 800 , mse_ 1900.165 , loss_anch 1900.165 tau-train= 0.71
epoch: 1000 , mse_ 1618.636 , loss_anch 1618.636 tau-train= 0.75

NN: 3
epoch: 200 , mse_ 1566.579 , loss_anch 1566.579 tau-train= 0.67
epoch: 400 , mse_ 619.814 , loss_anch 619.814 tau-train= 0.75
epoch: 600 , mse_ 163.569 , loss_anch 163.569 tau-train= 0.93
epoch: 800 , mse_ 16.958 , loss_anch 16.958 tau-train= 1.00
epoch: 1000 , mse_ 0.427 , loss_anch 0.427 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 581.554 , loss_anch 581.554 tau-train= 0.75
epoch: 400 , mse_ 118.773 , loss_anch 118.773 tau-train= 0.96
epoch: 600 , mse_ 1.997 , loss_anch 1.997 tau-train= 1.00
epoch: 800 , mse_ 0.011 , loss_anch 0.011 tau-train= 1.00
epoch: 1000 , mse_ 0.0 , loss_anch 0.0 tau-train= 1.00
tau-train-ens=0.9272727272727274
tau-archive=0.9272727272727274
eval=1 | not-eval=5 | tau= 0.91 | n_kendall=12 | std(means)/mean(stds)=  0.21 | std(means)=6.01e+01 | mean(stds)=2.89e+02
delta_f=2.9e-02
tau-population= 0.87 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=10.853469708718317 | norm-max=12.13941703508117
subset-idx-size=30

NN: 0
epoch: 200 , mse_ 3472.834 , loss_anch 3472.834 tau-train= 0.56
epoch: 400 , mse_ 2751.874 , loss_anch 2751.874 tau-train= 0.71
epoch: 600 , mse_ 2094.904 , loss_anch 2094.904 tau-train= 0.71
epoch: 800 , mse_ 1601.46 , loss_anch 1601.46 tau-train= 0.71
epoch: 1000 , mse_ 1327.949 , loss_anch 1327.949 tau-train= 0.71

NN: 1
epoch: 200 , mse_ 1021.053 , loss_anch 1021.053 tau-train= 0.75
epoch: 400 , mse_ 377.58 , loss_anch 377.58 tau-train= 0.82
epoch: 600 , mse_ 55.434 , loss_anch 55.434 tau-train= 0.93
epoch: 800 , mse_ 3.492 , loss_anch 3.492 tau-train= 0.96
epoch: 1000 , mse_ 3.085 , loss_anch 3.085 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 4285.041 , loss_anch 4285.041 tau-train= 0.13
epoch: 400 , mse_ 3230.747 , loss_anch 3230.747 tau-train= 0.60
epoch: 600 , mse_ 2463.5 , loss_anch 2463.5 tau-train= 0.64
epoch: 800 , mse_ 1961.411 , loss_anch 1961.411 tau-train= 0.60
epoch: 1000 , mse_ 1640.622 , loss_anch 1640.622 tau-train= 0.67

NN: 3
epoch: 200 , mse_ 1184.704 , loss_anch 1184.704 tau-train= 0.64
epoch: 400 , mse_ 373.403 , loss_anch 373.403 tau-train= 0.75
epoch: 600 , mse_ 57.444 , loss_anch 57.444 tau-train= 0.89
epoch: 800 , mse_ 7.578 , loss_anch 7.578 tau-train= 0.93
epoch: 1000 , mse_ 1.034 , loss_anch 1.034 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 847.532 , loss_anch 847.532 tau-train= 0.78
epoch: 400 , mse_ 212.293 , loss_anch 212.293 tau-train= 0.85
epoch: 600 , mse_ 13.459 , loss_anch 13.459 tau-train= 0.96
epoch: 800 , mse_ 0.221 , loss_anch 0.221 tau-train= 1.00
epoch: 1000 , mse_ 0.014 , loss_anch 0.014 tau-train= 1.00
tau-train-ens=0.9272727272727274
tau-archive=0.9272727272727274
eval=1 | not-eval=5 | tau= 0.91 | n_kendall=12 | std(means)/mean(stds)=  0.26 | std(means)=2.17e+01 | mean(stds)=8.33e+01
delta_f=2.9e-02
tau-population= 0.73 | tau-pop-offset= 0.87 | final-target-hit=False
subset-max-norm=10.864141846736754 | norm-max=12.13941703508117
subset-idx-size=32

NN: 0
epoch: 200 , mse_ 3660.139 , loss_anch 3660.139 tau-train= 0.35
epoch: 400 , mse_ 2840.386 , loss_anch 2840.386 tau-train= 0.49
epoch: 600 , mse_ 2309.692 , loss_anch 2309.692 tau-train= 0.60
epoch: 800 , mse_ 1930.165 , loss_anch 1930.165 tau-train= 0.64
epoch: 1000 , mse_ 1628.843 , loss_anch 1628.843 tau-train= 0.71

NN: 1
epoch: 200 , mse_ 2011.484 , loss_anch 2011.484 tau-train= 0.45
epoch: 400 , mse_ 1261.112 , loss_anch 1261.112 tau-train= 0.71
epoch: 600 , mse_ 736.563 , loss_anch 736.563 tau-train= 0.64
epoch: 800 , mse_ 300.139 , loss_anch 300.139 tau-train= 0.71
epoch: 1000 , mse_ 90.701 , loss_anch 90.701 tau-train= 0.78

NN: 2
epoch: 200 , mse_ 3653.163 , loss_anch 3653.163 tau-train= 0.31
epoch: 400 , mse_ 2766.796 , loss_anch 2766.796 tau-train= 0.38
epoch: 600 , mse_ 2081.681 , loss_anch 2081.681 tau-train= 0.49
epoch: 800 , mse_ 1764.642 , loss_anch 1764.642 tau-train= 0.53
epoch: 1000 , mse_ 1618.405 , loss_anch 1618.405 tau-train= 0.64

NN: 3
epoch: 200 , mse_ 2208.092 , loss_anch 2208.092 tau-train= 0.38
epoch: 400 , mse_ 1214.887 , loss_anch 1214.887 tau-train= 0.64
epoch: 600 , mse_ 625.272 , loss_anch 625.272 tau-train= 0.71
epoch: 800 , mse_ 282.279 , loss_anch 282.279 tau-train= 0.78
epoch: 1000 , mse_ 138.235 , loss_anch 138.235 tau-train= 0.82

NN: 4
epoch: 200 , mse_ 1575.265 , loss_anch 1575.265 tau-train= 0.45
epoch: 400 , mse_ 851.651 , loss_anch 851.651 tau-train= 0.60
epoch: 600 , mse_ 279.361 , loss_anch 279.361 tau-train= 0.75
epoch: 800 , mse_ 56.174 , loss_anch 56.174 tau-train= 0.89
epoch: 1000 , mse_ 12.228 , loss_anch 12.228 tau-train= 0.96
tau-train-ens=0.8545454545454545
tau-archive=0.8545454545454545
eval=1 | not-eval=5 | tau= 0.88 | n_kendall=12 | std(means)/mean(stds)=  0.11 | std(means)=1.95e+01 | mean(stds)=1.71e+02
delta_f=2.9e-02
tau-population= 0.87 | tau-pop-offset= 0.73 | final-target-hit=False
subset-max-norm=10.524593063284186 | norm-max=12.13941703508117
subset-idx-size=33

NN: 0
epoch: 200 , mse_ 3777.473 , loss_anch 3777.473 tau-train= 0.24
epoch: 400 , mse_ 2950.172 , loss_anch 2950.172 tau-train= 0.31
epoch: 600 , mse_ 2335.349 , loss_anch 2335.349 tau-train= 0.45
epoch: 800 , mse_ 1881.94 , loss_anch 1881.94 tau-train= 0.49
epoch: 1000 , mse_ 1683.712 , loss_anch 1683.712 tau-train= 0.53

NN: 1
epoch: 200 , mse_ 2266.079 , loss_anch 2266.079 tau-train= 0.24
epoch: 400 , mse_ 1535.732 , loss_anch 1535.732 tau-train= 0.60
epoch: 600 , mse_ 1118.577 , loss_anch 1118.577 tau-train= 0.60
epoch: 800 , mse_ 756.687 , loss_anch 756.687 tau-train= 0.67
epoch: 1000 , mse_ 520.051 , loss_anch 520.051 tau-train= 0.67

NN: 2
epoch: 200 , mse_ 3091.732 , loss_anch 3091.732 tau-train= 0.31
epoch: 400 , mse_ 2128.114 , loss_anch 2128.114 tau-train= 0.45
epoch: 600 , mse_ 1735.127 , loss_anch 1735.127 tau-train= 0.49
epoch: 800 , mse_ 1596.255 , loss_anch 1596.255 tau-train= 0.64
epoch: 1000 , mse_ 1515.384 , loss_anch 1515.384 tau-train= 0.71

NN: 3
epoch: 200 , mse_ 2109.169 , loss_anch 2109.169 tau-train= 0.38
epoch: 400 , mse_ 1364.873 , loss_anch 1364.873 tau-train= 0.71
epoch: 600 , mse_ 935.915 , loss_anch 935.915 tau-train= 0.78
epoch: 800 , mse_ 642.331 , loss_anch 642.331 tau-train= 0.82
epoch: 1000 , mse_ 436.908 , loss_anch 436.908 tau-train= 0.78

NN: 4
epoch: 200 , mse_ 1936.415 , loss_anch 1936.415 tau-train= 0.27
epoch: 400 , mse_ 1347.635 , loss_anch 1347.635 tau-train= 0.67
epoch: 600 , mse_ 889.596 , loss_anch 889.596 tau-train= 0.67
epoch: 800 , mse_ 511.759 , loss_anch 511.759 tau-train= 0.67
epoch: 1000 , mse_ 298.545 , loss_anch 298.545 tau-train= 0.71
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1077)__call__()
-> print(f"tau-train-ens={_tau}")
(Pdb) 0.6363636363636364
(Pdb) *** NameError: name '_values_true' is not defined
(Pdb) 956  	    def __call__(
957  	        self,
958  	        *,
959  	        x_train: NDArray[np.float64],
960  	        y_train: NDArray[np.float64],
961  	        x_test: NDArray[np.float64],
962  	        weights: Optional[NDArray[np.float64]] = None,
963  	    ) -> Model:
964  	        data_noise = self.__data_noise
965  	        """Taken form `RAFs <https://github.com/YanasGH/RAFs/blob/6a0ec46a7d9cd830e7d8e74358643aee1f65323d/main_experiments/rafs.py#L94-L157>`_"""
966  	        X_train, y_train, X_val = x_train, y_train, x_test
967  	
968  	        n = X_train.shape[0]
969  	        x_dim = X_train.shape[1]
970  	        y_dim = y_train.shape[1]
971  	        if __debug__ and self.__debug:
972  	            _max_model_size = max(
973  	                x_test.shape[0], x_dim * (x_dim + 3) + 2
974  	            )
975  	            _n_kendall_archive = min(15, _max_model_size) - 1
976  	
977  	        n_ensembles = 5
978  	        hidden_size = 100
979  	        init_stddev_1_w = np.sqrt(10)
980  	        init_stddev_1_b = init_stddev_1_w  # set these equal
981  	        init_stddev_2_w = 1.0 / np.sqrt(hidden_size)  # normal scaling
982  	        lambda_anchor = data_noise / (
983  	            np.array([init_stddev_1_w, init_stddev_1_b, init_stddev_2_w]) ** 2
984  	        )
985  	
986  	        n_epochs = self.__epochs
987  	        learning_rate = 0.01
988  	
989  	        NNs = []
990  	        y_prior = []
991  	        tf.reset_default_graph()
992  	        sess = tf.Session()
993  	
994  	        # loop to initialise all ensemble members, get priors
995  	        for ens in range(0, n_ensembles):
996  	            NNs.append(
997  	                NN(
998  	                    x_dim,
999  	                    y_dim,
1000 	                    hidden_size,
1001 	                    init_stddev_1_w,
1002 	                    init_stddev_1_b,
1003 	                    init_stddev_2_w,
1004 	                    n,
1005 	                    learning_rate,
1006 	                    ens,
1007 	                )
1008 	            )
1009 	
1010 	            # initialise only unitialized variables - stops overwriting ensembles already created
1011 	            global_vars = tf.global_variables()
1012 	            is_not_initialized = sess.run(
1013 	                [tf.is_variable_initialized(var) for var in global_vars]
1014 	            )
1015 	            not_initialized_vars = [
1016 	                v for (v, f) in zip(global_vars, is_not_initialized) if not f
1017 	            ]
1018 	            if len(not_initialized_vars):
1019 	                sess.run(tf.variables_initializer(not_initialized_vars))
1020 	
1021 	            # do regularisation now that we've created initialisations
1022 	            NNs[ens].anchor(
1023 	                sess, lambda_anchor
1024 	            )  # Do that if you want to minimize the anchored loss
1025 	
1026 	            # save their priors
1027 	            y_prior.append(NNs[ens].predict(X_val, sess))
1028 	
1029 	        for ens in range(0, n_ensembles):
1030 	            feed_b = {}
1031 	            feed_b[NNs[ens].inputs] = X_train
1032 	            feed_b[NNs[ens].y_target] = y_train
1033 	            if __debug__ and self.__debug:
1034 	                print("\nNN:", ens)
1035 	
1036 	            ep_ = 0
1037 	            while ep_ < n_epochs:
1038 	                ep_ += 1
1039 	                blank = sess.run(NNs[ens].optimizer, feed_dict=feed_b)  # noqa: F841
1040 	                if ep_ % (n_epochs / 5) == 0:
1041 	                    loss_mse = sess.run(NNs[ens].mse_, feed_dict=feed_b)
1042 	                    loss_anch = sess.run(NNs[ens].loss_, feed_dict=feed_b)
1043 	                    if __debug__ and self.__debug:
1044 	                        print(
1045 	                            "epoch:",
1046 	                            ep_,
1047 	                            ", mse_",
1048 	                            np.round(loss_mse * 1e3, 3),
1049 	                            ", loss_anch",
1050 	                            np.round(loss_anch * 1e3, 3),
1051 	                            "tau-train={:>5.2f}".format(
1052 	                                kendalltau(
1053 	                                    y_train[-_n_kendall_archive:],  # pyright: ignore [reportOperatorIssue,reportPossiblyUnboundVariable]
1054 	                                    np.array(
1055 	                                        NNs[ens].predict(
1056 	                                            X_train[-_n_kendall_archive:],  # pyright: ignore [reportOperatorIssue,reportPossiblyUnboundVariable]
1057 	                                            sess,
1058 	                                        )
1059 	                                    ),
1060 	                                ).statistic
1061 	                            ),
1062 	                        )
1063 	                    # the anchored loss is minimized, but it's useful to keep an eye on mse too
1064 	
1065 	        if __debug__ and self.__debug:
1066 	            _tau = kendalltau(
1067 	                y_train[-_n_kendall_archive:],  # pyright: ignore [reportOperatorIssue,reportPossiblyUnboundVariable]
1068 	                np.mean(
1069 	                    np.array(
1070 	                        [nn.predict(X_train[-_n_kendall_archive:], sess) for nn in NNs]  # pyright: ignore [reportOperatorIssue,reportPossiblyUnboundVariable]
1071 	                    ),
1072 	                    axis=0,
1073 	                ),
1074 	            ).statistic
1075 	            if _tau < 0.7:
1076 	                breakpoint()
1077 ->	            print(f"tau-train-ens={_tau}")
1078 	
1079 	        def raf(features):
1080 	            y_pred = np.array([nn.predict(features, sess) for nn in NNs])
1081 	            return Prediction(
1082 	                np.mean(y_pred, axis=0),
1083 	                np.sqrt(np.square(np.std(y_pred, axis=0, ddof=1)) + data_noise),
1084 	            )
1085 	
1086 	        return raf
(Pdb) array([[ 2.11969193e+00],
       [ 2.89579957e+00],
       [ 2.99278879e+00],
       [ 2.89187004e+00],
       [ 2.15390107e+00],
       [-4.75395513e+00],
       [ 4.24573839e+00],
       [ 3.51068391e+00],
       [ 9.64351469e-01],
       [ 3.13516834e-01],
       [ 2.61568499e+00],
       [-1.11778499e-01],
       [-4.20001518e-01],
       [ 5.85079282e-05],
       [ 3.88339500e+00],
       [ 2.66114855e+00],
       [ 2.39878222e+00],
       [ 2.26959142e+00],
       [ 2.15358328e+00],
       [-2.37613737e+00],
       [-9.05317185e+00],
       [ 6.01828906e-01],
       [-6.02738374e-02],
       [-3.99647183e+00],
       [-9.74631903e+00],
       [-1.36266485e+00],
       [-5.05224113e-01],
       [-2.92873069e+00],
       [-2.60971449e+00],
       [-2.55050524e+00],
       [-3.10632215e+00],
       [-3.32720281e+00],
       [-4.94542834e+00]])
(Pdb) tau-train-ens=0.6363636363636364
tau-archive=0.6363636363636364
eval=6 | not-eval=0 | tau= 0.24 | n_kendall=12 | std(means)/mean(stds)=  1.08 | std(means)=2.46e+02 | mean(stds)=2.27e+02
delta_f=2.9e-02
tau-population= 0.47 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=11.732150116856372 | norm-max=12.13941703508117
subset-idx-size=39

NN: 0
epoch: 200 , mse_ 4002.405 , loss_anch 4002.405 tau-train= 0.16
epoch: 400 , mse_ 3349.579 , loss_anch 3349.579 tau-train= 0.20
epoch: 600 , mse_ 2742.702 , loss_anch 2742.702 tau-train= 0.20
epoch: 800 , mse_ 2327.205 , loss_anch 2327.205 tau-train= 0.31
epoch: 1000 , mse_ 1973.879 , loss_anch 1973.879 tau-train= 0.42

NN: 1
epoch: 200 , mse_ 2462.79 , loss_anch 2462.79 tau-train= 0.31
epoch: 400 , mse_ 1626.154 , loss_anch 1626.154 tau-train= 0.31
epoch: 600 , mse_ 1446.219 , loss_anch 1446.219 tau-train= 0.45
epoch: 800 , mse_ 1362.93 , loss_anch 1362.93 tau-train= 0.56
epoch: 1000 , mse_ 1292.739 , loss_anch 1292.739 tau-train= 0.56

NN: 2
epoch: 200 , mse_ 3054.899 , loss_anch 3054.899 tau-train= 0.27
epoch: 400 , mse_ 2037.681 , loss_anch 2037.681 tau-train= 0.38
epoch: 600 , mse_ 1665.551 , loss_anch 1665.551 tau-train= 0.42
epoch: 800 , mse_ 1560.328 , loss_anch 1560.328 tau-train= 0.42
epoch: 1000 , mse_ 1510.793 , loss_anch 1510.793 tau-train= 0.49

NN: 3
epoch: 200 , mse_ 2474.474 , loss_anch 2474.474 tau-train= 0.09
epoch: 400 , mse_ 1575.254 , loss_anch 1575.254 tau-train= 0.45
epoch: 600 , mse_ 1249.793 , loss_anch 1249.793 tau-train= 0.67
epoch: 800 , mse_ 1085.248 , loss_anch 1085.248 tau-train= 0.75
epoch: 1000 , mse_ 960.775 , loss_anch 960.775 tau-train= 0.85

NN: 4
epoch: 200 , mse_ 2109.797 , loss_anch 2109.797 tau-train= 0.24
epoch: 400 , mse_ 1518.673 , loss_anch 1518.673 tau-train= 0.27
epoch: 600 , mse_ 1359.339 , loss_anch 1359.339 tau-train= 0.53
epoch: 800 , mse_ 1272.257 , loss_anch 1272.257 tau-train= 0.53
epoch: 1000 , mse_ 1166.428 , loss_anch 1166.428 tau-train= 0.53
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1077)__call__()
-> print(f"tau-train-ens={_tau}")
(Pdb) 0.4909090909090909
(Pdb) array([[ 2.18002791e+00],
       [ 2.95613556e+00],
       [ 3.05312478e+00],
       [ 2.95220603e+00],
       [ 2.21423706e+00],
       [-4.69361915e+00],
       [ 4.30607437e+00],
       [ 3.57101989e+00],
       [ 1.02468745e+00],
       [ 3.73852818e-01],
       [ 2.67602097e+00],
       [-5.14425154e-02],
       [-3.59665534e-01],
       [ 6.03944919e-02],
       [ 3.94373099e+00],
       [ 2.72148454e+00],
       [ 2.45911820e+00],
       [ 2.32992741e+00],
       [ 2.21391927e+00],
       [-2.31580138e+00],
       [-8.99283587e+00],
       [ 6.62164890e-01],
       [ 6.21466202e-05],
       [-3.93613584e+00],
       [-9.68598305e+00],
       [-1.30232887e+00],
       [-4.44888129e-01],
       [-2.86839471e+00],
       [-2.54937850e+00],
       [-2.49016925e+00],
       [-3.04598617e+00],
       [-3.26686683e+00],
       [-4.88509236e+00],
       [ 6.00894048e-01],
       [ 8.47053733e-02],
       [-3.93266787e+00],
       [-4.01088436e+00],
       [-4.17560973e+00],
       [-4.60134638e+00]])
(Pdb) tau-train-ens=0.4909090909090909
tau-archive=0.4909090909090909
eval=6 | not-eval=0 | tau= 0.64 | n_kendall=12 | std(means)/mean(stds)=  0.08 | std(means)=7.97e+00 | mean(stds)=1.06e+02
delta_f=2.9e-02
tau-population= 0.33 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=10.150144202117083 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 3201.092 , loss_anch 3201.092 tau-train= 0.64
epoch: 400 , mse_ 2868.686 , loss_anch 2868.686 tau-train= 0.64
epoch: 600 , mse_ 2566.016 , loss_anch 2566.016 tau-train= 0.78
epoch: 800 , mse_ 2208.517 , loss_anch 2208.517 tau-train= 0.82
epoch: 1000 , mse_ 1757.754 , loss_anch 1757.754 tau-train= 0.82

NN: 1
epoch: 200 , mse_ 1995.214 , loss_anch 1995.214 tau-train= 0.82
epoch: 400 , mse_ 1207.003 , loss_anch 1207.003 tau-train= 0.93
epoch: 600 , mse_ 805.275 , loss_anch 805.275 tau-train= 0.96
epoch: 800 , mse_ 537.94 , loss_anch 537.94 tau-train= 0.89
epoch: 1000 , mse_ 353.227 , loss_anch 353.227 tau-train= 0.89

NN: 2
epoch: 200 , mse_ 2512.818 , loss_anch 2512.818 tau-train= 0.56
epoch: 400 , mse_ 1740.273 , loss_anch 1740.273 tau-train= 0.71
epoch: 600 , mse_ 1545.729 , loss_anch 1545.729 tau-train= 0.82
epoch: 800 , mse_ 1475.913 , loss_anch 1475.913 tau-train= 0.85
epoch: 1000 , mse_ 1435.544 , loss_anch 1435.544 tau-train= 0.85

NN: 3
epoch: 200 , mse_ 2647.794 , loss_anch 2647.794 tau-train= 0.71
epoch: 400 , mse_ 1409.653 , loss_anch 1409.653 tau-train= 0.93
epoch: 600 , mse_ 876.527 , loss_anch 876.527 tau-train= 0.93
epoch: 800 , mse_ 591.946 , loss_anch 591.946 tau-train= 0.93
epoch: 1000 , mse_ 388.28 , loss_anch 388.28 tau-train= 0.96

NN: 4
epoch: 200 , mse_ 2157.984 , loss_anch 2157.984 tau-train= 0.75
epoch: 400 , mse_ 1296.83 , loss_anch 1296.83 tau-train= 0.85
epoch: 600 , mse_ 894.139 , loss_anch 894.139 tau-train= 0.93
epoch: 800 , mse_ 532.542 , loss_anch 532.542 tau-train= 0.96
epoch: 1000 , mse_ 300.226 , loss_anch 300.226 tau-train= 0.96
tau-train-ens=0.8909090909090909
tau-archive=0.8909090909090909
eval=1 | not-eval=5 | tau= 0.91 | n_kendall=12 | std(means)/mean(stds)=  0.19 | std(means)=3.06e+00 | mean(stds)=1.61e+01
delta_f=2.9e-02
tau-population= 0.33 | tau-pop-offset= 0.20 | final-target-hit=False
subset-max-norm=11.659732148962528 | norm-max=12.13941703508117
subset-idx-size=39

NN: 0
epoch: 200 , mse_ 4358.809 , loss_anch 4358.809 tau-train= 0.53
epoch: 400 , mse_ 3167.485 , loss_anch 3167.485 tau-train= 0.60
epoch: 600 , mse_ 2375.479 , loss_anch 2375.479 tau-train= 0.67
epoch: 800 , mse_ 2159.547 , loss_anch 2159.547 tau-train= 0.64
epoch: 1000 , mse_ 1979.45 , loss_anch 1979.45 tau-train= 0.71

NN: 1
epoch: 200 , mse_ 2348.934 , loss_anch 2348.934 tau-train= 0.67
epoch: 400 , mse_ 1511.162 , loss_anch 1511.162 tau-train= 0.85
epoch: 600 , mse_ 1225.891 , loss_anch 1225.891 tau-train= 0.93
epoch: 800 , mse_ 1060.579 , loss_anch 1060.579 tau-train= 0.89
epoch: 1000 , mse_ 931.647 , loss_anch 931.647 tau-train= 0.85

NN: 2
epoch: 200 , mse_ 3325.929 , loss_anch 3325.929 tau-train= 0.64
epoch: 400 , mse_ 2063.496 , loss_anch 2063.496 tau-train= 0.71
epoch: 600 , mse_ 1672.044 , loss_anch 1672.044 tau-train= 0.78
epoch: 800 , mse_ 1441.133 , loss_anch 1441.133 tau-train= 0.85
epoch: 1000 , mse_ 1281.306 , loss_anch 1281.306 tau-train= 0.89

NN: 3
epoch: 200 , mse_ 3409.22 , loss_anch 3409.22 tau-train= 0.71
epoch: 400 , mse_ 1703.12 , loss_anch 1703.12 tau-train= 0.78
epoch: 600 , mse_ 1135.199 , loss_anch 1135.199 tau-train= 0.93
epoch: 800 , mse_ 884.867 , loss_anch 884.867 tau-train= 0.93
epoch: 1000 , mse_ 718.141 , loss_anch 718.141 tau-train= 0.89

NN: 4
epoch: 200 , mse_ 3151.46 , loss_anch 3151.46 tau-train= 0.71
epoch: 400 , mse_ 1973.106 , loss_anch 1973.106 tau-train= 0.82
epoch: 600 , mse_ 1239.366 , loss_anch 1239.366 tau-train= 0.89
epoch: 800 , mse_ 938.938 , loss_anch 938.938 tau-train= 0.93
epoch: 1000 , mse_ 709.414 , loss_anch 709.414 tau-train= 0.89
tau-train-ens=0.8545454545454545
tau-archive=0.8545454545454545
eval=1 | not-eval=5 | tau= 0.88 | n_kendall=12 | std(means)/mean(stds)=  0.08 | std(means)=9.36e-01 | mean(stds)=1.18e+01
delta_f=2.9e-02
tau-population= 0.33 | tau-pop-offset= 0.47 | final-target-hit=False
subset-max-norm=11.641237638961572 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 4277.938 , loss_anch 4277.938 tau-train= 0.67
epoch: 400 , mse_ 3280.205 , loss_anch 3280.205 tau-train= 0.82
epoch: 600 , mse_ 2687.784 , loss_anch 2687.784 tau-train= 0.82
epoch: 800 , mse_ 2205.002 , loss_anch 2205.002 tau-train= 0.78
epoch: 1000 , mse_ 1836.007 , loss_anch 1836.007 tau-train= 0.85

NN: 1
epoch: 200 , mse_ 2102.732 , loss_anch 2102.732 tau-train= 0.85
epoch: 400 , mse_ 1393.939 , loss_anch 1393.939 tau-train= 0.93
epoch: 600 , mse_ 1130.552 , loss_anch 1130.552 tau-train= 0.89
epoch: 800 , mse_ 948.965 , loss_anch 948.965 tau-train= 0.85
epoch: 1000 , mse_ 784.242 , loss_anch 784.242 tau-train= 0.89

NN: 2
epoch: 200 , mse_ 3304.404 , loss_anch 3304.404 tau-train= 0.71
epoch: 400 , mse_ 2613.983 , loss_anch 2613.983 tau-train= 0.82
epoch: 600 , mse_ 2138.127 , loss_anch 2138.127 tau-train= 0.71
epoch: 800 , mse_ 1898.513 , loss_anch 1898.513 tau-train= 0.78
epoch: 1000 , mse_ 1731.398 , loss_anch 1731.398 tau-train= 0.82

NN: 3
epoch: 200 , mse_ 3510.168 , loss_anch 3510.168 tau-train= 0.82
epoch: 400 , mse_ 2379.301 , loss_anch 2379.301 tau-train= 0.85
epoch: 600 , mse_ 1580.214 , loss_anch 1580.214 tau-train= 0.93
epoch: 800 , mse_ 1161.752 , loss_anch 1161.752 tau-train= 1.00
epoch: 1000 , mse_ 965.187 , loss_anch 965.187 tau-train= 0.96

NN: 4
epoch: 200 , mse_ 1585.274 , loss_anch 1585.274 tau-train= 0.89
epoch: 400 , mse_ 1245.141 , loss_anch 1245.141 tau-train= 0.89
epoch: 600 , mse_ 1053.036 , loss_anch 1053.036 tau-train= 0.93
epoch: 800 , mse_ 868.219 , loss_anch 868.219 tau-train= 0.89
epoch: 1000 , mse_ 715.435 , loss_anch 715.435 tau-train= 0.93
tau-train-ens=0.9636363636363636
tau-archive=0.9636363636363636
eval=6 | not-eval=0 | tau= 0.60 | n_kendall=12 | std(means)/mean(stds)=  0.13 | std(means)=1.61e+00 | mean(stds)=1.21e+01
delta_f=2.9e-02
tau-population= 0.33 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=6.666704637062396 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 4930.092 , loss_anch 4930.092 tau-train= 0.24
epoch: 400 , mse_ 4271.798 , loss_anch 4271.798 tau-train= 0.31
epoch: 600 , mse_ 3596.292 , loss_anch 3596.292 tau-train= 0.45
epoch: 800 , mse_ 2229.59 , loss_anch 2229.59 tau-train= 0.49
epoch: 1000 , mse_ 1552.012 , loss_anch 1552.012 tau-train= 0.75

NN: 1
epoch: 200 , mse_ 1639.55 , loss_anch 1639.55 tau-train= 0.85
epoch: 400 , mse_ 961.452 , loss_anch 961.452 tau-train= 0.96
epoch: 600 , mse_ 677.821 , loss_anch 677.821 tau-train= 0.96
epoch: 800 , mse_ 493.344 , loss_anch 493.344 tau-train= 0.93
epoch: 1000 , mse_ 395.735 , loss_anch 395.735 tau-train= 0.96

NN: 2
epoch: 200 , mse_ 2600.296 , loss_anch 2600.296 tau-train= 0.60
epoch: 400 , mse_ 1688.852 , loss_anch 1688.852 tau-train= 0.71
epoch: 600 , mse_ 1489.533 , loss_anch 1489.533 tau-train= 0.82
epoch: 800 , mse_ 1384.943 , loss_anch 1384.943 tau-train= 0.85
epoch: 1000 , mse_ 1265.198 , loss_anch 1265.198 tau-train= 0.93

NN: 3
epoch: 200 , mse_ 1878.196 , loss_anch 1878.196 tau-train= 1.00
epoch: 400 , mse_ 901.575 , loss_anch 901.575 tau-train= 0.93
epoch: 600 , mse_ 637.564 , loss_anch 637.564 tau-train= 1.00
epoch: 800 , mse_ 488.265 , loss_anch 488.265 tau-train= 0.96
epoch: 1000 , mse_ 365.599 , loss_anch 365.599 tau-train= 0.93

NN: 4
epoch: 200 , mse_ 1509.666 , loss_anch 1509.666 tau-train= 1.00
epoch: 400 , mse_ 843.369 , loss_anch 843.369 tau-train= 0.93
epoch: 600 , mse_ 474.789 , loss_anch 474.789 tau-train= 0.96
epoch: 800 , mse_ 233.064 , loss_anch 233.064 tau-train= 0.96
epoch: 1000 , mse_ 101.196 , loss_anch 101.196 tau-train= 0.93
tau-train-ens=1.0
tau-archive=1.0
eval=1 | not-eval=5 | tau= 0.94 | n_kendall=12 | std(means)/mean(stds)=  0.24 | std(means)=7.69e-01 | mean(stds)=3.22e+00
delta_f=2.9e-02
tau-population= 1.00 | tau-pop-offset= 0.87 | final-target-hit=False
subset-max-norm=9.698046598707004 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 4451.987 , loss_anch 4451.987 tau-train= 0.38
epoch: 400 , mse_ 2356.802 , loss_anch 2356.802 tau-train= 0.49
epoch: 600 , mse_ 1890.757 , loss_anch 1890.757 tau-train= 0.67
epoch: 800 , mse_ 1766.931 , loss_anch 1766.931 tau-train= 0.75
epoch: 1000 , mse_ 1664.553 , loss_anch 1664.553 tau-train= 0.85

NN: 1
epoch: 200 , mse_ 1827.638 , loss_anch 1827.638 tau-train= 0.82
epoch: 400 , mse_ 1291.197 , loss_anch 1291.197 tau-train= 0.93
epoch: 600 , mse_ 1114.04 , loss_anch 1114.04 tau-train= 0.93
epoch: 800 , mse_ 1006.501 , loss_anch 1006.501 tau-train= 0.96
epoch: 1000 , mse_ 865.182 , loss_anch 865.182 tau-train= 0.96

NN: 2
epoch: 200 , mse_ 2268.035 , loss_anch 2268.035 tau-train= 0.49
epoch: 400 , mse_ 1807.09 , loss_anch 1807.09 tau-train= 0.75
epoch: 600 , mse_ 1563.957 , loss_anch 1563.957 tau-train= 0.82
epoch: 800 , mse_ 1447.764 , loss_anch 1447.764 tau-train= 0.85
epoch: 1000 , mse_ 1379.006 , loss_anch 1379.006 tau-train= 0.89

NN: 3
epoch: 200 , mse_ 2788.926 , loss_anch 2788.926 tau-train= 0.85
epoch: 400 , mse_ 1350.825 , loss_anch 1350.825 tau-train= 0.96
epoch: 600 , mse_ 798.384 , loss_anch 798.384 tau-train= 0.96
epoch: 800 , mse_ 518.822 , loss_anch 518.822 tau-train= 0.96
epoch: 1000 , mse_ 355.243 , loss_anch 355.243 tau-train= 0.96

NN: 4
epoch: 200 , mse_ 1373.434 , loss_anch 1373.434 tau-train= 0.96
epoch: 400 , mse_ 954.206 , loss_anch 954.206 tau-train= 0.96
epoch: 600 , mse_ 717.693 , loss_anch 717.693 tau-train= 0.93
epoch: 800 , mse_ 525.227 , loss_anch 525.227 tau-train= 0.96
epoch: 1000 , mse_ 379.465 , loss_anch 379.465 tau-train= 0.96
tau-train-ens=0.9272727272727274
tau-archive=0.9272727272727274
eval=6 | not-eval=0 | tau= 0.29 | n_kendall=12 | std(means)/mean(stds)=  0.15 | std(means)=3.92e-01 | mean(stds)=2.70e+00
delta_f=2.9e-02
tau-population=-0.07 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) array([[-54.37864188],
       [-53.27837773],
       [-54.29114397],
       [-53.40865967],
       [-52.26856884],
       [-54.24637855]])
(Pdb) array([[-54.34052454],
       [-53.61339054],
       [-54.3355653 ],
       [-54.83861524],
       [-54.49424184],
       [-54.71073688]])
(Pdb) -54.37864187607973
(Pdb) -54.8386152384105
(Pdb) subset-max-norm=10.072331578208432 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 4390.966 , loss_anch 4390.966 tau-train= 0.20
epoch: 400 , mse_ 4031.76 , loss_anch 4031.76 tau-train=-0.02
epoch: 600 , mse_ 3801.984 , loss_anch 3801.984 tau-train= 0.05
epoch: 800 , mse_ 3548.617 , loss_anch 3548.617 tau-train= 0.20
epoch: 1000 , mse_ 3285.399 , loss_anch 3285.399 tau-train= 0.24

NN: 1
epoch: 200 , mse_ 1269.423 , loss_anch 1269.423 tau-train= 0.78
epoch: 400 , mse_ 808.537 , loss_anch 808.537 tau-train= 0.96
epoch: 600 , mse_ 572.119 , loss_anch 572.119 tau-train= 0.93
epoch: 800 , mse_ 334.581 , loss_anch 334.581 tau-train= 0.96
epoch: 1000 , mse_ 250.721 , loss_anch 250.721 tau-train= 0.96

NN: 2
epoch: 200 , mse_ 2374.853 , loss_anch 2374.853 tau-train= 0.20
epoch: 400 , mse_ 1779.933 , loss_anch 1779.933 tau-train= 0.67
epoch: 600 , mse_ 1440.292 , loss_anch 1440.292 tau-train= 0.78
epoch: 800 , mse_ 1218.622 , loss_anch 1218.622 tau-train= 0.82
epoch: 1000 , mse_ 1071.995 , loss_anch 1071.995 tau-train= 0.85

NN: 3
epoch: 200 , mse_ 1683.999 , loss_anch 1683.999 tau-train= 0.78
epoch: 400 , mse_ 874.868 , loss_anch 874.868 tau-train= 0.82
epoch: 600 , mse_ 504.503 , loss_anch 504.503 tau-train= 0.85
epoch: 800 , mse_ 349.335 , loss_anch 349.335 tau-train= 0.85
epoch: 1000 , mse_ 266.001 , loss_anch 266.001 tau-train= 0.89

NN: 4
epoch: 200 , mse_ 1530.341 , loss_anch 1530.341 tau-train= 0.71
epoch: 400 , mse_ 778.607 , loss_anch 778.607 tau-train= 0.89
epoch: 600 , mse_ 436.421 , loss_anch 436.421 tau-train= 0.93
epoch: 800 , mse_ 267.449 , loss_anch 267.449 tau-train= 0.96
epoch: 1000 , mse_ 208.789 , loss_anch 208.789 tau-train= 0.93
tau-train-ens=0.7818181818181819
tau-archive=0.7818181818181819
eval=6 | not-eval=0 | tau= 0.60 | n_kendall=12 | std(means)/mean(stds)=  0.13 | std(means)=2.22e-01 | mean(stds)=1.69e+00
delta_f=2.2e-02
tau-population= 0.47 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=7.62097310805998 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1817.279 , loss_anch 1817.279 tau-train= 0.27
epoch: 400 , mse_ 1193.258 , loss_anch 1193.258 tau-train= 0.53
epoch: 600 , mse_ 941.627 , loss_anch 941.627 tau-train= 0.64
epoch: 800 , mse_ 805.245 , loss_anch 805.245 tau-train= 0.78
epoch: 1000 , mse_ 703.217 , loss_anch 703.217 tau-train= 0.75

NN: 1
epoch: 200 , mse_ 908.877 , loss_anch 908.877 tau-train= 0.64
epoch: 400 , mse_ 346.328 , loss_anch 346.328 tau-train= 0.82
epoch: 600 , mse_ 271.754 , loss_anch 271.754 tau-train= 0.93
epoch: 800 , mse_ 222.263 , loss_anch 222.263 tau-train= 0.89
epoch: 1000 , mse_ 184.254 , loss_anch 184.254 tau-train= 0.93

NN: 2
epoch: 200 , mse_ 1692.275 , loss_anch 1692.275 tau-train= 0.45
epoch: 400 , mse_ 979.711 , loss_anch 979.711 tau-train= 0.71
epoch: 600 , mse_ 660.326 , loss_anch 660.326 tau-train= 0.85
epoch: 800 , mse_ 489.418 , loss_anch 489.418 tau-train= 0.93
epoch: 1000 , mse_ 378.699 , loss_anch 378.699 tau-train= 0.89

NN: 3
epoch: 200 , mse_ 611.564 , loss_anch 611.564 tau-train= 0.75
epoch: 400 , mse_ 331.622 , loss_anch 331.622 tau-train= 0.82
epoch: 600 , mse_ 191.494 , loss_anch 191.494 tau-train= 0.85
epoch: 800 , mse_ 109.795 , loss_anch 109.795 tau-train= 0.93
epoch: 1000 , mse_ 69.984 , loss_anch 69.984 tau-train= 1.00

NN: 4
epoch: 200 , mse_ 749.446 , loss_anch 749.446 tau-train= 0.60
epoch: 400 , mse_ 414.204 , loss_anch 414.204 tau-train= 0.78
epoch: 600 , mse_ 294.062 , loss_anch 294.062 tau-train= 0.82
epoch: 800 , mse_ 226.899 , loss_anch 226.899 tau-train= 0.93
epoch: 1000 , mse_ 180.328 , loss_anch 180.328 tau-train= 0.93
tau-train-ens=0.8909090909090909
tau-archive=0.8909090909090909
eval=1 | not-eval=5 | tau= 0.91 | n_kendall=12 | std(means)/mean(stds)=  0.23 | std(means)=2.06e-01 | mean(stds)=9.00e-01
delta_f=2.2e-02
tau-population= 0.47 | tau-pop-offset= 0.33 | final-target-hit=False
subset-max-norm=7.104149354775897 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 2479.75 , loss_anch 2479.75 tau-train= 0.31
epoch: 400 , mse_ 2104.928 , loss_anch 2104.928 tau-train= 0.45
epoch: 600 , mse_ 1834.698 , loss_anch 1834.698 tau-train= 0.49
epoch: 800 , mse_ 1679.673 , loss_anch 1679.673 tau-train= 0.42
epoch: 1000 , mse_ 1549.424 , loss_anch 1549.424 tau-train= 0.45

NN: 1
epoch: 200 , mse_ 868.075 , loss_anch 868.075 tau-train= 0.71
epoch: 400 , mse_ 576.66 , loss_anch 576.66 tau-train= 0.78
epoch: 600 , mse_ 401.818 , loss_anch 401.818 tau-train= 0.89
epoch: 800 , mse_ 304.794 , loss_anch 304.794 tau-train= 0.96
epoch: 1000 , mse_ 255.908 , loss_anch 255.908 tau-train= 0.96

NN: 2
epoch: 200 , mse_ 1741.35 , loss_anch 1741.35 tau-train= 0.35
epoch: 400 , mse_ 1124.463 , loss_anch 1124.463 tau-train= 0.64
epoch: 600 , mse_ 752.162 , loss_anch 752.162 tau-train= 0.82
epoch: 800 , mse_ 582.592 , loss_anch 582.592 tau-train= 0.82
epoch: 1000 , mse_ 467.896 , loss_anch 467.896 tau-train= 0.82

NN: 3
epoch: 200 , mse_ 1068.071 , loss_anch 1068.071 tau-train= 0.71
epoch: 400 , mse_ 772.184 , loss_anch 772.184 tau-train= 0.78
epoch: 600 , mse_ 639.955 , loss_anch 639.955 tau-train= 0.82
epoch: 800 , mse_ 509.18 , loss_anch 509.18 tau-train= 0.85
epoch: 1000 , mse_ 410.117 , loss_anch 410.117 tau-train= 0.89

NN: 4
epoch: 200 , mse_ 859.29 , loss_anch 859.29 tau-train= 0.75
epoch: 400 , mse_ 589.808 , loss_anch 589.808 tau-train= 0.82
epoch: 600 , mse_ 396.202 , loss_anch 396.202 tau-train= 0.89
epoch: 800 , mse_ 252.964 , loss_anch 252.964 tau-train= 0.96
epoch: 1000 , mse_ 184.22 , loss_anch 184.22 tau-train= 0.96
tau-train-ens=0.8545454545454545
tau-archive=0.8545454545454545
eval=6 | not-eval=0 | tau= 0.64 | n_kendall=12 | std(means)/mean(stds)=  0.31 | std(means)=2.11e-01 | mean(stds)=6.79e-01
delta_f=2.2e-02
tau-population= 0.73 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=4.695300961862543 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1873.816 , loss_anch 1873.816 tau-train= 0.20
epoch: 400 , mse_ 1445.361 , loss_anch 1445.361 tau-train= 0.45
epoch: 600 , mse_ 1115.233 , loss_anch 1115.233 tau-train= 0.56
epoch: 800 , mse_ 962.019 , loss_anch 962.019 tau-train= 0.53
epoch: 1000 , mse_ 894.727 , loss_anch 894.727 tau-train= 0.53

NN: 1
epoch: 200 , mse_ 851.21 , loss_anch 851.21 tau-train= 0.49
epoch: 400 , mse_ 525.554 , loss_anch 525.554 tau-train= 0.53
epoch: 600 , mse_ 326.116 , loss_anch 326.116 tau-train= 0.67
epoch: 800 , mse_ 188.501 , loss_anch 188.501 tau-train= 0.85
epoch: 1000 , mse_ 107.579 , loss_anch 107.579 tau-train= 0.85

NN: 2
epoch: 200 , mse_ 1921.59 , loss_anch 1921.59 tau-train= 0.24
epoch: 400 , mse_ 1524.931 , loss_anch 1524.931 tau-train= 0.45
epoch: 600 , mse_ 1149.742 , loss_anch 1149.742 tau-train= 0.56
epoch: 800 , mse_ 978.802 , loss_anch 978.802 tau-train= 0.56
epoch: 1000 , mse_ 860.479 , loss_anch 860.479 tau-train= 0.53

NN: 3
epoch: 200 , mse_ 912.151 , loss_anch 912.151 tau-train= 0.45
epoch: 400 , mse_ 491.303 , loss_anch 491.303 tau-train= 0.60
epoch: 600 , mse_ 299.125 , loss_anch 299.125 tau-train= 0.67
epoch: 800 , mse_ 153.638 , loss_anch 153.638 tau-train= 0.85
epoch: 1000 , mse_ 83.1 , loss_anch 83.1 tau-train= 0.96

NN: 4
epoch: 200 , mse_ 683.447 , loss_anch 683.447 tau-train= 0.45
epoch: 400 , mse_ 388.168 , loss_anch 388.168 tau-train= 0.71
epoch: 600 , mse_ 231.803 , loss_anch 231.803 tau-train= 0.78
epoch: 800 , mse_ 111.329 , loss_anch 111.329 tau-train= 0.85
epoch: 1000 , mse_ 57.836 , loss_anch 57.836 tau-train= 0.96
tau-train-ens=0.7818181818181819
tau-archive=0.7818181818181819
eval=6 | not-eval=0 | tau= 0.11 | n_kendall=12 | std(means)/mean(stds)=  0.23 | std(means)=1.67e-01 | mean(stds)=7.35e-01
delta_f=1.4e-02
tau-population= 0.20 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) *** NameError: name 'values_true' is not defined
(Pdb) -54.926246050380364
(Pdb) *** AttributeError: 'Prediction' object has no attribute 'min'
(Pdb) *** AttributeError: 'Prediction' object has no attribute 'min'
(Pdb) -54.905254497683586
(Pdb) --Call--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1555)surrogate_model()
-> @wraps(model)
(Pdb) 1555 ->	        @wraps(model)
1556 	        def surrogate_model(
1557 	            features: np.ndarray[tuple[N, DIM], np.dtype[np.float64]],
1558 	        ) -> Prediction[N]:
1559 	            features_transf = x_transf.transform(features)
1560 	            pred_transf = model(features_transf)
1561 	            return Prediction(
1562 	                y_transf.transform_inv(pred_transf.mean),
1563 	                y_transf.transform_inv_std(pred_transf.std),
1564 	            )
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1559)surrogate_model()
-> features_transf = x_transf.transform(features)
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1560)surrogate_model()
-> pred_transf = model(features_transf)
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1561)surrogate_model()
-> return Prediction(
(Pdb) Prediction(mean=array([[ 0.2541698 ],
       [-0.70916254],
       [-2.33473935],
       [-1.61556707],
       [-1.72979682],
       [-2.98014627]]), std=array([[0.49122921],
       [0.3175376 ],
       [0.67746159],
       [0.66801261],
       [0.16945754],
       [1.16089131]]))
(Pdb) *** NameError: name 'y_train' is not defined
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1562)surrogate_model()
-> y_transf.transform_inv(pred_transf.mean),
(Pdb) --Call--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1459)transform_inv()
-> def transform_inv(
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1462)transform_inv()
-> return np.e**data * self.__scale - self.__improvement + self.__shift
(Pdb) ['_MinAdjustedLog__improvement', '_MinAdjustedLog__min_offset', '_MinAdjustedLog__scale', '_MinAdjustedLog__shift', '__abstractmethods__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', 'transform', 'transform_inv', 'transform_inv_std']
(Pdb) 0.39025140189809093
(Pdb) 0.007132388048859184
(Pdb) -54.917941185050445
(Pdb) -54.925073573099304
(Pdb) 1459 	    def transform_inv(
1460 	        self, data: np.ndarray[S, dtype[float64]], /
1461 	    ) -> np.ndarray[S, dtype[float64]]:
1462 ->	        return np.e**data * self.__scale - self.__improvement + self.__shift
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1462)transform_inv()->array([[-54.4...54.9052545 ]])
-> return np.e**data * self.__scale - self.__improvement + self.__shift
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1563)surrogate_model()
-> y_transf.transform_inv_std(pred_transf.std),
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1561)surrogate_model()
-> return Prediction(
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1561)surrogate_model()->Prediction(me...1.245986  ]]))
-> return Prediction(
(Pdb) 1555 	        @wraps(model)
1556 	        def surrogate_model(
1557 	            features: np.ndarray[tuple[N, DIM], np.dtype[np.float64]],
1558 	        ) -> Prediction[N]:
1559 	            features_transf = x_transf.transform(features)
1560 	            pred_transf = model(features_transf)
1561 ->	            return Prediction(
1562 	                y_transf.transform_inv(pred_transf.mean),
1563 	                y_transf.transform_inv_std(pred_transf.std),
1564 	            )
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1858)__call__()
-> return ValuesAndEvaluatedIdx(values, np.flatnonzero(evaluated).astype(np.uint))
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1858)__call__()->ValuesAndEval...dtype=uint64))
-> return ValuesAndEvaluatedIdx(values, np.flatnonzero(evaluated).astype(np.uint))
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1914)get_values_and_eval_idx()->ValuesAndEval...dtype=uint64))
-> evolution_control(
(Pdb) 1910 	        def get_values_and_eval_idx(
1911 	            problem, es, points, archive
1912 	        ) -> ValuesAndEvaluatedIdx:
1913 	            return (
1914 ->	                evolution_control(
1915 	                    model=surrogate(
1916 	                        x_train=archive.x, y_train=archive.y, x_test=points, es=es
1917 	                    ),
1918 	                    points=points,
1919 	                    problem=problem,
1920 	                    archive=archive,
1921 	                )
1922 	                if archive.x.size > n_min
1923 	                else evaluate_all(
1924 	                    model=predict_zeros_and_ones,
1925 	                    points=points,
1926 	                    problem=problem,
1927 	                    archive=archive,
1928 	                )
1929 	            )
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1950)seek_minimum()
-> if sort_archive:
(Pdb) 1893 	def seek_minimum(
1894 	    problem: Problem,
1895 	    *,
1896 	    es: Cma,
1897 	    surrogate_and_ec: Optional[SurrogateAndEc] = None,
1898 	    sort_archive=True,
1899 	    log: Optional[Callable] = None,  # TODO: Log Protocol
1900 	    verbose=False,
1901 	) -> Archive:
1902 	    t_0 = time.perf_counter()
1903 	    if verbose:
1904 	        print('__'.join([str(i) for i in (problem, es, surr_and_ec)]))
1905 	
1906 	    if surrogate_and_ec is not None:
1907 	        surrogate, evolution_control, get_n_min = surrogate_and_ec
1908 	        n_min = get_n_min(dim=problem.dimension)
1909 	
1910 	        def get_values_and_eval_idx(
1911 	            problem, es, points, archive
1912 	        ) -> ValuesAndEvaluatedIdx:
1913 	            return (
1914 	                evolution_control(
1915 	                    model=surrogate(
1916 	                        x_train=archive.x, y_train=archive.y, x_test=points, es=es
1917 	                    ),
1918 	                    points=points,
1919 	                    problem=problem,
1920 	                    archive=archive,
1921 	                )
1922 	                if archive.x.size > n_min
1923 	                else evaluate_all(
1924 	                    model=predict_zeros_and_ones,
1925 	                    points=points,
1926 	                    problem=problem,
1927 	                    archive=archive,
1928 	                )
1929 	            )
1930 	    else:
1931 	
1932 	        def get_values_and_eval_idx(
1933 	            problem, es, points, archive
1934 	        ) -> ValuesAndEvaluatedIdx:
1935 	            return evaluate_all(
1936 	                model=predict_zeros_and_ones,
1937 	                points=points,
1938 	                problem=problem,
1939 	                archive=archive,
1940 	            )
1941 	
1942 	    archive = Archive(np.empty((0, problem.dimension)), np.empty((0, 1)))
1943 	
1944 	    end = problem.final_target_hit or problem.all_evals_used
1945 	    while not end:
1946 	        points = es.ask()
1947 	
1948 	        values, eval_idx = get_values_and_eval_idx(problem, es, points, archive)
1949 	
1950 ->	        if sort_archive:
1951 	            eval_idx = eval_idx[values.squeeze()[eval_idx].argsort()[::-1]]
1952 	
1953 	        archive = Archive(
1954 	            np.concatenate((archive.x, points[eval_idx])),
1955 	            np.concatenate((archive.y, values[eval_idx])),
1956 	        )
1957 	        if end := problem.final_target_hit or problem.all_evals_used:
1958 	            break
1959 	        es.tell(points, values)
1960 	
1961 	    t = time.perf_counter() - t_0
1962 	    if log is not None:
1963 	        log(
1964 	            problem=problem,
1965 	            es=es,
1966 	            surrogate_and_ec=surrogate_and_ec,
1967 	            secs=t,
1968 	        )
1969 	
1970 	    return archive
(Pdb) array([[ 5.03120405e+06],
       [ 2.87871406e+06],
       [ 2.05881880e+06],
       [ 1.96398048e+06],
       [ 1.36194964e+06],
       [ 2.31937753e+05],
       [ 4.83309208e+05],
       [ 3.34342465e+04],
       [ 1.19252745e+05],
       [ 3.98305276e+06],
       [ 4.82536966e+05],
       [ 3.24793067e+05],
       [ 1.86580035e+05],
       [ 2.88916901e+04],
       [ 2.15726854e+04],
       [ 1.62553023e+05],
       [ 2.63616202e+04],
       [ 1.56670320e+02],
       [ 3.33398665e+04],
       [ 4.04856242e+02],
       [ 4.51682976e+02],
       [ 4.03053113e+02],
       [ 3.87060521e+03],
       [ 1.64033608e+02],
       [-5.46933714e+01],
       [ 7.13160182e+03],
       [ 5.05880919e+03],
       [ 3.21503861e+03],
       [ 1.71850209e+03],
       [ 7.95403255e+02],
       [ 1.17257111e+01],
       [-2.01532287e+01],
       [ 2.92533476e+02],
       [-3.21945780e+01],
       [-3.82204199e+01],
       [-2.95063777e+01],
       [ 3.49339093e+03],
       [ 1.17946094e+03],
       [ 3.08694177e+02],
       [ 2.24784413e+02],
       [ 1.90886928e+02],
       [ 1.63964041e+02],
       [-5.25520011e+01],
       [-5.49093224e+01],
       [-8.53766638e+00],
       [-3.09938537e+01],
       [-5.44453523e+01],
       [-5.49108088e+01],
       [-4.84093267e+01],
       [-3.95840150e+01],
       [-5.35540509e+01],
       [-5.30436585e+01],
       [-5.29296768e+01],
       [-5.37750584e+01],
       [-5.40004447e+01],
       [-5.47315207e+01],
       [-1.12937820e+01],
       [-2.88811686e+01],
       [-5.44437301e+01],
       [-5.44789830e+01],
       [-5.45447916e+01],
       [-5.46722094e+01],
       [-3.73672804e+01],
       [-4.63316300e+01],
       [-4.66758614e+01],
       [-4.68314907e+01],
       [-5.17153885e+01],
       [-5.20780530e+01],
       [-5.45955601e+01],
       [-5.45684153e+01],
       [-4.72812098e+01],
       [-5.39249647e+01],
       [-5.40419751e+01],
       [-5.42541969e+01],
       [-5.44507762e+01],
       [-5.48573001e+01],
       [-5.49046877e+01],
       [-5.22685688e+01],
       [-5.32783777e+01],
       [-5.34086597e+01],
       [-5.42463785e+01],
       [-5.42911440e+01],
       [-5.43786419e+01],
       [-5.43444524e+01],
       [-5.45323307e+01],
       [-5.45946073e+01],
       [-5.46817796e+01],
       [-5.48595263e+01],
       [-5.49179412e+01],
       [-5.49025549e+01],
       [-5.39836058e+01],
       [-5.45230489e+01],
       [-5.47445246e+01],
       [-5.47573107e+01],
       [-5.48768063e+01],
       [-5.48949635e+01]])
(Pdb) subset-max-norm=3.789383332210259 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1392.321 , loss_anch 1392.321 tau-train= 0.24
epoch: 400 , mse_ 1221.345 , loss_anch 1221.345 tau-train= 0.35
epoch: 600 , mse_ 1033.501 , loss_anch 1033.501 tau-train= 0.27
epoch: 800 , mse_ 917.286 , loss_anch 917.286 tau-train= 0.35
epoch: 1000 , mse_ 860.291 , loss_anch 860.291 tau-train= 0.35

NN: 1
epoch: 200 , mse_ 800.313 , loss_anch 800.313 tau-train= 0.35
epoch: 400 , mse_ 473.565 , loss_anch 473.565 tau-train= 0.35
epoch: 600 , mse_ 336.971 , loss_anch 336.971 tau-train= 0.42
epoch: 800 , mse_ 222.204 , loss_anch 222.204 tau-train= 0.60
epoch: 1000 , mse_ 147.807 , loss_anch 147.807 tau-train= 0.71

NN: 2
epoch: 200 , mse_ 1227.149 , loss_anch 1227.149 tau-train= 0.38
epoch: 400 , mse_ 1008.522 , loss_anch 1008.522 tau-train= 0.35
epoch: 600 , mse_ 863.579 , loss_anch 863.579 tau-train= 0.24
epoch: 800 , mse_ 783.003 , loss_anch 783.003 tau-train= 0.27
epoch: 1000 , mse_ 735.723 , loss_anch 735.723 tau-train= 0.27

NN: 3
epoch: 200 , mse_ 961.56 , loss_anch 961.56 tau-train= 0.35
epoch: 400 , mse_ 580.91 , loss_anch 580.91 tau-train= 0.27
epoch: 600 , mse_ 382.213 , loss_anch 382.213 tau-train= 0.38
epoch: 800 , mse_ 255.61 , loss_anch 255.61 tau-train= 0.49
epoch: 1000 , mse_ 149.199 , loss_anch 149.199 tau-train= 0.75

NN: 4
epoch: 200 , mse_ 871.92 , loss_anch 871.92 tau-train= 0.31
epoch: 400 , mse_ 461.921 , loss_anch 461.921 tau-train= 0.35
epoch: 600 , mse_ 261.737 , loss_anch 261.737 tau-train= 0.56
epoch: 800 , mse_ 139.388 , loss_anch 139.388 tau-train= 0.75
epoch: 1000 , mse_ 74.029 , loss_anch 74.029 tau-train= 0.85
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1077)__call__()
-> print(f"tau-train-ens={_tau}")
(Pdb) 0.6727272727272727
(Pdb) 956  	    def __call__(
957  	        self,
958  	        *,
959  	        x_train: NDArray[np.float64],
960  	        y_train: NDArray[np.float64],
961  	        x_test: NDArray[np.float64],
962  	        weights: Optional[NDArray[np.float64]] = None,
963  	    ) -> Model:
964  	        data_noise = self.__data_noise
965  	        """Taken form `RAFs <https://github.com/YanasGH/RAFs/blob/6a0ec46a7d9cd830e7d8e74358643aee1f65323d/main_experiments/rafs.py#L94-L157>`_"""
966  	        X_train, y_train, X_val = x_train, y_train, x_test
967  	
968  	        n = X_train.shape[0]
969  	        x_dim = X_train.shape[1]
970  	        y_dim = y_train.shape[1]
971  	        if __debug__ and self.__debug:
972  	            _max_model_size = max(
973  	                x_test.shape[0], x_dim * (x_dim + 3) + 2
974  	            )
975  	            _n_kendall_archive = min(15, _max_model_size) - 1
976  	
977  	        n_ensembles = 5
978  	        hidden_size = 100
979  	        init_stddev_1_w = np.sqrt(10)
980  	        init_stddev_1_b = init_stddev_1_w  # set these equal
981  	        init_stddev_2_w = 1.0 / np.sqrt(hidden_size)  # normal scaling
982  	        lambda_anchor = data_noise / (
983  	            np.array([init_stddev_1_w, init_stddev_1_b, init_stddev_2_w]) ** 2
984  	        )
985  	
986  	        n_epochs = self.__epochs
987  	        learning_rate = 0.01
988  	
989  	        NNs = []
990  	        y_prior = []
991  	        tf.reset_default_graph()
992  	        sess = tf.Session()
993  	
994  	        # loop to initialise all ensemble members, get priors
995  	        for ens in range(0, n_ensembles):
996  	            NNs.append(
997  	                NN(
998  	                    x_dim,
999  	                    y_dim,
1000 	                    hidden_size,
1001 	                    init_stddev_1_w,
1002 	                    init_stddev_1_b,
1003 	                    init_stddev_2_w,
1004 	                    n,
1005 	                    learning_rate,
1006 	                    ens,
1007 	                )
1008 	            )
1009 	
1010 	            # initialise only unitialized variables - stops overwriting ensembles already created
1011 	            global_vars = tf.global_variables()
1012 	            is_not_initialized = sess.run(
1013 	                [tf.is_variable_initialized(var) for var in global_vars]
1014 	            )
1015 	            not_initialized_vars = [
1016 	                v for (v, f) in zip(global_vars, is_not_initialized) if not f
1017 	            ]
1018 	            if len(not_initialized_vars):
1019 	                sess.run(tf.variables_initializer(not_initialized_vars))
1020 	
1021 	            # do regularisation now that we've created initialisations
1022 	            NNs[ens].anchor(
1023 	                sess, lambda_anchor
1024 	            )  # Do that if you want to minimize the anchored loss
1025 	
1026 	            # save their priors
1027 	            y_prior.append(NNs[ens].predict(X_val, sess))
1028 	
1029 	        for ens in range(0, n_ensembles):
1030 	            feed_b = {}
1031 	            feed_b[NNs[ens].inputs] = X_train
1032 	            feed_b[NNs[ens].y_target] = y_train
1033 	            if __debug__ and self.__debug:
1034 	                print("\nNN:", ens)
1035 	
1036 	            ep_ = 0
1037 	            while ep_ < n_epochs:
1038 	                ep_ += 1
1039 	                blank = sess.run(NNs[ens].optimizer, feed_dict=feed_b)  # noqa: F841
1040 	                if ep_ % (n_epochs / 5) == 0:
1041 	                    loss_mse = sess.run(NNs[ens].mse_, feed_dict=feed_b)
1042 	                    loss_anch = sess.run(NNs[ens].loss_, feed_dict=feed_b)
1043 	                    if __debug__ and self.__debug:
1044 	                        print(
1045 	                            "epoch:",
1046 	                            ep_,
1047 	                            ", mse_",
1048 	                            np.round(loss_mse * 1e3, 3),
1049 	                            ", loss_anch",
1050 	                            np.round(loss_anch * 1e3, 3),
1051 	                            "tau-train={:>5.2f}".format(
1052 	                                kendalltau(
1053 	                                    y_train[-_n_kendall_archive:],  # pyright: ignore [reportOperatorIssue,reportPossiblyUnboundVariable]
1054 	                                    np.array(
1055 	                                        NNs[ens].predict(
1056 	                                            X_train[-_n_kendall_archive:],  # pyright: ignore [reportOperatorIssue,reportPossiblyUnboundVariable]
1057 	                                            sess,
1058 	                                        )
1059 	                                    ),
1060 	                                ).statistic
1061 	                            ),
1062 	                        )
1063 	                    # the anchored loss is minimized, but it's useful to keep an eye on mse too
1064 	
1065 	        if __debug__ and self.__debug:
1066 	            _tau = kendalltau(
1067 	                y_train[-_n_kendall_archive:],  # pyright: ignore [reportOperatorIssue,reportPossiblyUnboundVariable]
1068 	                np.mean(
1069 	                    np.array(
1070 	                        [nn.predict(X_train[-_n_kendall_archive:], sess) for nn in NNs]  # pyright: ignore [reportOperatorIssue,reportPossiblyUnboundVariable]
1071 	                    ),
1072 	                    axis=0,
1073 	                ),
1074 	            ).statistic
1075 	            if _tau < 0.7:
1076 	                breakpoint()
1077 ->	            print(f"tau-train-ens={_tau}")
1078 	
1079 	        def raf(features):
1080 	            y_pred = np.array([nn.predict(features, sess) for nn in NNs])
1081 	            return Prediction(
1082 	                np.mean(y_pred, axis=0),
1083 	                np.sqrt(np.square(np.std(y_pred, axis=0, ddof=1)) + data_noise),
1084 	            )
1085 	
1086 	        return raf
(Pdb) array([[-2.65343977],
       [ 0.31135367],
       [ 1.34878607],
       [ 1.66338919],
       [ 1.72192155],
       [-0.56806004],
       [ 0.31466413],
       [ 0.24012988],
       [ 0.08411448],
       [-0.31176768],
       [-0.05544186],
       [ 0.02158872],
       [ 1.0358809 ],
       [ 0.91269643],
       [ 0.64119824],
       [ 0.30020429],
       [-1.53435713],
       [-2.48478609],
       [ 0.65262436],
       [ 0.58536243],
       [ 0.4391897 ],
       [ 0.49887447],
       [ 0.11558486],
       [-0.05263532],
       [-0.34892988],
       [-1.56359835],
       [-3.07142627],
       [-2.41580463],
       [ 0.97604139],
       [ 0.13839892],
       [-0.63425266],
       [-0.70390898],
       [-1.82538442],
       [-2.20290393],
       [ 0.03218233],
       [ 0.02423548],
       [-1.21343177],
       [-1.83679866],
       [-1.96231584],
       [-3.76457345]])
(Pdb) 956  	    def __call__(
957  	        self,
958  	        *,
959  	        x_train: NDArray[np.float64],
960  	        y_train: NDArray[np.float64],
961  	        x_test: NDArray[np.float64],
962  	        weights: Optional[NDArray[np.float64]] = None,
963  	    ) -> Model:
964  	        data_noise = self.__data_noise
965  	        """Taken form `RAFs <https://github.com/YanasGH/RAFs/blob/6a0ec46a7d9cd830e7d8e74358643aee1f65323d/main_experiments/rafs.py#L94-L157>`_"""
966  	        X_train, y_train, X_val = x_train, y_train, x_test
967  	
968  	        n = X_train.shape[0]
969  	        x_dim = X_train.shape[1]
970  	        y_dim = y_train.shape[1]
971  	        if __debug__ and self.__debug:
972  	            _max_model_size = max(
973  	                x_test.shape[0], x_dim * (x_dim + 3) + 2
974  	            )
975  	            _n_kendall_archive = min(15, _max_model_size) - 1
976  	
977  	        n_ensembles = 5
978  	        hidden_size = 100
979  	        init_stddev_1_w = np.sqrt(10)
980  	        init_stddev_1_b = init_stddev_1_w  # set these equal
981  	        init_stddev_2_w = 1.0 / np.sqrt(hidden_size)  # normal scaling
982  	        lambda_anchor = data_noise / (
983  	            np.array([init_stddev_1_w, init_stddev_1_b, init_stddev_2_w]) ** 2
984  	        )
985  	
986  	        n_epochs = self.__epochs
987  	        learning_rate = 0.01
988  	
989  	        NNs = []
990  	        y_prior = []
991  	        tf.reset_default_graph()
992  	        sess = tf.Session()
993  	
994  	        # loop to initialise all ensemble members, get priors
995  	        for ens in range(0, n_ensembles):
996  	            NNs.append(
997  	                NN(
998  	                    x_dim,
999  	                    y_dim,
1000 	                    hidden_size,
1001 	                    init_stddev_1_w,
1002 	                    init_stddev_1_b,
1003 	                    init_stddev_2_w,
1004 	                    n,
1005 	                    learning_rate,
1006 	                    ens,
1007 	                )
1008 	            )
1009 	
1010 	            # initialise only unitialized variables - stops overwriting ensembles already created
1011 	            global_vars = tf.global_variables()
1012 	            is_not_initialized = sess.run(
1013 	                [tf.is_variable_initialized(var) for var in global_vars]
1014 	            )
1015 	            not_initialized_vars = [
1016 	                v for (v, f) in zip(global_vars, is_not_initialized) if not f
1017 	            ]
1018 	            if len(not_initialized_vars):
1019 	                sess.run(tf.variables_initializer(not_initialized_vars))
1020 	
1021 	            # do regularisation now that we've created initialisations
1022 	            NNs[ens].anchor(
1023 	                sess, lambda_anchor
1024 	            )  # Do that if you want to minimize the anchored loss
1025 	
1026 	            # save their priors
1027 	            y_prior.append(NNs[ens].predict(X_val, sess))
1028 	
1029 	        for ens in range(0, n_ensembles):
1030 	            feed_b = {}
1031 	            feed_b[NNs[ens].inputs] = X_train
1032 	            feed_b[NNs[ens].y_target] = y_train
1033 	            if __debug__ and self.__debug:
1034 	                print("\nNN:", ens)
1035 	
1036 	            ep_ = 0
1037 	            while ep_ < n_epochs:
1038 	                ep_ += 1
1039 	                blank = sess.run(NNs[ens].optimizer, feed_dict=feed_b)  # noqa: F841
1040 	                if ep_ % (n_epochs / 5) == 0:
1041 	                    loss_mse = sess.run(NNs[ens].mse_, feed_dict=feed_b)
1042 	                    loss_anch = sess.run(NNs[ens].loss_, feed_dict=feed_b)
1043 	                    if __debug__ and self.__debug:
1044 	                        print(
1045 	                            "epoch:",
1046 	                            ep_,
1047 	                            ", mse_",
1048 	                            np.round(loss_mse * 1e3, 3),
1049 	                            ", loss_anch",
1050 	                            np.round(loss_anch * 1e3, 3),
1051 	                            "tau-train={:>5.2f}".format(
1052 	                                kendalltau(
1053 	                                    y_train[-_n_kendall_archive:],  # pyright: ignore [reportOperatorIssue,reportPossiblyUnboundVariable]
1054 	                                    np.array(
1055 	                                        NNs[ens].predict(
1056 	                                            X_train[-_n_kendall_archive:],  # pyright: ignore [reportOperatorIssue,reportPossiblyUnboundVariable]
1057 	                                            sess,
1058 	                                        )
1059 	                                    ),
1060 	                                ).statistic
1061 	                            ),
1062 	                        )
1063 	                    # the anchored loss is minimized, but it's useful to keep an eye on mse too
1064 	
1065 	        if __debug__ and self.__debug:
1066 	            _tau = kendalltau(
1067 	                y_train[-_n_kendall_archive:],  # pyright: ignore [reportOperatorIssue,reportPossiblyUnboundVariable]
1068 	                np.mean(
1069 	                    np.array(
1070 	                        [nn.predict(X_train[-_n_kendall_archive:], sess) for nn in NNs]  # pyright: ignore [reportOperatorIssue,reportPossiblyUnboundVariable]
1071 	                    ),
1072 	                    axis=0,
1073 	                ),
1074 	            ).statistic
1075 	            if _tau < 0.7:
1076 	                breakpoint()
1077 ->	            print(f"tau-train-ens={_tau}")
1078 	
1079 	        def raf(features):
1080 	            y_pred = np.array([nn.predict(features, sess) for nn in NNs])
1081 	            return Prediction(
1082 	                np.mean(y_pred, axis=0),
1083 	                np.sqrt(np.square(np.std(y_pred, axis=0, ddof=1)) + data_noise),
1084 	            )
1085 	
1086 	        return raf
(Pdb) tau-train-ens=0.6727272727272727
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1079)__call__()
-> def raf(features):
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()
-> return raf
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()-><function Raf...x7fd7a57e9b80>
-> return raf
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1544)__call__()
-> model = (
(Pdb) 1500 	    def __call__(
1501 	        self,
1502 	        *,
1503 	        x_train: NDArray[np.float64],
1504 	        y_train: NDArray[np.float64],
1505 	        x_test: NDArray[np.float64],
1506 	        es: Cma,
1507 	    ) -> Model:
1508 	        subset_idx = self.__subset(
1509 	            x_train=x_train, y_train=y_train, x_test=x_test, es=es
1510 	        )
1511 	        subset_idx = np.sort(subset_idx)  # Important for some ECs
1512 	        if __debug__:
1513 	            print(f"subset-idx-size={subset_idx.size}")
1514 	        x_subset, y_subset = x_train[subset_idx], y_train[subset_idx]
1515 	
1516 	        weights = None
1517 	        # # Hansen's 20..1
1518 	        # weights = np.linspace(1, 20, y_subset.shape[0])[:, None]
1519 	        # # Experimental weights inversely proportional to the Mahalanobis norm
1520 	        # norms = np.array([es.mahalanobis_norm(x) for x in x_subset - es.mean])
1521 	        # weights = np.e ** (-norms*2)
1522 	
1523 	        x_transf = self.__x_transf(
1524 	            x_subset,
1525 	            x_train=x_subset,
1526 	            y_train=y_subset,
1527 	            x_test=x_test,
1528 	            es=es,
1529 	            weights=weights,
1530 	        )
1531 	        y_transf = self.__y_transf(
1532 	            y_subset,
1533 	            x_train=x_subset,
1534 	            y_train=y_subset,
1535 	            x_test=x_test,
1536 	            es=es,
1537 	            weights=weights,
1538 	        )
1539 	
1540 	        x_train_transf = x_transf.transform(x_subset)
1541 	        y_train_transf = y_transf.transform(y_subset)
1542 	        x_test_transf = x_transf.transform(x_test)
1543 	
1544 ->	        model = (
1545 	            self.__model(
1546 	                x_train=x_train_transf,
1547 	                y_train=y_train_transf,
1548 	                x_test=x_test_transf,
1549 	                weights=weights,
1550 	            )
1551 	            if isinstance(self.__model, ModelFactory)
1552 	            else self.__model
1553 	        )
1554 	
1555 	        @wraps(model)
1556 	        def surrogate_model(
1557 	            features: np.ndarray[tuple[N, DIM], np.dtype[np.float64]],
1558 	        ) -> Prediction[N]:
1559 	            features_transf = x_transf.transform(features)
1560 	            pred_transf = model(features_transf)
1561 	            return Prediction(
1562 	                y_transf.transform_inv(pred_transf.mean),
1563 	                y_transf.transform_inv_std(pred_transf.std),
1564 	            )
1565 	
1566 	        return surrogate_model
(Pdb) array([[-54.90932239],
       [-54.44535226],
       [-53.55405089],
       [-53.04365851],
       [-52.92967684],
       [-54.73152067],
       [-54.4437301 ],
       [-54.47898298],
       [-54.54479158],
       [-54.67220936],
       [-54.59556007],
       [-54.56841534],
       [-53.92496466],
       [-54.04197515],
       [-54.25419694],
       [-54.45077623],
       [-54.85730007],
       [-54.90468766],
       [-54.24637855],
       [-54.29114397],
       [-54.37864188],
       [-54.34445243],
       [-54.53233066],
       [-54.59460734],
       [-54.68177962],
       [-54.85952627],
       [-54.91794119],
       [-54.90255493],
       [-53.98360577],
       [-54.52304891],
       [-54.74452465],
       [-54.75731069],
       [-54.87680627],
       [-54.89496351],
       [-54.56451602],
       [-54.56744498],
       [-54.82806814],
       [-54.87746164],
       [-54.88419585],
       [-54.92624605]])
(Pdb) tau-archive=0.6727272727272727
eval=6 | not-eval=0 | tau= 0.60 | n_kendall=12 | std(means)/mean(stds)=  0.06 | std(means)=1.22e-01 | mean(stds)=2.22e+00
delta_f=1.4e-02
tau-population= 0.47 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=4.4339490538818325 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1275.822 , loss_anch 1275.822 tau-train=-0.27
epoch: 400 , mse_ 1114.553 , loss_anch 1114.553 tau-train=-0.09
epoch: 600 , mse_ 987.555 , loss_anch 987.555 tau-train= 0.09
epoch: 800 , mse_ 889.972 , loss_anch 889.972 tau-train= 0.13
epoch: 1000 , mse_ 819.04 , loss_anch 819.04 tau-train= 0.27

NN: 1
epoch: 200 , mse_ 670.886 , loss_anch 670.886 tau-train= 0.31
epoch: 400 , mse_ 470.843 , loss_anch 470.843 tau-train= 0.64
epoch: 600 , mse_ 323.355 , loss_anch 323.355 tau-train= 0.75
epoch: 800 , mse_ 164.983 , loss_anch 164.983 tau-train= 0.89
epoch: 1000 , mse_ 60.982 , loss_anch 60.982 tau-train= 0.93

NN: 2
epoch: 200 , mse_ 1039.374 , loss_anch 1039.374 tau-train= 0.09
epoch: 400 , mse_ 735.75 , loss_anch 735.75 tau-train= 0.24
epoch: 600 , mse_ 547.91 , loss_anch 547.91 tau-train= 0.49
epoch: 800 , mse_ 368.819 , loss_anch 368.819 tau-train= 0.64
epoch: 1000 , mse_ 253.08 , loss_anch 253.08 tau-train= 0.67

NN: 3
epoch: 200 , mse_ 723.983 , loss_anch 723.983 tau-train= 0.16
epoch: 400 , mse_ 511.276 , loss_anch 511.276 tau-train= 0.60
epoch: 600 , mse_ 295.721 , loss_anch 295.721 tau-train= 0.78
epoch: 800 , mse_ 177.086 , loss_anch 177.086 tau-train= 0.89
epoch: 1000 , mse_ 106.378 , loss_anch 106.378 tau-train= 0.96

NN: 4
epoch: 200 , mse_ 548.24 , loss_anch 548.24 tau-train= 0.53
epoch: 400 , mse_ 410.501 , loss_anch 410.501 tau-train= 0.64
epoch: 600 , mse_ 254.142 , loss_anch 254.142 tau-train= 0.78
epoch: 800 , mse_ 125.778 , loss_anch 125.778 tau-train= 0.93
epoch: 1000 , mse_ 45.819 , loss_anch 45.819 tau-train= 0.96
tau-train-ens=0.8181818181818182
tau-archive=0.8181818181818182
eval=6 | not-eval=0 | tau= 0.78 | n_kendall=12 | std(means)/mean(stds)=  0.89 | std(means)=3.52e-01 | mean(stds)=3.95e-01
delta_f=1.4e-02
tau-population= 0.60 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=4.986949251094622 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 944.181 , loss_anch 944.181 tau-train= 0.42
epoch: 400 , mse_ 817.768 , loss_anch 817.768 tau-train= 0.60
epoch: 600 , mse_ 665.988 , loss_anch 665.988 tau-train= 0.60
epoch: 800 , mse_ 527.551 , loss_anch 527.551 tau-train= 0.60
epoch: 1000 , mse_ 429.2 , loss_anch 429.2 tau-train= 0.67

NN: 1
epoch: 200 , mse_ 524.215 , loss_anch 524.215 tau-train= 0.64
epoch: 400 , mse_ 279.638 , loss_anch 279.638 tau-train= 0.85
epoch: 600 , mse_ 157.167 , loss_anch 157.167 tau-train= 0.89
epoch: 800 , mse_ 96.877 , loss_anch 96.877 tau-train= 0.93
epoch: 1000 , mse_ 61.842 , loss_anch 61.842 tau-train= 0.96

NN: 2
epoch: 200 , mse_ 1029.235 , loss_anch 1029.235 tau-train= 0.31
epoch: 400 , mse_ 872.405 , loss_anch 872.405 tau-train= 0.49
epoch: 600 , mse_ 730.481 , loss_anch 730.481 tau-train= 0.60
epoch: 800 , mse_ 601.689 , loss_anch 601.689 tau-train= 0.60
epoch: 1000 , mse_ 502.823 , loss_anch 502.823 tau-train= 0.60

NN: 3
epoch: 200 , mse_ 420.587 , loss_anch 420.587 tau-train= 0.71
epoch: 400 , mse_ 153.447 , loss_anch 153.447 tau-train= 0.89
epoch: 600 , mse_ 71.926 , loss_anch 71.926 tau-train= 0.93
epoch: 800 , mse_ 38.78 , loss_anch 38.78 tau-train= 0.96
epoch: 1000 , mse_ 25.171 , loss_anch 25.171 tau-train= 0.96

NN: 4
epoch: 200 , mse_ 216.817 , loss_anch 216.817 tau-train= 0.82
epoch: 400 , mse_ 88.765 , loss_anch 88.765 tau-train= 0.89
epoch: 600 , mse_ 40.409 , loss_anch 40.409 tau-train= 0.93
epoch: 800 , mse_ 30.624 , loss_anch 30.624 tau-train= 0.96
epoch: 1000 , mse_ 13.084 , loss_anch 13.084 tau-train= 1.00
tau-train-ens=0.8909090909090909
tau-archive=0.8909090909090909
eval=1 | not-eval=5 | tau= 0.88 | n_kendall=12 | std(means)/mean(stds)=  0.20 | std(means)=4.30e-02 | mean(stds)=2.11e-01
delta_f=1.4e-02
tau-population= 0.33 | tau-pop-offset= 0.47 | final-target-hit=False
subset-max-norm=5.91168820889991 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 922.652 , loss_anch 922.652 tau-train= 0.45
epoch: 400 , mse_ 682.168 , loss_anch 682.168 tau-train= 0.49
epoch: 600 , mse_ 561.098 , loss_anch 561.098 tau-train= 0.56
epoch: 800 , mse_ 497.163 , loss_anch 497.163 tau-train= 0.64
epoch: 1000 , mse_ 428.53 , loss_anch 428.53 tau-train= 0.64

NN: 1
epoch: 200 , mse_ 466.918 , loss_anch 466.918 tau-train= 0.60
epoch: 400 , mse_ 194.686 , loss_anch 194.686 tau-train= 0.71
epoch: 600 , mse_ 74.13 , loss_anch 74.13 tau-train= 0.89
epoch: 800 , mse_ 27.827 , loss_anch 27.827 tau-train= 1.00
epoch: 1000 , mse_ 13.596 , loss_anch 13.596 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 903.456 , loss_anch 903.456 tau-train= 0.49
epoch: 400 , mse_ 596.415 , loss_anch 596.415 tau-train= 0.75
epoch: 600 , mse_ 401.443 , loss_anch 401.443 tau-train= 0.64
epoch: 800 , mse_ 269.468 , loss_anch 269.468 tau-train= 0.71
epoch: 1000 , mse_ 196.249 , loss_anch 196.249 tau-train= 0.75

NN: 3
epoch: 200 , mse_ 492.396 , loss_anch 492.396 tau-train= 0.56
epoch: 400 , mse_ 260.375 , loss_anch 260.375 tau-train= 0.56
epoch: 600 , mse_ 147.641 , loss_anch 147.641 tau-train= 0.85
epoch: 800 , mse_ 92.901 , loss_anch 92.901 tau-train= 0.93
epoch: 1000 , mse_ 60.051 , loss_anch 60.051 tau-train= 0.93

NN: 4
epoch: 200 , mse_ 201.722 , loss_anch 201.722 tau-train= 0.49
epoch: 400 , mse_ 39.829 , loss_anch 39.829 tau-train= 0.93
epoch: 600 , mse_ 9.702 , loss_anch 9.702 tau-train= 1.00
epoch: 800 , mse_ 4.125 , loss_anch 4.125 tau-train= 1.00
epoch: 1000 , mse_ 2.276 , loss_anch 2.276 tau-train= 1.00
tau-train-ens=0.9272727272727274
tau-archive=0.9636363636363636
eval=1 | not-eval=5 | tau= 0.88 | n_kendall=12 | std(means)/mean(stds)=  0.25 | std(means)=3.30e-02 | mean(stds)=1.33e-01
delta_f=1.4e-02
tau-population= 0.73 | tau-pop-offset= 0.60 | final-target-hit=False
subset-max-norm=6.778965923925291 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1183.251 , loss_anch 1183.251 tau-train= 0.53
epoch: 400 , mse_ 986.262 , loss_anch 986.262 tau-train= 0.56
epoch: 600 , mse_ 747.835 , loss_anch 747.835 tau-train= 0.53
epoch: 800 , mse_ 514.062 , loss_anch 514.062 tau-train= 0.49
epoch: 1000 , mse_ 369.318 , loss_anch 369.318 tau-train= 0.60

NN: 1
epoch: 200 , mse_ 497.691 , loss_anch 497.691 tau-train= 0.56
epoch: 400 , mse_ 161.125 , loss_anch 161.125 tau-train= 0.85
epoch: 600 , mse_ 65.72 , loss_anch 65.72 tau-train= 0.89
epoch: 800 , mse_ 35.593 , loss_anch 35.593 tau-train= 0.96
epoch: 1000 , mse_ 22.474 , loss_anch 22.474 tau-train= 0.96

NN: 2
epoch: 200 , mse_ 951.71 , loss_anch 951.71 tau-train= 0.60
epoch: 400 , mse_ 527.11 , loss_anch 527.11 tau-train= 0.75
epoch: 600 , mse_ 352.113 , loss_anch 352.113 tau-train= 0.60
epoch: 800 , mse_ 281.573 , loss_anch 281.573 tau-train= 0.64
epoch: 1000 , mse_ 242.732 , loss_anch 242.732 tau-train= 0.67

NN: 3
epoch: 200 , mse_ 796.975 , loss_anch 796.975 tau-train= 0.49
epoch: 400 , mse_ 319.613 , loss_anch 319.613 tau-train= 0.71
epoch: 600 , mse_ 141.889 , loss_anch 141.889 tau-train= 0.78
epoch: 800 , mse_ 75.755 , loss_anch 75.755 tau-train= 0.89
epoch: 1000 , mse_ 40.531 , loss_anch 40.531 tau-train= 0.96

NN: 4
epoch: 200 , mse_ 400.904 , loss_anch 400.904 tau-train= 0.60
epoch: 400 , mse_ 90.092 , loss_anch 90.092 tau-train= 0.85
epoch: 600 , mse_ 34.113 , loss_anch 34.113 tau-train= 0.96
epoch: 800 , mse_ 20.446 , loss_anch 20.446 tau-train= 1.00
epoch: 1000 , mse_ 16.84 , loss_anch 16.84 tau-train= 1.00
tau-train-ens=0.9272727272727274
tau-archive=0.9636363636363636
eval=1 | not-eval=5 | tau= 0.94 | n_kendall=12 | std(means)/mean(stds)=  0.10 | std(means)=1.33e-02 | mean(stds)=1.38e-01
delta_f=1.4e-02
tau-population= 0.07 | tau-pop-offset=-0.07 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) -54.918158138404486
(Pdb) -54.91219781542641
(Pdb) subset-max-norm=7.720874010965482 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1279.92 , loss_anch 1279.92 tau-train= 0.35
epoch: 400 , mse_ 872.499 , loss_anch 872.499 tau-train= 0.56
epoch: 600 , mse_ 663.918 , loss_anch 663.918 tau-train= 0.49
epoch: 800 , mse_ 531.621 , loss_anch 531.621 tau-train= 0.49
epoch: 1000 , mse_ 445.308 , loss_anch 445.308 tau-train= 0.60

NN: 1
epoch: 200 , mse_ 438.97 , loss_anch 438.97 tau-train= 0.56
epoch: 400 , mse_ 175.972 , loss_anch 175.972 tau-train= 0.78
epoch: 600 , mse_ 91.482 , loss_anch 91.482 tau-train= 0.89
epoch: 800 , mse_ 54.987 , loss_anch 54.987 tau-train= 0.93
epoch: 1000 , mse_ 37.352 , loss_anch 37.352 tau-train= 1.00

NN: 2
epoch: 200 , mse_ 1021.838 , loss_anch 1021.838 tau-train= 0.35
epoch: 400 , mse_ 820.623 , loss_anch 820.623 tau-train= 0.38
epoch: 600 , mse_ 672.961 , loss_anch 672.961 tau-train= 0.53
epoch: 800 , mse_ 590.296 , loss_anch 590.296 tau-train= 0.53
epoch: 1000 , mse_ 519.554 , loss_anch 519.554 tau-train= 0.53

NN: 3
epoch: 200 , mse_ 486.166 , loss_anch 486.166 tau-train= 0.49
epoch: 400 , mse_ 208.962 , loss_anch 208.962 tau-train= 0.78
epoch: 600 , mse_ 117.203 , loss_anch 117.203 tau-train= 0.82
epoch: 800 , mse_ 69.836 , loss_anch 69.836 tau-train= 0.89
epoch: 1000 , mse_ 84.076 , loss_anch 84.076 tau-train= 0.89

NN: 4
epoch: 200 , mse_ 326.14 , loss_anch 326.14 tau-train= 0.75
epoch: 400 , mse_ 154.378 , loss_anch 154.378 tau-train= 0.82
epoch: 600 , mse_ 86.552 , loss_anch 86.552 tau-train= 0.82
epoch: 800 , mse_ 43.866 , loss_anch 43.866 tau-train= 0.93
epoch: 1000 , mse_ 30.28 , loss_anch 30.28 tau-train= 0.96
tau-train-ens=0.9272727272727274
tau-archive=0.7818181818181819
eval=6 | not-eval=0 | tau= 0.16 | n_kendall=12 | std(means)/mean(stds)=  0.14 | std(means)=1.88e-02 | mean(stds)=1.36e-01
delta_f=1.4e-02
tau-population=-0.20 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) -54.909824528924815
(Pdb) -54.91821043662748
(Pdb) subset-max-norm=6.2932718145165225 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 984.461 , loss_anch 984.461 tau-train= 0.09
epoch: 400 , mse_ 768.297 , loss_anch 768.297 tau-train= 0.20
epoch: 600 , mse_ 617.729 , loss_anch 617.729 tau-train= 0.42
epoch: 800 , mse_ 508.403 , loss_anch 508.403 tau-train= 0.35
epoch: 1000 , mse_ 433.721 , loss_anch 433.721 tau-train= 0.38

NN: 1
epoch: 200 , mse_ 455.891 , loss_anch 455.891 tau-train= 0.38
epoch: 400 , mse_ 145.902 , loss_anch 145.902 tau-train= 0.60
epoch: 600 , mse_ 87.792 , loss_anch 87.792 tau-train= 0.56
epoch: 800 , mse_ 57.603 , loss_anch 57.603 tau-train= 0.64
epoch: 1000 , mse_ 33.224 , loss_anch 33.224 tau-train= 0.75

NN: 2
epoch: 200 , mse_ 1088.66 , loss_anch 1088.66 tau-train=-0.02
epoch: 400 , mse_ 815.846 , loss_anch 815.846 tau-train= 0.09
epoch: 600 , mse_ 626.413 , loss_anch 626.413 tau-train= 0.31
epoch: 800 , mse_ 540.178 , loss_anch 540.178 tau-train= 0.27
epoch: 1000 , mse_ 484.146 , loss_anch 484.146 tau-train= 0.27

NN: 3
epoch: 200 , mse_ 326.387 , loss_anch 326.387 tau-train= 0.56
epoch: 400 , mse_ 118.96 , loss_anch 118.96 tau-train= 0.64
epoch: 600 , mse_ 69.554 , loss_anch 69.554 tau-train= 0.64
epoch: 800 , mse_ 43.143 , loss_anch 43.143 tau-train= 0.64
epoch: 1000 , mse_ 37.03 , loss_anch 37.03 tau-train= 0.71

NN: 4
epoch: 200 , mse_ 314.82 , loss_anch 314.82 tau-train= 0.53
epoch: 400 , mse_ 102.168 , loss_anch 102.168 tau-train= 0.64
epoch: 600 , mse_ 56.966 , loss_anch 56.966 tau-train= 0.71
epoch: 800 , mse_ 40.57 , loss_anch 40.57 tau-train= 0.75
epoch: 1000 , mse_ 31.728 , loss_anch 31.728 tau-train= 0.85
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1077)__call__()
-> print(f"tau-train-ens={_tau}")
(Pdb) 0.6363636363636364
(Pdb) array([[-0.79850659],
       [ 2.17901412],
       [ 1.77593471],
       [ 0.49895318],
       [-0.5858323 ],
       [ 2.04009825],
       [ 1.73793561],
       [ 0.46735824],
       [-1.37956361],
       [-0.501346  ],
       [ 2.23407841],
       [ 1.44500578],
       [ 1.37312782],
       [ 0.18079766],
       [-0.2479641 ],
       [ 2.11822357],
       [ 0.84139546],
       [ 0.16813242],
       [ 0.02775509],
       [-2.80346934],
       [ 1.83431625],
       [ 0.88774792],
       [ 0.4557284 ],
       [ 0.08897658],
       [-0.22322799],
       [-0.6448779 ],
       [ 1.32653053],
       [ 0.78556895],
       [ 0.65747679],
       [-0.11299699],
       [-1.20030042],
       [-0.65328939],
       [-2.11032216],
       [-0.75011432],
       [-0.04016812],
       [-0.0914365 ],
       [-0.29587179],
       [-0.32272824],
       [-0.6527307 ],
       [-0.824517  ]])
(Pdb) tau-train-ens=0.6363636363636364
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1079)__call__()
-> def raf(features):
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()
-> return raf
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()-><function Raf...x7fd7786ad9d0>
-> return raf
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1544)__call__()
-> model = (
(Pdb) 1500 	    def __call__(
1501 	        self,
1502 	        *,
1503 	        x_train: NDArray[np.float64],
1504 	        y_train: NDArray[np.float64],
1505 	        x_test: NDArray[np.float64],
1506 	        es: Cma,
1507 	    ) -> Model:
1508 	        subset_idx = self.__subset(
1509 	            x_train=x_train, y_train=y_train, x_test=x_test, es=es
1510 	        )
1511 	        subset_idx = np.sort(subset_idx)  # Important for some ECs
1512 	        if __debug__:
1513 	            print(f"subset-idx-size={subset_idx.size}")
1514 	        x_subset, y_subset = x_train[subset_idx], y_train[subset_idx]
1515 	
1516 	        weights = None
1517 	        # # Hansen's 20..1
1518 	        # weights = np.linspace(1, 20, y_subset.shape[0])[:, None]
1519 	        # # Experimental weights inversely proportional to the Mahalanobis norm
1520 	        # norms = np.array([es.mahalanobis_norm(x) for x in x_subset - es.mean])
1521 	        # weights = np.e ** (-norms*2)
1522 	
1523 	        x_transf = self.__x_transf(
1524 	            x_subset,
1525 	            x_train=x_subset,
1526 	            y_train=y_subset,
1527 	            x_test=x_test,
1528 	            es=es,
1529 	            weights=weights,
1530 	        )
1531 	        y_transf = self.__y_transf(
1532 	            y_subset,
1533 	            x_train=x_subset,
1534 	            y_train=y_subset,
1535 	            x_test=x_test,
1536 	            es=es,
1537 	            weights=weights,
1538 	        )
1539 	
1540 	        x_train_transf = x_transf.transform(x_subset)
1541 	        y_train_transf = y_transf.transform(y_subset)
1542 	        x_test_transf = x_transf.transform(x_test)
1543 	
1544 ->	        model = (
1545 	            self.__model(
1546 	                x_train=x_train_transf,
1547 	                y_train=y_train_transf,
1548 	                x_test=x_test_transf,
1549 	                weights=weights,
1550 	            )
1551 	            if isinstance(self.__model, ModelFactory)
1552 	            else self.__model
1553 	        )
1554 	
1555 	        @wraps(model)
1556 	        def surrogate_model(
1557 	            features: np.ndarray[tuple[N, DIM], np.dtype[np.float64]],
1558 	        ) -> Prediction[N]:
1559 	            features_transf = x_transf.transform(features)
1560 	            pred_transf = model(features_transf)
1561 	            return Prediction(
1562 	                y_transf.transform_inv(pred_transf.mean),
1563 	                y_transf.transform_inv_std(pred_transf.std),
1564 	            )
1565 	
1566 	        return surrogate_model
(Pdb) array([[-54.90932239],
       [-54.54479158],
       [-54.67220936],
       [-54.85730007],
       [-54.90468766],
       [-54.59460734],
       [-54.68177962],
       [-54.85952627],
       [-54.91794119],
       [-54.90255493],
       [-54.52304891],
       [-54.74452465],
       [-54.75731069],
       [-54.87680627],
       [-54.89496351],
       [-54.56744498],
       [-54.82806814],
       [-54.87746164],
       [-54.88419585],
       [-54.92624605],
       [-54.65677849],
       [-54.82328528],
       [-54.86032817],
       [-54.88137477],
       [-54.89411409],
       [-54.90607474],
       [-54.76512194],
       [-54.83354189],
       [-54.84500414],
       [-54.89006264],
       [-54.91579356],
       [-54.90626576],
       [-54.92361235],
       [-54.90835269],
       [-54.88713015],
       [-54.88921664],
       [-54.89655005],
       [-54.89740676],
       [-54.90625312],
       [-54.90982453]])
(Pdb) tau-archive=0.6363636363636364
eval=6 | not-eval=0 | tau= 0.64 | n_kendall=12 | std(means)/mean(stds)=  0.16 | std(means)=9.31e-03 | mean(stds)=5.98e-02
delta_f=1.4e-02
tau-population= 1.00 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=6.537495301264284 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 630.036 , loss_anch 630.036 tau-train= 0.49
epoch: 400 , mse_ 578.095 , loss_anch 578.095 tau-train= 0.42
epoch: 600 , mse_ 533.578 , loss_anch 533.578 tau-train= 0.60
epoch: 800 , mse_ 492.325 , loss_anch 492.325 tau-train= 0.71
epoch: 1000 , mse_ 452.52 , loss_anch 452.52 tau-train= 0.67

NN: 1
epoch: 200 , mse_ 370.944 , loss_anch 370.944 tau-train= 0.27
epoch: 400 , mse_ 271.888 , loss_anch 271.888 tau-train= 0.27
epoch: 600 , mse_ 179.974 , loss_anch 179.974 tau-train= 0.35
epoch: 800 , mse_ 122.977 , loss_anch 122.977 tau-train= 0.42
epoch: 1000 , mse_ 100.085 , loss_anch 100.085 tau-train= 0.42

NN: 2
epoch: 200 , mse_ 648.198 , loss_anch 648.198 tau-train= 0.53
epoch: 400 , mse_ 595.256 , loss_anch 595.256 tau-train= 0.35
epoch: 600 , mse_ 546.361 , loss_anch 546.361 tau-train= 0.38
epoch: 800 , mse_ 497.769 , loss_anch 497.769 tau-train= 0.38
epoch: 1000 , mse_ 449.374 , loss_anch 449.374 tau-train= 0.45

NN: 3
epoch: 200 , mse_ 370.4 , loss_anch 370.4 tau-train= 0.27
epoch: 400 , mse_ 288.41 , loss_anch 288.41 tau-train= 0.27
epoch: 600 , mse_ 227.169 , loss_anch 227.169 tau-train= 0.38
epoch: 800 , mse_ 169.672 , loss_anch 169.672 tau-train= 0.49
epoch: 1000 , mse_ 129.551 , loss_anch 129.551 tau-train= 0.45

NN: 4
epoch: 200 , mse_ 294.57 , loss_anch 294.57 tau-train= 0.27
epoch: 400 , mse_ 161.867 , loss_anch 161.867 tau-train= 0.35
epoch: 600 , mse_ 107.08 , loss_anch 107.08 tau-train= 0.45
epoch: 800 , mse_ 87.941 , loss_anch 87.941 tau-train= 0.49
epoch: 1000 , mse_ 73.367 , loss_anch 73.367 tau-train= 0.53
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1077)__call__()
-> print(f"tau-train-ens={_tau}")
(Pdb) 0.41818181818181815
(Pdb) array([[-0.44402341],
       [ 2.13041788],
       [ 0.85343636],
       [-0.23134912],
       [ 2.39458143],
       [ 0.82184141],
       [-1.02508043],
       [-0.14686282],
       [ 1.727611  ],
       [ 0.53528084],
       [ 0.10651908],
       [ 1.19587864],
       [ 0.5226156 ],
       [ 0.38223827],
       [-2.44898616],
       [ 1.2422311 ],
       [ 0.81021158],
       [ 0.44345976],
       [ 0.13125519],
       [-0.29039472],
       [ 1.68101371],
       [ 1.14005213],
       [ 1.01195997],
       [ 0.24148619],
       [-0.84581724],
       [-0.29880621],
       [-1.75583898],
       [-0.39563114],
       [ 0.31431505],
       [ 0.26304668],
       [ 0.05861139],
       [ 0.03175494],
       [-0.29824753],
       [-0.47003382],
       [-0.16716069],
       [-0.32635657],
       [-0.66978679],
       [-0.77542086],
       [-0.86047345],
       [-1.13876721]])
(Pdb) tau-train-ens=0.41818181818181815
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1079)__call__()
-> def raf(features):
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()
-> return raf
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()-><function Raf...x7fd7786ad940>
-> return raf
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1544)__call__()
-> model = (
(Pdb) array([[-54.90932239],
       [-54.67220936],
       [-54.85730007],
       [-54.90468766],
       [-54.59460734],
       [-54.85952627],
       [-54.91794119],
       [-54.90255493],
       [-54.75731069],
       [-54.87680627],
       [-54.89496351],
       [-54.82806814],
       [-54.87746164],
       [-54.88419585],
       [-54.92624605],
       [-54.82328528],
       [-54.86032817],
       [-54.88137477],
       [-54.89411409],
       [-54.90607474],
       [-54.76512194],
       [-54.83354189],
       [-54.84500414],
       [-54.89006264],
       [-54.91579356],
       [-54.90626576],
       [-54.92361235],
       [-54.90835269],
       [-54.88713015],
       [-54.88921664],
       [-54.89655005],
       [-54.89740676],
       [-54.90625312],
       [-54.90982453],
       [-54.90308388],
       [-54.90688028],
       [-54.9132748 ],
       [-54.91483914],
       [-54.91598395],
       [-54.91911667]])
(Pdb) tau-archive=0.41818181818181815
eval=6 | not-eval=0 | tau= 0.11 | n_kendall=12 | std(means)/mean(stds)=  0.26 | std(means)=1.46e-02 | mean(stds)=5.58e-02
delta_f=8.0e-03
tau-population= 0.07 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) array([-54.91948256, -54.92808049, -54.89960748, -54.91691013,
       -54.91797741, -54.93196305])
(Pdb) -54.93196304824649
(Pdb) -54.926114888703644
(Pdb) subset-max-norm=3.1143392894449176 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 366.116 , loss_anch 366.116 tau-train= 0.53
epoch: 400 , mse_ 312.684 , loss_anch 312.684 tau-train= 0.53
epoch: 600 , mse_ 266.509 , loss_anch 266.509 tau-train= 0.45
epoch: 800 , mse_ 225.703 , loss_anch 225.703 tau-train= 0.42
epoch: 1000 , mse_ 185.873 , loss_anch 185.873 tau-train= 0.45

NN: 1
epoch: 200 , mse_ 253.596 , loss_anch 253.596 tau-train= 0.45
epoch: 400 , mse_ 130.496 , loss_anch 130.496 tau-train= 0.67
epoch: 600 , mse_ 71.137 , loss_anch 71.137 tau-train= 0.56
epoch: 800 , mse_ 60.806 , loss_anch 60.806 tau-train= 0.53
epoch: 1000 , mse_ 60.167 , loss_anch 60.167 tau-train= 0.49

NN: 2
epoch: 200 , mse_ 344.619 , loss_anch 344.619 tau-train= 0.35
epoch: 400 , mse_ 279.826 , loss_anch 279.826 tau-train= 0.38
epoch: 600 , mse_ 220.529 , loss_anch 220.529 tau-train= 0.38
epoch: 800 , mse_ 182.452 , loss_anch 182.452 tau-train= 0.53
epoch: 1000 , mse_ 152.248 , loss_anch 152.248 tau-train= 0.53

NN: 3
epoch: 200 , mse_ 286.029 , loss_anch 286.029 tau-train= 0.35
epoch: 400 , mse_ 208.956 , loss_anch 208.956 tau-train= 0.56
epoch: 600 , mse_ 115.461 , loss_anch 115.461 tau-train= 0.60
epoch: 800 , mse_ 66.636 , loss_anch 66.636 tau-train= 0.42
epoch: 1000 , mse_ 56.346 , loss_anch 56.346 tau-train= 0.56

NN: 4
epoch: 200 , mse_ 231.184 , loss_anch 231.184 tau-train= 0.35
epoch: 400 , mse_ 104.512 , loss_anch 104.512 tau-train= 0.38
epoch: 600 , mse_ 59.796 , loss_anch 59.796 tau-train= 0.45
epoch: 800 , mse_ 55.337 , loss_anch 55.337 tau-train= 0.45
epoch: 1000 , mse_ 53.157 , loss_anch 53.157 tau-train= 0.45
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1077)__call__()
-> print(f"tau-train-ens={_tau}")
(Pdb) array([[-0.00220831],
       [ 1.08344991],
       [ 0.15884074],
       [ 1.05469767],
       [-0.39518097],
       [ 0.22504864],
       [ 0.79797524],
       [ 0.43046361],
       [ 0.78681271],
       [ 0.66425676],
       [-1.01851185],
       [ 1.44326065],
       [ 1.04413495],
       [ 0.7174369 ],
       [ 0.45102798],
       [ 0.11330161],
       [ 1.2288872 ],
       [ 0.54368344],
       [-0.28189725],
       [ 0.10686461],
       [-0.77607075],
       [ 0.03369959],
       [ 0.60576779],
       [ 0.56199334],
       [ 0.39088279],
       [ 0.36884004],
       [ 0.10729176],
       [-0.02132176],
       [ 0.20903219],
       [ 0.08587083],
       [-0.16357132],
       [-0.23539814],
       [-0.29143767],
       [-0.46308876],
       [ 0.30988323],
       [-0.33919133],
       [-0.39720637],
       [-0.48520327],
       [-1.23058738],
       [-1.92373456]])
(Pdb) tau-train-ens=0.5272727272727272
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1079)__call__()
-> def raf(features):
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()
-> return raf
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()-><function Raf...x7fd7a57e9d30>
-> return raf
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1544)__call__()
-> model = (
(Pdb) array([[-54.90932239],
       [-54.85730007],
       [-54.90468766],
       [-54.85952627],
       [-54.91794119],
       [-54.90255493],
       [-54.87680627],
       [-54.89496351],
       [-54.87746164],
       [-54.88419585],
       [-54.92624605],
       [-54.82328528],
       [-54.86032817],
       [-54.88137477],
       [-54.89411409],
       [-54.90607474],
       [-54.84500414],
       [-54.89006264],
       [-54.91579356],
       [-54.90626576],
       [-54.92361235],
       [-54.90835269],
       [-54.88713015],
       [-54.88921664],
       [-54.89655005],
       [-54.89740676],
       [-54.90625312],
       [-54.90982453],
       [-54.90308388],
       [-54.90688028],
       [-54.9132748 ],
       [-54.91483914],
       [-54.91598395],
       [-54.91911667],
       [-54.89960748],
       [-54.91691013],
       [-54.91797741],
       [-54.91948256],
       [-54.92808049],
       [-54.93196305]])
(Pdb) tau-archive=0.5272727272727272
eval=6 | not-eval=0 | tau= 0.38 | n_kendall=12 | std(means)/mean(stds)=  1.66 | std(means)=8.20e-02 | mean(stds)=4.93e-02
delta_f=5.8e-03
tau-population= 0.07 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) -54.93424690085959
(Pdb) -54.9305909300389
(Pdb) subset-max-norm=2.374329421926926 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 401.353 , loss_anch 401.353 tau-train= 0.49
epoch: 400 , mse_ 368.421 , loss_anch 368.421 tau-train= 0.64
epoch: 600 , mse_ 331.544 , loss_anch 331.544 tau-train= 0.64
epoch: 800 , mse_ 295.05 , loss_anch 295.05 tau-train= 0.64
epoch: 1000 , mse_ 262.976 , loss_anch 262.976 tau-train= 0.64

NN: 1
epoch: 200 , mse_ 203.321 , loss_anch 203.321 tau-train= 0.75
epoch: 400 , mse_ 186.48 , loss_anch 186.48 tau-train= 0.75
epoch: 600 , mse_ 169.668 , loss_anch 169.668 tau-train= 0.75
epoch: 800 , mse_ 152.255 , loss_anch 152.255 tau-train= 0.71
epoch: 1000 , mse_ 134.031 , loss_anch 134.031 tau-train= 0.67

NN: 2
epoch: 200 , mse_ 322.213 , loss_anch 322.213 tau-train= 0.67
epoch: 400 , mse_ 240.476 , loss_anch 240.476 tau-train= 0.64
epoch: 600 , mse_ 202.774 , loss_anch 202.774 tau-train= 0.71
epoch: 800 , mse_ 187.361 , loss_anch 187.361 tau-train= 0.75
epoch: 1000 , mse_ 175.699 , loss_anch 175.699 tau-train= 0.78

NN: 3
epoch: 200 , mse_ 194.767 , loss_anch 194.767 tau-train= 0.67
epoch: 400 , mse_ 161.262 , loss_anch 161.262 tau-train= 0.75
epoch: 600 , mse_ 142.637 , loss_anch 142.637 tau-train= 0.71
epoch: 800 , mse_ 126.943 , loss_anch 126.943 tau-train= 0.71
epoch: 1000 , mse_ 114.744 , loss_anch 114.744 tau-train= 0.67

NN: 4
epoch: 200 , mse_ 191.185 , loss_anch 191.185 tau-train= 0.75
epoch: 400 , mse_ 153.098 , loss_anch 153.098 tau-train= 0.71
epoch: 600 , mse_ 131.532 , loss_anch 131.532 tau-train= 0.67
epoch: 800 , mse_ 119.905 , loss_anch 119.905 tau-train= 0.67
epoch: 1000 , mse_ 113.993 , loss_anch 113.993 tau-train= 0.67
tau-train-ens=0.7090909090909091
tau-archive=0.6363636363636364
eval=6 | not-eval=0 | tau= 0.87 | n_kendall=12 | std(means)/mean(stds)=  0.46 | std(means)=1.45e-02 | mean(stds)=3.19e-02
delta_f=7.7e-04
tau-population= 0.60 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=2.537183831961494 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 133.527 , loss_anch 133.527 tau-train= 0.49
epoch: 400 , mse_ 99.578 , loss_anch 99.578 tau-train= 0.64
epoch: 600 , mse_ 83.72 , loss_anch 83.72 tau-train= 0.71
epoch: 800 , mse_ 76.192 , loss_anch 76.192 tau-train= 0.75
epoch: 1000 , mse_ 71.187 , loss_anch 71.187 tau-train= 0.67

NN: 1
epoch: 200 , mse_ 64.103 , loss_anch 64.103 tau-train= 0.75
epoch: 400 , mse_ 54.396 , loss_anch 54.396 tau-train= 0.85
epoch: 600 , mse_ 49.356 , loss_anch 49.356 tau-train= 0.82
epoch: 800 , mse_ 45.477 , loss_anch 45.477 tau-train= 0.89
epoch: 1000 , mse_ 42.313 , loss_anch 42.313 tau-train= 0.89

NN: 2
epoch: 200 , mse_ 117.96 , loss_anch 117.96 tau-train= 0.35
epoch: 400 , mse_ 87.394 , loss_anch 87.394 tau-train= 0.67
epoch: 600 , mse_ 72.303 , loss_anch 72.303 tau-train= 0.75
epoch: 800 , mse_ 64.4 , loss_anch 64.4 tau-train= 0.78
epoch: 1000 , mse_ 60.869 , loss_anch 60.869 tau-train= 0.78

NN: 3
epoch: 200 , mse_ 60.757 , loss_anch 60.757 tau-train= 0.82
epoch: 400 , mse_ 54.301 , loss_anch 54.301 tau-train= 0.85
epoch: 600 , mse_ 49.352 , loss_anch 49.352 tau-train= 0.82
epoch: 800 , mse_ 44.956 , loss_anch 44.956 tau-train= 0.89
epoch: 1000 , mse_ 41.569 , loss_anch 41.569 tau-train= 0.89

NN: 4
epoch: 200 , mse_ 59.835 , loss_anch 59.835 tau-train= 0.78
epoch: 400 , mse_ 55.059 , loss_anch 55.059 tau-train= 0.85
epoch: 600 , mse_ 52.616 , loss_anch 52.616 tau-train= 0.82
epoch: 800 , mse_ 49.829 , loss_anch 49.829 tau-train= 0.85
epoch: 1000 , mse_ 45.858 , loss_anch 45.858 tau-train= 0.89
tau-train-ens=0.8181818181818182
tau-archive=0.8181818181818182
eval=2 | not-eval=4 | tau= 0.88 | n_kendall=12 | std(means)/mean(stds)=  0.65 | std(means)=2.47e-02 | mean(stds)=3.78e-02
delta_f=7.7e-04
tau-population= 0.47 | tau-pop-offset= 0.73 | final-target-hit=False
subset-max-norm=3.3283676003593317 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 310.721 , loss_anch 310.721 tau-train= 0.49
epoch: 400 , mse_ 267.693 , loss_anch 267.693 tau-train= 0.49
epoch: 600 , mse_ 222.212 , loss_anch 222.212 tau-train= 0.42
epoch: 800 , mse_ 170.578 , loss_anch 170.578 tau-train= 0.42
epoch: 1000 , mse_ 132.077 , loss_anch 132.077 tau-train= 0.49

NN: 1
epoch: 200 , mse_ 211.649 , loss_anch 211.649 tau-train= 0.67
epoch: 400 , mse_ 134.236 , loss_anch 134.236 tau-train= 0.64
epoch: 600 , mse_ 93.129 , loss_anch 93.129 tau-train= 0.64
epoch: 800 , mse_ 82.513 , loss_anch 82.513 tau-train= 0.64
epoch: 1000 , mse_ 73.095 , loss_anch 73.095 tau-train= 0.64

NN: 2
epoch: 200 , mse_ 251.438 , loss_anch 251.438 tau-train= 0.64
epoch: 400 , mse_ 198.571 , loss_anch 198.571 tau-train= 0.60
epoch: 600 , mse_ 143.727 , loss_anch 143.727 tau-train= 0.60
epoch: 800 , mse_ 116.05 , loss_anch 116.05 tau-train= 0.64
epoch: 1000 , mse_ 100.888 , loss_anch 100.888 tau-train= 0.64

NN: 3
epoch: 200 , mse_ 188.774 , loss_anch 188.774 tau-train= 0.75
epoch: 400 , mse_ 102.702 , loss_anch 102.702 tau-train= 0.71
epoch: 600 , mse_ 68.722 , loss_anch 68.722 tau-train= 0.71
epoch: 800 , mse_ 60.665 , loss_anch 60.665 tau-train= 0.71
epoch: 1000 , mse_ 54.032 , loss_anch 54.032 tau-train= 0.71

NN: 4
epoch: 200 , mse_ 181.685 , loss_anch 181.685 tau-train= 0.71
epoch: 400 , mse_ 110.597 , loss_anch 110.597 tau-train= 0.60
epoch: 600 , mse_ 75.821 , loss_anch 75.821 tau-train= 0.67
epoch: 800 , mse_ 65.024 , loss_anch 65.024 tau-train= 0.64
epoch: 1000 , mse_ 53.357 , loss_anch 53.357 tau-train= 0.75
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1077)__call__()
-> print(f"tau-train-ens={_tau}")
(Pdb) array([[ 0.31148788],
       [ 0.26796481],
       [ 1.22400408],
       [ 0.43617839],
       [ 1.19805921],
       [ 0.0278617 ],
       [ 0.65608502],
       [ 0.85377954],
       [-0.35192373],
       [ 1.55425762],
       [ 1.18854625],
       [ 0.10640957],
       [-0.2152069 ],
       [ 0.33889341],
       [ 0.76643162],
       [ 0.60521329],
       [ 0.29699581],
       [ 0.47594269],
       [ 0.37912148],
       [ 0.19129881],
       [ 0.13942979],
       [ 0.09968994],
       [-0.01789543],
       [ 0.06634242],
       [ 0.02648235],
       [-0.03257629],
       [-0.45955745],
       [-0.73467392],
       [ 0.64973968],
       [-0.13046989],
       [-0.45889104],
       [-0.64704556],
       [-0.94081821],
       [ 0.93528704],
       [ 0.52450722],
       [ 0.21121891],
       [ 0.16507972],
       [-1.63396539],
       [-0.40307257],
       [-0.91953209]])
(Pdb) tau-train-ens=0.6727272727272727
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1079)__call__()
-> def raf(features):
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()
-> return raf
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()-><function Raf...x7fd7a57e9940>
-> return raf
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1544)__call__()
-> model = (
(Pdb) array([[-54.90932239],
       [-54.9108088 ],
       [-54.85730007],
       [-54.90468766],
       [-54.85952627],
       [-54.91794119],
       [-54.89496351],
       [-54.88419585],
       [-54.92624605],
       [-54.82328528],
       [-54.86032817],
       [-54.91579356],
       [-54.92361235],
       [-54.90835269],
       [-54.88921664],
       [-54.89740676],
       [-54.90982453],
       [-54.90308388],
       [-54.90688028],
       [-54.9132748 ],
       [-54.91483914],
       [-54.91598395],
       [-54.91911667],
       [-54.91691013],
       [-54.91797741],
       [-54.91948256],
       [-54.92808049],
       [-54.93196305],
       [-54.89527509],
       [-54.92178973],
       [-54.92806973],
       [-54.93084025],
       [-54.9342469 ],
       [-54.87909826],
       [-54.90103667],
       [-54.91265213],
       [-54.91407569],
       [-54.93923499],
       [-54.92714243],
       [-54.93403227]])
(Pdb) tau-archive=0.41818181818181815
eval=6 | not-eval=0 | tau= 0.38 | n_kendall=12 | std(means)/mean(stds)=  0.34 | std(means)=1.11e-02 | mean(stds)=3.28e-02
delta_f=7.7e-04
tau-population= 0.20 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) array([-54.93307833, -54.93414344, -54.9353689 , -54.93057714,
       -54.93602751, -54.93786815])
(Pdb) -54.93786815448193
(Pdb) -54.939459048917904
(Pdb) subset-max-norm=3.4844623283330893 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 240.041 , loss_anch 240.041 tau-train= 0.49
epoch: 400 , mse_ 165.944 , loss_anch 165.944 tau-train= 0.60
epoch: 600 , mse_ 156.308 , loss_anch 156.308 tau-train= 0.60
epoch: 800 , mse_ 151.063 , loss_anch 151.063 tau-train= 0.60
epoch: 1000 , mse_ 146.539 , loss_anch 146.539 tau-train= 0.64

NN: 1
epoch: 200 , mse_ 116.978 , loss_anch 116.978 tau-train= 0.78
epoch: 400 , mse_ 97.351 , loss_anch 97.351 tau-train= 0.75
epoch: 600 , mse_ 80.882 , loss_anch 80.882 tau-train= 0.78
epoch: 800 , mse_ 64.075 , loss_anch 64.075 tau-train= 0.78
epoch: 1000 , mse_ 55.073 , loss_anch 55.073 tau-train= 0.82

NN: 2
epoch: 200 , mse_ 158.123 , loss_anch 158.123 tau-train= 0.67
epoch: 400 , mse_ 149.465 , loss_anch 149.465 tau-train= 0.67
epoch: 600 , mse_ 143.195 , loss_anch 143.195 tau-train= 0.67
epoch: 800 , mse_ 136.188 , loss_anch 136.188 tau-train= 0.71
epoch: 1000 , mse_ 129.297 , loss_anch 129.297 tau-train= 0.71

NN: 3
epoch: 200 , mse_ 137.864 , loss_anch 137.864 tau-train= 0.64
epoch: 400 , mse_ 115.345 , loss_anch 115.345 tau-train= 0.75
epoch: 600 , mse_ 96.009 , loss_anch 96.009 tau-train= 0.75
epoch: 800 , mse_ 82.123 , loss_anch 82.123 tau-train= 0.78
epoch: 1000 , mse_ 70.965 , loss_anch 70.965 tau-train= 0.82

NN: 4
epoch: 200 , mse_ 102.795 , loss_anch 102.795 tau-train= 0.75
epoch: 400 , mse_ 81.285 , loss_anch 81.285 tau-train= 0.82
epoch: 600 , mse_ 62.463 , loss_anch 62.463 tau-train= 0.85
epoch: 800 , mse_ 46.685 , loss_anch 46.685 tau-train= 0.89
epoch: 1000 , mse_ 35.356 , loss_anch 35.356 tau-train= 0.89
tau-train-ens=0.7454545454545454
tau-archive=0.7454545454545454
eval=6 | not-eval=0 | tau= 0.73 | n_kendall=12 | std(means)/mean(stds)=  0.32 | std(means)=1.41e-02 | mean(stds)=4.47e-02
delta_f=7.7e-04
tau-population= 0.47 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=4.91900809457187 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 202.287 , loss_anch 202.287 tau-train= 0.49
epoch: 400 , mse_ 184.291 , loss_anch 184.291 tau-train= 0.49
epoch: 600 , mse_ 170.034 , loss_anch 170.034 tau-train= 0.49
epoch: 800 , mse_ 154.51 , loss_anch 154.51 tau-train= 0.53
epoch: 1000 , mse_ 144.527 , loss_anch 144.527 tau-train= 0.53

NN: 1
epoch: 200 , mse_ 125.434 , loss_anch 125.434 tau-train= 0.82
epoch: 400 , mse_ 107.258 , loss_anch 107.258 tau-train= 0.78
epoch: 600 , mse_ 90.779 , loss_anch 90.779 tau-train= 0.78
epoch: 800 , mse_ 72.883 , loss_anch 72.883 tau-train= 0.78
epoch: 1000 , mse_ 56.887 , loss_anch 56.887 tau-train= 0.75

NN: 2
epoch: 200 , mse_ 196.984 , loss_anch 196.984 tau-train= 0.60
epoch: 400 , mse_ 175.807 , loss_anch 175.807 tau-train= 0.60
epoch: 600 , mse_ 159.932 , loss_anch 159.932 tau-train= 0.60
epoch: 800 , mse_ 146.692 , loss_anch 146.692 tau-train= 0.60
epoch: 1000 , mse_ 136.25 , loss_anch 136.25 tau-train= 0.53

NN: 3
epoch: 200 , mse_ 138.549 , loss_anch 138.549 tau-train= 0.71
epoch: 400 , mse_ 100.662 , loss_anch 100.662 tau-train= 0.75
epoch: 600 , mse_ 81.215 , loss_anch 81.215 tau-train= 0.75
epoch: 800 , mse_ 66.799 , loss_anch 66.799 tau-train= 0.75
epoch: 1000 , mse_ 57.332 , loss_anch 57.332 tau-train= 0.75

NN: 4
epoch: 200 , mse_ 118.625 , loss_anch 118.625 tau-train= 0.75
epoch: 400 , mse_ 99.784 , loss_anch 99.784 tau-train= 0.75
epoch: 600 , mse_ 76.585 , loss_anch 76.585 tau-train= 0.75
epoch: 800 , mse_ 60.864 , loss_anch 60.864 tau-train= 0.71
epoch: 1000 , mse_ 51.997 , loss_anch 51.997 tau-train= 0.67
tau-train-ens=0.7454545454545454
tau-archive=0.7454545454545454
eval=6 | not-eval=0 | tau= 0.51 | n_kendall=12 | std(means)/mean(stds)=  0.31 | std(means)=4.63e-03 | mean(stds)=1.48e-02
delta_f=7.7e-04
tau-population= 0.47 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=4.719118639070463 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 202.524 , loss_anch 202.524 tau-train= 0.67
epoch: 400 , mse_ 179.588 , loss_anch 179.588 tau-train= 0.75
epoch: 600 , mse_ 157.335 , loss_anch 157.335 tau-train= 0.71
epoch: 800 , mse_ 140.632 , loss_anch 140.632 tau-train= 0.71
epoch: 1000 , mse_ 127.471 , loss_anch 127.471 tau-train= 0.67

NN: 1
epoch: 200 , mse_ 144.343 , loss_anch 144.343 tau-train= 0.75
epoch: 400 , mse_ 108.887 , loss_anch 108.887 tau-train= 0.67
epoch: 600 , mse_ 81.339 , loss_anch 81.339 tau-train= 0.71
epoch: 800 , mse_ 65.055 , loss_anch 65.055 tau-train= 0.75
epoch: 1000 , mse_ 54.847 , loss_anch 54.847 tau-train= 0.71

NN: 2
epoch: 200 , mse_ 214.744 , loss_anch 214.744 tau-train= 0.78
epoch: 400 , mse_ 178.791 , loss_anch 178.791 tau-train= 0.71
epoch: 600 , mse_ 153.888 , loss_anch 153.888 tau-train= 0.71
epoch: 800 , mse_ 141.03 , loss_anch 141.03 tau-train= 0.71
epoch: 1000 , mse_ 134.138 , loss_anch 134.138 tau-train= 0.60

NN: 3
epoch: 200 , mse_ 151.355 , loss_anch 151.355 tau-train= 0.71
epoch: 400 , mse_ 128.656 , loss_anch 128.656 tau-train= 0.78
epoch: 600 , mse_ 109.528 , loss_anch 109.528 tau-train= 0.78
epoch: 800 , mse_ 83.88 , loss_anch 83.88 tau-train= 0.71
epoch: 1000 , mse_ 62.587 , loss_anch 62.587 tau-train= 0.75

NN: 4
epoch: 200 , mse_ 146.854 , loss_anch 146.854 tau-train= 0.67
epoch: 400 , mse_ 125.979 , loss_anch 125.979 tau-train= 0.78
epoch: 600 , mse_ 101.632 , loss_anch 101.632 tau-train= 0.75
epoch: 800 , mse_ 84.893 , loss_anch 84.893 tau-train= 0.78
epoch: 1000 , mse_ 72.973 , loss_anch 72.973 tau-train= 0.75
tau-train-ens=0.7090909090909091
tau-archive=0.7090909090909091
eval=6 | not-eval=0 | tau= 0.42 | n_kendall=12 | std(means)/mean(stds)=  0.12 | std(means)=1.41e-03 | mean(stds)=1.16e-02
delta_f=7.7e-04
tau-population= 0.20 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) -54.936442969756506
(Pdb) -54.93643281354394
(Pdb) subset-max-norm=4.666168217339062 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 201.254 , loss_anch 201.254 tau-train= 0.45
epoch: 400 , mse_ 188.906 , loss_anch 188.906 tau-train= 0.38
epoch: 600 , mse_ 180.707 , loss_anch 180.707 tau-train= 0.45
epoch: 800 , mse_ 173.593 , loss_anch 173.593 tau-train= 0.56
epoch: 1000 , mse_ 166.724 , loss_anch 166.724 tau-train= 0.60

NN: 1
epoch: 200 , mse_ 113.061 , loss_anch 113.061 tau-train= 0.71
epoch: 400 , mse_ 84.131 , loss_anch 84.131 tau-train= 0.75
epoch: 600 , mse_ 58.342 , loss_anch 58.342 tau-train= 0.78
epoch: 800 , mse_ 41.813 , loss_anch 41.813 tau-train= 0.82
epoch: 1000 , mse_ 33.516 , loss_anch 33.516 tau-train= 0.85

NN: 2
epoch: 200 , mse_ 180.777 , loss_anch 180.777 tau-train= 0.49
epoch: 400 , mse_ 157.111 , loss_anch 157.111 tau-train= 0.64
epoch: 600 , mse_ 135.703 , loss_anch 135.703 tau-train= 0.60
epoch: 800 , mse_ 121.33 , loss_anch 121.33 tau-train= 0.60
epoch: 1000 , mse_ 109.779 , loss_anch 109.779 tau-train= 0.64

NN: 3
epoch: 200 , mse_ 131.087 , loss_anch 131.087 tau-train= 0.71
epoch: 400 , mse_ 100.232 , loss_anch 100.232 tau-train= 0.67
epoch: 600 , mse_ 72.346 , loss_anch 72.346 tau-train= 0.75
epoch: 800 , mse_ 53.908 , loss_anch 53.908 tau-train= 0.75
epoch: 1000 , mse_ 41.52 , loss_anch 41.52 tau-train= 0.75

NN: 4
epoch: 200 , mse_ 103.987 , loss_anch 103.987 tau-train= 0.64
epoch: 400 , mse_ 72.965 , loss_anch 72.965 tau-train= 0.71
epoch: 600 , mse_ 44.907 , loss_anch 44.907 tau-train= 0.82
epoch: 800 , mse_ 30.523 , loss_anch 30.523 tau-train= 0.89
epoch: 1000 , mse_ 23.842 , loss_anch 23.842 tau-train= 0.93
tau-train-ens=0.8181818181818182
tau-archive=0.8181818181818182
eval=6 | not-eval=0 | tau= 0.29 | n_kendall=12 | std(means)/mean(stds)=  0.13 | std(means)=1.13e-03 | mean(stds)=8.46e-03
delta_f=7.7e-04
tau-population= 0.20 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) -54.9372143951033
(Pdb) -54.93570135796458
(Pdb) subset-max-norm=5.728726086434182 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 164.655 , loss_anch 164.655 tau-train=-0.02
epoch: 400 , mse_ 142.845 , loss_anch 142.845 tau-train= 0.20
epoch: 600 , mse_ 129.544 , loss_anch 129.544 tau-train= 0.35
epoch: 800 , mse_ 118.803 , loss_anch 118.803 tau-train= 0.38
epoch: 1000 , mse_ 108.548 , loss_anch 108.548 tau-train= 0.38

NN: 1
epoch: 200 , mse_ 85.603 , loss_anch 85.603 tau-train= 0.45
epoch: 400 , mse_ 71.031 , loss_anch 71.031 tau-train= 0.60
epoch: 600 , mse_ 59.991 , loss_anch 59.991 tau-train= 0.64
epoch: 800 , mse_ 51.659 , loss_anch 51.659 tau-train= 0.64
epoch: 1000 , mse_ 43.999 , loss_anch 43.999 tau-train= 0.67

NN: 2
epoch: 200 , mse_ 122.953 , loss_anch 122.953 tau-train= 0.05
epoch: 400 , mse_ 105.209 , loss_anch 105.209 tau-train= 0.16
epoch: 600 , mse_ 94.537 , loss_anch 94.537 tau-train= 0.31
epoch: 800 , mse_ 87.804 , loss_anch 87.804 tau-train= 0.35
epoch: 1000 , mse_ 79.601 , loss_anch 79.601 tau-train= 0.42

NN: 3
epoch: 200 , mse_ 89.092 , loss_anch 89.092 tau-train= 0.38
epoch: 400 , mse_ 65.149 , loss_anch 65.149 tau-train= 0.64
epoch: 600 , mse_ 53.079 , loss_anch 53.079 tau-train= 0.71
epoch: 800 , mse_ 43.291 , loss_anch 43.291 tau-train= 0.75
epoch: 1000 , mse_ 35.529 , loss_anch 35.529 tau-train= 0.71

NN: 4
epoch: 200 , mse_ 62.406 , loss_anch 62.406 tau-train= 0.71
epoch: 400 , mse_ 44.39 , loss_anch 44.39 tau-train= 0.75
epoch: 600 , mse_ 34.05 , loss_anch 34.05 tau-train= 0.71
epoch: 800 , mse_ 26.968 , loss_anch 26.968 tau-train= 0.67
epoch: 1000 , mse_ 22.511 , loss_anch 22.511 tau-train= 0.75
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1077)__call__()
-> print(f"tau-train-ens={_tau}")
(Pdb) array([[ 9.55180727e-01],
       [ 1.12362225e+00],
       [ 1.35839054e+00],
       [ 8.18462424e-01],
       [ 4.47289676e-01],
       [ 1.22552838e+00],
       [ 5.69482884e-01],
       [ 1.40258857e-01],
       [-1.39647204e+00],
       [ 8.90705491e-01],
       [ 1.73474898e-01],
       [ 5.96079024e-01],
       [ 1.56408253e-01],
       [-5.40006678e-02],
       [-1.88513714e-01],
       [-7.03324858e-01],
       [ 8.00660338e-01],
       [ 5.13284304e-01],
       [ 4.44026545e-01],
       [ 2.26295705e-01],
       [ 2.15909901e-01],
       [-1.43256210e-01],
       [ 8.54481831e-01],
       [ 5.23412272e-01],
       [ 5.05575931e-01],
       [ 2.41187458e-01],
       [-1.25596688e-03],
       [-3.01593159e-01],
       [ 8.65250164e-01],
       [ 3.57607144e-01],
       [ 8.61194951e-02],
       [ 2.93874518e-02],
       [-2.13901610e-01],
       [-2.83730844e-01],
       [ 7.97698949e-01],
       [ 1.31672838e-01],
       [ 1.26484960e-02],
       [ 1.18753972e-03],
       [-2.87958843e-01],
       [-4.88898936e-01]])
(Pdb) tau-train-ens=0.6727272727272727
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1079)__call__()
-> def raf(features):
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()
-> return raf
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()-><function Raf...x7fd7a601e670>
-> return raf
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1544)__call__()
-> model = (
(Pdb) array([[-54.92624605],
       [-54.92361235],
       [-54.91911667],
       [-54.92808049],
       [-54.93196305],
       [-54.92178973],
       [-54.93084025],
       [-54.9342469 ],
       [-54.93923499],
       [-54.92714243],
       [-54.93403227],
       [-54.93057714],
       [-54.93414344],
       [-54.9353689 ],
       [-54.93602751],
       [-54.93786815],
       [-54.92830142],
       [-54.9313737 ],
       [-54.93199119],
       [-54.93367593],
       [-54.93374749],
       [-54.93581573],
       [-54.92762126],
       [-54.93127977],
       [-54.93144456],
       [-54.93357202],
       [-54.93508548],
       [-54.9365166 ],
       [-54.92748072],
       [-54.93270407],
       [-54.93458181],
       [-54.93491383],
       [-54.93614218],
       [-54.93644297],
       [-54.9283378 ],
       [-54.93430123],
       [-54.93500825],
       [-54.93507199],
       [-54.93646052],
       [-54.9372144 ]])
(Pdb) tau-archive=0.6727272727272727
eval=6 | not-eval=0 | tau=-0.20 | n_kendall=12 | std(means)/mean(stds)=  0.34 | std(means)=2.26e-03 | mean(stds)=6.73e-03
delta_f=7.7e-04
tau-population=-0.47 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) -54.93797511654934
(Pdb) -54.93621590277447
(Pdb) subset-max-norm=4.1382188293715485 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 152.655 , loss_anch 152.655 tau-train=-0.42
epoch: 400 , mse_ 137.953 , loss_anch 137.953 tau-train= 0.45
epoch: 600 , mse_ 127.25 , loss_anch 127.25 tau-train= 0.49
epoch: 800 , mse_ 117.853 , loss_anch 117.853 tau-train= 0.49
epoch: 1000 , mse_ 109.634 , loss_anch 109.634 tau-train= 0.56

NN: 1
epoch: 200 , mse_ 85.246 , loss_anch 85.246 tau-train= 0.42
epoch: 400 , mse_ 54.461 , loss_anch 54.461 tau-train= 0.42
epoch: 600 , mse_ 40.541 , loss_anch 40.541 tau-train= 0.49
epoch: 800 , mse_ 32.35 , loss_anch 32.35 tau-train= 0.53
epoch: 1000 , mse_ 28.547 , loss_anch 28.547 tau-train= 0.56

NN: 2
epoch: 200 , mse_ 113.612 , loss_anch 113.612 tau-train= 0.60
epoch: 400 , mse_ 93.145 , loss_anch 93.145 tau-train= 0.49
epoch: 600 , mse_ 75.015 , loss_anch 75.015 tau-train= 0.45
epoch: 800 , mse_ 67.623 , loss_anch 67.623 tau-train= 0.45
epoch: 1000 , mse_ 58.511 , loss_anch 58.511 tau-train= 0.45

NN: 3
epoch: 200 , mse_ 79.257 , loss_anch 79.257 tau-train= 0.38
epoch: 400 , mse_ 46.787 , loss_anch 46.787 tau-train= 0.49
epoch: 600 , mse_ 35.096 , loss_anch 35.096 tau-train= 0.53
epoch: 800 , mse_ 29.167 , loss_anch 29.167 tau-train= 0.53
epoch: 1000 , mse_ 26.795 , loss_anch 26.795 tau-train= 0.56

NN: 4
epoch: 200 , mse_ 93.212 , loss_anch 93.212 tau-train= 0.31
epoch: 400 , mse_ 66.752 , loss_anch 66.752 tau-train= 0.42
epoch: 600 , mse_ 49.187 , loss_anch 49.187 tau-train= 0.42
epoch: 800 , mse_ 38.795 , loss_anch 38.795 tau-train= 0.53
epoch: 1000 , mse_ 32.273 , loss_anch 32.273 tau-train= 0.53
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1077)__call__()
-> print(f"tau-train-ens={_tau}")
(Pdb) array([[ 1.01763157],
       [ 0.64257899],
       [ 0.76621318],
       [ 0.33103247],
       [-1.27021063],
       [ 1.09047495],
       [ 0.36480765],
       [ 0.79310005],
       [ 0.34745607],
       [ 0.13309557],
       [-0.00442638],
       [-0.53549026],
       [ 0.99967471],
       [ 0.70937395],
       [ 0.63927488],
       [ 0.41847964],
       [ 0.40793007],
       [ 0.04189001],
       [ 0.71962008],
       [ 0.70157483],
       [ 0.43360323],
       [ 0.18691179],
       [-0.12037642],
       [ 0.55171947],
       [ 0.27594026],
       [ 0.21815176],
       [-0.03043011],
       [-0.10203822],
       [ 0.99668731],
       [ 0.32229882],
       [ 0.20108925],
       [ 0.18940355],
       [-0.10637808],
       [-0.31323611],
       [-0.32673112],
       [-0.39651297],
       [-0.40202798],
       [-0.53484927],
       [-0.57266034],
       [-0.57706345]])
(Pdb) tau-train-ens=0.5272727272727272
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1079)__call__()
-> def raf(features):
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()
-> return raf
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()-><function Raf...x7fd7a601e670>
-> return raf
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1544)__call__()
-> model = (
(Pdb) array([[-54.92808049],
       [-54.93196305],
       [-54.93084025],
       [-54.9342469 ],
       [-54.93923499],
       [-54.92714243],
       [-54.93403227],
       [-54.93057714],
       [-54.93414344],
       [-54.9353689 ],
       [-54.93602751],
       [-54.93786815],
       [-54.92830142],
       [-54.9313737 ],
       [-54.93199119],
       [-54.93367593],
       [-54.93374749],
       [-54.93581573],
       [-54.93127977],
       [-54.93144456],
       [-54.93357202],
       [-54.93508548],
       [-54.9365166 ],
       [-54.93270407],
       [-54.93458181],
       [-54.93491383],
       [-54.93614218],
       [-54.93644297],
       [-54.9283378 ],
       [-54.93430123],
       [-54.93500825],
       [-54.93507199],
       [-54.93646052],
       [-54.9372144 ],
       [-54.93725837],
       [-54.93747652],
       [-54.93749312],
       [-54.93786647],
       [-54.937964  ],
       [-54.93797512]])
(Pdb) tau-archive=0.5272727272727272
eval=6 | not-eval=0 | tau=-0.20 | n_kendall=12 | std(means)/mean(stds)=  0.54 | std(means)=2.84e-03 | mean(stds)=5.28e-03
delta_f=3.6e-04
tau-population=-0.33 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) -54.93963708351362
(Pdb) -54.93776457444546
(Pdb) subset-max-norm=3.259323684922349 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1187.102 , loss_anch 1187.102 tau-train= 0.75
epoch: 400 , mse_ 1093.212 , loss_anch 1093.212 tau-train= 0.78
epoch: 600 , mse_ 999.246 , loss_anch 999.246 tau-train= 0.82
epoch: 800 , mse_ 902.584 , loss_anch 902.584 tau-train= 0.82
epoch: 1000 , mse_ 801.582 , loss_anch 801.582 tau-train= 0.82

NN: 1
epoch: 200 , mse_ 1061.773 , loss_anch 1061.773 tau-train= 0.75
epoch: 400 , mse_ 662.742 , loss_anch 662.742 tau-train= 0.75
epoch: 600 , mse_ 300.529 , loss_anch 300.529 tau-train= 0.78
epoch: 800 , mse_ 226.153 , loss_anch 226.153 tau-train= 0.78
epoch: 1000 , mse_ 200.314 , loss_anch 200.314 tau-train= 0.75

NN: 2
epoch: 200 , mse_ 1137.947 , loss_anch 1137.947 tau-train= 0.78
epoch: 400 , mse_ 919.885 , loss_anch 919.885 tau-train= 0.75
epoch: 600 , mse_ 696.399 , loss_anch 696.399 tau-train= 0.71
epoch: 800 , mse_ 494.502 , loss_anch 494.502 tau-train= 0.71
epoch: 1000 , mse_ 352.368 , loss_anch 352.368 tau-train= 0.75

NN: 3
epoch: 200 , mse_ 999.265 , loss_anch 999.265 tau-train= 0.78
epoch: 400 , mse_ 533.955 , loss_anch 533.955 tau-train= 0.75
epoch: 600 , mse_ 226.632 , loss_anch 226.632 tau-train= 0.75
epoch: 800 , mse_ 155.482 , loss_anch 155.482 tau-train= 0.67
epoch: 1000 , mse_ 136.062 , loss_anch 136.062 tau-train= 0.67

NN: 4
epoch: 200 , mse_ 648.252 , loss_anch 648.252 tau-train= 0.71
epoch: 400 , mse_ 185.361 , loss_anch 185.361 tau-train= 0.67
epoch: 600 , mse_ 145.626 , loss_anch 145.626 tau-train= 0.67
epoch: 800 , mse_ 126.082 , loss_anch 126.082 tau-train= 0.67
epoch: 1000 , mse_ 106.397 , loss_anch 106.397 tau-train= 0.71
tau-train-ens=0.7454545454545454
tau-archive=0.7454545454545454
eval=6 | not-eval=0 | tau= 0.11 | n_kendall=12 | std(means)/mean(stds)=  0.93 | std(means)=1.04e-02 | mean(stds)=1.13e-02
delta_f=3.6e-04
tau-population=-0.07 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) 9.439061673077731e-05
(Pdb) -54.93952787091308
(Pdb) -54.93962226152981
(Pdb) *** SyntaxError: invalid syntax
(Pdb) -9.439061673077731e-05
(Pdb) subset-max-norm=1.3796687538929628 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1121.064 , loss_anch 1121.064 tau-train= 0.38
epoch: 400 , mse_ 963.878 , loss_anch 963.878 tau-train= 0.42
epoch: 600 , mse_ 868.379 , loss_anch 868.379 tau-train= 0.45
epoch: 800 , mse_ 812.257 , loss_anch 812.257 tau-train= 0.49
epoch: 1000 , mse_ 774.265 , loss_anch 774.265 tau-train= 0.45

NN: 1
epoch: 200 , mse_ 770.3 , loss_anch 770.3 tau-train= 0.49
epoch: 400 , mse_ 663.71 , loss_anch 663.71 tau-train= 0.56
epoch: 600 , mse_ 582.11 , loss_anch 582.11 tau-train= 0.60
epoch: 800 , mse_ 522.559 , loss_anch 522.559 tau-train= 0.60
epoch: 1000 , mse_ 456.308 , loss_anch 456.308 tau-train= 0.60

NN: 2
epoch: 200 , mse_ 860.766 , loss_anch 860.766 tau-train= 0.45
epoch: 400 , mse_ 763.624 , loss_anch 763.624 tau-train= 0.53
epoch: 600 , mse_ 716.075 , loss_anch 716.075 tau-train= 0.56
epoch: 800 , mse_ 659.198 , loss_anch 659.198 tau-train= 0.56
epoch: 1000 , mse_ 610.409 , loss_anch 610.409 tau-train= 0.56

NN: 3
epoch: 200 , mse_ 720.547 , loss_anch 720.547 tau-train= 0.53
epoch: 400 , mse_ 590.503 , loss_anch 590.503 tau-train= 0.56
epoch: 600 , mse_ 494.465 , loss_anch 494.465 tau-train= 0.56
epoch: 800 , mse_ 405.353 , loss_anch 405.353 tau-train= 0.60
epoch: 1000 , mse_ 336.964 , loss_anch 336.964 tau-train= 0.60

NN: 4
epoch: 200 , mse_ 662.837 , loss_anch 662.837 tau-train= 0.53
epoch: 400 , mse_ 554.429 , loss_anch 554.429 tau-train= 0.60
epoch: 600 , mse_ 476.781 , loss_anch 476.781 tau-train= 0.60
epoch: 800 , mse_ 392.114 , loss_anch 392.114 tau-train= 0.64
epoch: 1000 , mse_ 318.358 , loss_anch 318.358 tau-train= 0.64
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1077)__call__()
-> print(f"tau-train-ens={_tau}")
(Pdb) *** NameError: name '_values_true' is not defined
(Pdb) 956  	    def __call__(
957  	        self,
958  	        *,
959  	        x_train: NDArray[np.float64],
960  	        y_train: NDArray[np.float64],
961  	        x_test: NDArray[np.float64],
962  	        weights: Optional[NDArray[np.float64]] = None,
963  	    ) -> Model:
964  	        data_noise = self.__data_noise
965  	        """Taken form `RAFs <https://github.com/YanasGH/RAFs/blob/6a0ec46a7d9cd830e7d8e74358643aee1f65323d/main_experiments/rafs.py#L94-L157>`_"""
966  	        X_train, y_train, X_val = x_train, y_train, x_test
967  	
968  	        n = X_train.shape[0]
969  	        x_dim = X_train.shape[1]
970  	        y_dim = y_train.shape[1]
971  	        if __debug__ and self.__debug:
972  	            _max_model_size = max(
973  	                x_test.shape[0], x_dim * (x_dim + 3) + 2
974  	            )
975  	            _n_kendall_archive = min(15, _max_model_size) - 1
976  	
977  	        n_ensembles = 5
978  	        hidden_size = 100
979  	        init_stddev_1_w = np.sqrt(10)
980  	        init_stddev_1_b = init_stddev_1_w  # set these equal
981  	        init_stddev_2_w = 1.0 / np.sqrt(hidden_size)  # normal scaling
982  	        lambda_anchor = data_noise / (
983  	            np.array([init_stddev_1_w, init_stddev_1_b, init_stddev_2_w]) ** 2
984  	        )
985  	
986  	        n_epochs = self.__epochs
987  	        learning_rate = 0.01
988  	
989  	        NNs = []
990  	        y_prior = []
991  	        tf.reset_default_graph()
992  	        sess = tf.Session()
993  	
994  	        # loop to initialise all ensemble members, get priors
995  	        for ens in range(0, n_ensembles):
996  	            NNs.append(
997  	                NN(
998  	                    x_dim,
999  	                    y_dim,
1000 	                    hidden_size,
1001 	                    init_stddev_1_w,
1002 	                    init_stddev_1_b,
1003 	                    init_stddev_2_w,
1004 	                    n,
1005 	                    learning_rate,
1006 	                    ens,
1007 	                )
1008 	            )
1009 	
1010 	            # initialise only unitialized variables - stops overwriting ensembles already created
1011 	            global_vars = tf.global_variables()
1012 	            is_not_initialized = sess.run(
1013 	                [tf.is_variable_initialized(var) for var in global_vars]
1014 	            )
1015 	            not_initialized_vars = [
1016 	                v for (v, f) in zip(global_vars, is_not_initialized) if not f
1017 	            ]
1018 	            if len(not_initialized_vars):
1019 	                sess.run(tf.variables_initializer(not_initialized_vars))
1020 	
1021 	            # do regularisation now that we've created initialisations
1022 	            NNs[ens].anchor(
1023 	                sess, lambda_anchor
1024 	            )  # Do that if you want to minimize the anchored loss
1025 	
1026 	            # save their priors
1027 	            y_prior.append(NNs[ens].predict(X_val, sess))
1028 	
1029 	        for ens in range(0, n_ensembles):
1030 	            feed_b = {}
1031 	            feed_b[NNs[ens].inputs] = X_train
1032 	            feed_b[NNs[ens].y_target] = y_train
1033 	            if __debug__ and self.__debug:
1034 	                print("\nNN:", ens)
1035 	
1036 	            ep_ = 0
1037 	            while ep_ < n_epochs:
1038 	                ep_ += 1
1039 	                blank = sess.run(NNs[ens].optimizer, feed_dict=feed_b)  # noqa: F841
1040 	                if ep_ % (n_epochs / 5) == 0:
1041 	                    loss_mse = sess.run(NNs[ens].mse_, feed_dict=feed_b)
1042 	                    loss_anch = sess.run(NNs[ens].loss_, feed_dict=feed_b)
1043 	                    if __debug__ and self.__debug:
1044 	                        print(
1045 	                            "epoch:",
1046 	                            ep_,
1047 	                            ", mse_",
1048 	                            np.round(loss_mse * 1e3, 3),
1049 	                            ", loss_anch",
1050 	                            np.round(loss_anch * 1e3, 3),
1051 	                            "tau-train={:>5.2f}".format(
1052 	                                kendalltau(
1053 	                                    y_train[-_n_kendall_archive:],  # pyright: ignore [reportOperatorIssue,reportPossiblyUnboundVariable]
1054 	                                    np.array(
1055 	                                        NNs[ens].predict(
1056 	                                            X_train[-_n_kendall_archive:],  # pyright: ignore [reportOperatorIssue,reportPossiblyUnboundVariable]
1057 	                                            sess,
1058 	                                        )
1059 	                                    ),
1060 	                                ).statistic
1061 	                            ),
1062 	                        )
1063 	                    # the anchored loss is minimized, but it's useful to keep an eye on mse too
1064 	
1065 	        if __debug__ and self.__debug:
1066 	            _tau = kendalltau(
1067 	                y_train[-_n_kendall_archive:],  # pyright: ignore [reportOperatorIssue,reportPossiblyUnboundVariable]
1068 	                np.mean(
1069 	                    np.array(
1070 	                        [nn.predict(X_train[-_n_kendall_archive:], sess) for nn in NNs]  # pyright: ignore [reportOperatorIssue,reportPossiblyUnboundVariable]
1071 	                    ),
1072 	                    axis=0,
1073 	                ),
1074 	            ).statistic
1075 	            if _tau < 0.7:
1076 	                breakpoint()
1077 ->	            print(f"tau-train-ens={_tau}")
1078 	
1079 	        def raf(features):
1080 	            y_pred = np.array([nn.predict(features, sess) for nn in NNs])
1081 	            return Prediction(
1082 	                np.mean(y_pred, axis=0),
1083 	                np.sqrt(np.square(np.std(y_pred, axis=0, ddof=1)) + data_noise),
1084 	            )
1085 	
1086 	        return raf
(Pdb) array([[ 0.56129151],
       [-1.9995386 ],
       [ 1.07941718],
       [ 0.75700415],
       [ 0.58025024],
       [ 0.32865111],
       [ 0.16171027],
       [-0.54708236],
       [ 0.2184888 ],
       [ 0.97895626],
       [ 0.39271744],
       [ 0.01677683],
       [ 0.81237074],
       [ 0.4973344 ],
       [ 0.12956601],
       [ 0.03998408],
       [ 1.29995676],
       [ 0.55119003],
       [ 0.40948796],
       [ 0.3956681 ],
       [ 0.03450212],
       [-0.23491689],
       [-0.25311689],
       [-0.34865604],
       [-0.35631412],
       [-0.54613892],
       [-0.6022911 ],
       [-0.60889801],
       [ 0.2841281 ],
       [-0.52491931],
       [-0.69459042],
       [-0.79899408],
       [-4.60363928],
       [-5.29678646],
       [-0.00692697],
       [-0.85562143],
       [-0.90879881],
       [-1.21484585],
       [-2.18606096],
       [-3.20835388]])
(Pdb) tau-train-ens=0.6000000000000001
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1079)__call__()
-> def raf(features):
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()
-> return raf
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()-><function Raf...x7fd7786ad1f0>
-> return raf
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1544)__call__()
-> model = (
(Pdb) array([[-54.9342469 ],
       [-54.93923499],
       [-54.93057714],
       [-54.93307833],
       [-54.93414344],
       [-54.9353689 ],
       [-54.93602751],
       [-54.93786815],
       [-54.93581573],
       [-54.93144456],
       [-54.93508548],
       [-54.9365166 ],
       [-54.93270407],
       [-54.93458181],
       [-54.93614218],
       [-54.93644297],
       [-54.9283378 ],
       [-54.93430123],
       [-54.93500825],
       [-54.93507199],
       [-54.93646052],
       [-54.9372144 ],
       [-54.93725837],
       [-54.93747652],
       [-54.93749312],
       [-54.93786647],
       [-54.937964  ],
       [-54.93797512],
       [-54.93555544],
       [-54.93782817],
       [-54.93811287],
       [-54.93826551],
       [-54.93962164],
       [-54.93963708],
       [-54.93659006],
       [-54.93834187],
       [-54.93840975],
       [-54.9387374 ],
       [-54.93930604],
       [-54.93952787]])
(Pdb) tau-archive=0.6000000000000001
eval=6 | not-eval=0 | tau= 0.60 | n_kendall=12 | std(means)/mean(stds)=  0.26 | std(means)=2.18e-03 | mean(stds)=8.30e-03
delta_f=3.6e-04
tau-population= 0.20 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) -2.2019638905135253e-05
(Pdb) -54.9396079634313
(Pdb) -54.939585943792395
(Pdb) subset-max-norm=3.1896091380537994 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1017.756 , loss_anch 1017.756 tau-train= 0.67
epoch: 400 , mse_ 878.165 , loss_anch 878.165 tau-train= 0.67
epoch: 600 , mse_ 793.792 , loss_anch 793.792 tau-train= 0.67
epoch: 800 , mse_ 736.646 , loss_anch 736.646 tau-train= 0.67
epoch: 1000 , mse_ 697.826 , loss_anch 697.826 tau-train= 0.67

NN: 1
epoch: 200 , mse_ 617.533 , loss_anch 617.533 tau-train= 0.64
epoch: 400 , mse_ 512.942 , loss_anch 512.942 tau-train= 0.71
epoch: 600 , mse_ 444.476 , loss_anch 444.476 tau-train= 0.78
epoch: 800 , mse_ 383.127 , loss_anch 383.127 tau-train= 0.85
epoch: 1000 , mse_ 321.85 , loss_anch 321.85 tau-train= 0.89

NN: 2
epoch: 200 , mse_ 803.926 , loss_anch 803.926 tau-train= 0.64
epoch: 400 , mse_ 704.264 , loss_anch 704.264 tau-train= 0.67
epoch: 600 , mse_ 672.187 , loss_anch 672.187 tau-train= 0.67
epoch: 800 , mse_ 647.775 , loss_anch 647.775 tau-train= 0.71
epoch: 1000 , mse_ 628.903 , loss_anch 628.903 tau-train= 0.71

NN: 3
epoch: 200 , mse_ 558.51 , loss_anch 558.51 tau-train= 0.71
epoch: 400 , mse_ 450.601 , loss_anch 450.601 tau-train= 0.82
epoch: 600 , mse_ 353.799 , loss_anch 353.799 tau-train= 0.89
epoch: 800 , mse_ 264.136 , loss_anch 264.136 tau-train= 0.93
epoch: 1000 , mse_ 209.872 , loss_anch 209.872 tau-train= 0.96

NN: 4
epoch: 200 , mse_ 586.329 , loss_anch 586.329 tau-train= 0.75
epoch: 400 , mse_ 483.621 , loss_anch 483.621 tau-train= 0.78
epoch: 600 , mse_ 418.574 , loss_anch 418.574 tau-train= 0.82
epoch: 800 , mse_ 353.843 , loss_anch 353.843 tau-train= 0.89
epoch: 1000 , mse_ 277.143 , loss_anch 277.143 tau-train= 0.89
tau-train-ens=0.8545454545454545
tau-archive=0.8545454545454545
eval=1 | not-eval=5 | tau= 0.88 | n_kendall=12 | std(means)/mean(stds)=  0.16 | std(means)=1.28e-03 | mean(stds)=8.16e-03
delta_f=3.2e-04
tau-population= 0.07 | tau-pop-offset= 0.20 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) -0.00019809933930048373
(Pdb) subset-max-norm=4.157502793795851 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 451.811 , loss_anch 451.811 tau-train= 0.71
epoch: 400 , mse_ 405.987 , loss_anch 405.987 tau-train= 0.75
epoch: 600 , mse_ 383.037 , loss_anch 383.037 tau-train= 0.71
epoch: 800 , mse_ 366.002 , loss_anch 366.002 tau-train= 0.71
epoch: 1000 , mse_ 353.472 , loss_anch 353.472 tau-train= 0.75

NN: 1
epoch: 200 , mse_ 316.648 , loss_anch 316.648 tau-train= 0.78
epoch: 400 , mse_ 275.2 , loss_anch 275.2 tau-train= 0.85
epoch: 600 , mse_ 234.927 , loss_anch 234.927 tau-train= 0.93
epoch: 800 , mse_ 180.385 , loss_anch 180.385 tau-train= 0.96
epoch: 1000 , mse_ 125.478 , loss_anch 125.478 tau-train= 0.96

NN: 2
epoch: 200 , mse_ 472.03 , loss_anch 472.03 tau-train= 0.67
epoch: 400 , mse_ 389.451 , loss_anch 389.451 tau-train= 0.71
epoch: 600 , mse_ 360.36 , loss_anch 360.36 tau-train= 0.75
epoch: 800 , mse_ 341.037 , loss_anch 341.037 tau-train= 0.82
epoch: 1000 , mse_ 319.815 , loss_anch 319.815 tau-train= 0.82

NN: 3
epoch: 200 , mse_ 339.285 , loss_anch 339.285 tau-train= 0.75
epoch: 400 , mse_ 291.611 , loss_anch 291.611 tau-train= 0.78
epoch: 600 , mse_ 245.198 , loss_anch 245.198 tau-train= 0.82
epoch: 800 , mse_ 192.122 , loss_anch 192.122 tau-train= 0.89
epoch: 1000 , mse_ 137.271 , loss_anch 137.271 tau-train= 0.93

NN: 4
epoch: 200 , mse_ 352.721 , loss_anch 352.721 tau-train= 0.75
epoch: 400 , mse_ 308.895 , loss_anch 308.895 tau-train= 0.78
epoch: 600 , mse_ 273.991 , loss_anch 273.991 tau-train= 0.85
epoch: 800 , mse_ 236.07 , loss_anch 236.07 tau-train= 0.85
epoch: 1000 , mse_ 190.052 , loss_anch 190.052 tau-train= 0.89
tau-train-ens=0.8545454545454545
tau-archive=0.8545454545454545
eval=6 | not-eval=0 | tau= 0.07 | n_kendall=12 | std(means)/mean(stds)=  0.39 | std(means)=1.48e-03 | mean(stds)=3.75e-03
delta_f=1.2e-05
tau-population=-0.20 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) -0.0003461598950806888
(Pdb) subset-max-norm=4.588688443569931 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 550.563 , loss_anch 550.563 tau-train= 0.64
epoch: 400 , mse_ 487.785 , loss_anch 487.785 tau-train= 0.67
epoch: 600 , mse_ 458.133 , loss_anch 458.133 tau-train= 0.67
epoch: 800 , mse_ 437.81 , loss_anch 437.81 tau-train= 0.71
epoch: 1000 , mse_ 422.444 , loss_anch 422.444 tau-train= 0.71

NN: 1
epoch: 200 , mse_ 366.913 , loss_anch 366.913 tau-train= 0.71
epoch: 400 , mse_ 327.541 , loss_anch 327.541 tau-train= 0.71
epoch: 600 , mse_ 259.769 , loss_anch 259.769 tau-train= 0.75
epoch: 800 , mse_ 160.541 , loss_anch 160.541 tau-train= 0.82
epoch: 1000 , mse_ 90.443 , loss_anch 90.443 tau-train= 0.85

NN: 2
epoch: 200 , mse_ 515.212 , loss_anch 515.212 tau-train= 0.67
epoch: 400 , mse_ 473.061 , loss_anch 473.061 tau-train= 0.71
epoch: 600 , mse_ 440.337 , loss_anch 440.337 tau-train= 0.67
epoch: 800 , mse_ 418.92 , loss_anch 418.92 tau-train= 0.71
epoch: 1000 , mse_ 407.48 , loss_anch 407.48 tau-train= 0.71

NN: 3
epoch: 200 , mse_ 363.201 , loss_anch 363.201 tau-train= 0.71
epoch: 400 , mse_ 283.065 , loss_anch 283.065 tau-train= 0.71
epoch: 600 , mse_ 181.488 , loss_anch 181.488 tau-train= 0.75
epoch: 800 , mse_ 127.366 , loss_anch 127.366 tau-train= 0.75
epoch: 1000 , mse_ 100.785 , loss_anch 100.785 tau-train= 0.82

NN: 4
epoch: 200 , mse_ 363.07 , loss_anch 363.07 tau-train= 0.75
epoch: 400 , mse_ 302.466 , loss_anch 302.466 tau-train= 0.75
epoch: 600 , mse_ 199.361 , loss_anch 199.361 tau-train= 0.78
epoch: 800 , mse_ 114.602 , loss_anch 114.602 tau-train= 0.78
epoch: 1000 , mse_ 78.208 , loss_anch 78.208 tau-train= 0.85
tau-train-ens=0.7818181818181819
tau-archive=0.7818181818181819
eval=6 | not-eval=0 | tau= 0.29 | n_kendall=12 | std(means)/mean(stds)=  0.07 | std(means)=3.45e-04 | mean(stds)=4.90e-03
delta_f=9.2e-06
tau-population= 0.07 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) 3.868152695929439e-06
(Pdb) subset-max-norm=5.219157085973877 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1117.969 , loss_anch 1117.969 tau-train= 0.56
epoch: 400 , mse_ 1033.661 , loss_anch 1033.661 tau-train= 0.67
epoch: 600 , mse_ 977.141 , loss_anch 977.141 tau-train= 0.67
epoch: 800 , mse_ 934.366 , loss_anch 934.366 tau-train= 0.71
epoch: 1000 , mse_ 905.951 , loss_anch 905.951 tau-train= 0.75

NN: 1
epoch: 200 , mse_ 648.11 , loss_anch 648.11 tau-train= 0.71
epoch: 400 , mse_ 528.847 , loss_anch 528.847 tau-train= 0.78
epoch: 600 , mse_ 440.511 , loss_anch 440.511 tau-train= 0.75
epoch: 800 , mse_ 341.547 , loss_anch 341.547 tau-train= 0.75
epoch: 1000 , mse_ 247.687 , loss_anch 247.687 tau-train= 0.85

NN: 2
epoch: 200 , mse_ 858.278 , loss_anch 858.278 tau-train= 0.75
epoch: 400 , mse_ 713.179 , loss_anch 713.179 tau-train= 0.75
epoch: 600 , mse_ 639.818 , loss_anch 639.818 tau-train= 0.67
epoch: 800 , mse_ 632.577 , loss_anch 632.577 tau-train= 0.75
epoch: 1000 , mse_ 553.626 , loss_anch 553.626 tau-train= 0.82

NN: 3
epoch: 200 , mse_ 716.675 , loss_anch 716.675 tau-train= 0.75
epoch: 400 , mse_ 551.635 , loss_anch 551.635 tau-train= 0.75
epoch: 600 , mse_ 469.668 , loss_anch 469.668 tau-train= 0.78
epoch: 800 , mse_ 385.641 , loss_anch 385.641 tau-train= 0.75
epoch: 1000 , mse_ 299.748 , loss_anch 299.748 tau-train= 0.82

NN: 4
epoch: 200 , mse_ 570.301 , loss_anch 570.301 tau-train= 0.78
epoch: 400 , mse_ 414.698 , loss_anch 414.698 tau-train= 0.75
epoch: 600 , mse_ 301.407 , loss_anch 301.407 tau-train= 0.78
epoch: 800 , mse_ 217.836 , loss_anch 217.836 tau-train= 0.89
epoch: 1000 , mse_ 162.442 , loss_anch 162.442 tau-train= 0.93
tau-train-ens=0.8545454545454545
tau-archive=0.8545454545454545
eval=6 | not-eval=0 | tau=-0.07 | n_kendall=12 | std(means)/mean(stds)=  0.05 | std(means)=4.05e-04 | mean(stds)=8.96e-03
delta_f=9.2e-06
tau-population=-0.60 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) -4.459653744959269e-05
(Pdb) subset-max-norm=6.109019340145485 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 795.544 , loss_anch 795.544 tau-train= 0.31
epoch: 400 , mse_ 751.523 , loss_anch 751.523 tau-train= 0.35
epoch: 600 , mse_ 719.662 , loss_anch 719.662 tau-train= 0.31
epoch: 800 , mse_ 691.881 , loss_anch 691.881 tau-train= 0.35
epoch: 1000 , mse_ 667.299 , loss_anch 667.299 tau-train= 0.35

NN: 1
epoch: 200 , mse_ 530.492 , loss_anch 530.492 tau-train= 0.49
epoch: 400 , mse_ 413.74 , loss_anch 413.74 tau-train= 0.56
epoch: 600 , mse_ 283.856 , loss_anch 283.856 tau-train= 0.67
epoch: 800 , mse_ 209.142 , loss_anch 209.142 tau-train= 0.75
epoch: 1000 , mse_ 165.657 , loss_anch 165.657 tau-train= 0.71

NN: 2
epoch: 200 , mse_ 729.507 , loss_anch 729.507 tau-train= 0.35
epoch: 400 , mse_ 656.191 , loss_anch 656.191 tau-train= 0.35
epoch: 600 , mse_ 623.384 , loss_anch 623.384 tau-train= 0.42
epoch: 800 , mse_ 595.124 , loss_anch 595.124 tau-train= 0.42
epoch: 1000 , mse_ 576.136 , loss_anch 576.136 tau-train= 0.42

NN: 3
epoch: 200 , mse_ 544.842 , loss_anch 544.842 tau-train= 0.49
epoch: 400 , mse_ 448.755 , loss_anch 448.755 tau-train= 0.56
epoch: 600 , mse_ 342.817 , loss_anch 342.817 tau-train= 0.64
epoch: 800 , mse_ 265.802 , loss_anch 265.802 tau-train= 0.71
epoch: 1000 , mse_ 218.054 , loss_anch 218.054 tau-train= 0.75

NN: 4
epoch: 200 , mse_ 513.566 , loss_anch 513.566 tau-train= 0.49
epoch: 400 , mse_ 429.804 , loss_anch 429.804 tau-train= 0.56
epoch: 600 , mse_ 331.077 , loss_anch 331.077 tau-train= 0.64
epoch: 800 , mse_ 229.462 , loss_anch 229.462 tau-train= 0.75
epoch: 1000 , mse_ 157.091 , loss_anch 157.091 tau-train= 0.71
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1077)__call__()
-> print(f"tau-train-ens={_tau}")
(Pdb) array([[ 0.27890532],
       [ 2.08677327],
       [ 2.16186914],
       [ 1.47843209],
       [ 1.31009254],
       [ 1.26315522],
       [ 1.25766119],
       [ 1.32794127],
       [ 1.18696794],
       [ 1.10231732],
       [-0.43402778],
       [-0.47645032],
       [ 1.05711892],
       [ 1.01515211],
       [ 0.78335255],
       [ 0.18054688],
       [-0.20911554],
       [ 1.26973717],
       [ 1.04079399],
       [ 0.52139758],
       [-0.39789961],
       [-0.59213438],
       [ 1.69773988],
       [ 1.37993177],
       [ 1.30935029],
       [-0.96380889],
       [-2.81316817],
       [-4.69140688],
       [-0.47126869],
       [-0.68034317],
       [-0.95080259],
       [-1.08759165],
       [-1.73533896],
       [-5.38455406],
       [-1.51480988],
       [-2.07857442],
       [-2.1200229 ],
       [-2.63546526],
       [-3.32058983],
       [-3.76777923]])
(Pdb) tau-train-ens=0.6727272727272727
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1079)__call__()
-> def raf(features):
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()
-> return raf
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()-><function Raf...x7fd7786adca0>
-> return raf
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1544)__call__()
-> model = (
(Pdb) array([[-54.93923499],
       [-54.9353689 ],
       [-54.93500825],
       [-54.93747652],
       [-54.93786647],
       [-54.937964  ],
       [-54.93797512],
       [-54.93782817],
       [-54.93811287],
       [-54.93826551],
       [-54.93962164],
       [-54.93963708],
       [-54.93834187],
       [-54.93840975],
       [-54.9387374 ],
       [-54.93930604],
       [-54.93952787],
       [-54.9379506 ],
       [-54.93836861],
       [-54.93902686],
       [-54.93960796],
       [-54.93967601],
       [-54.93685933],
       [-54.93771261],
       [-54.93786805],
       [-54.93977455],
       [-54.93995899],
       [-54.93998817],
       [-54.93963523],
       [-54.93970281],
       [-54.93977168],
       [-54.93980003],
       [-54.93989224],
       [-54.9399908 ],
       [-54.93986727],
       [-54.93992164],
       [-54.93992455],
       [-54.93995229],
       [-54.9399727 ],
       [-54.93998017]])
(Pdb) tau-archive=0.6727272727272727
eval=6 | not-eval=0 | tau= 0.56 | n_kendall=12 | std(means)/mean(stds)=  0.17 | std(means)=1.39e-04 | mean(stds)=8.07e-04
delta_f=5.7e-06
tau-population= 0.33 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=7.703641174897052 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 757.752 , loss_anch 757.752 tau-train= 0.45
epoch: 400 , mse_ 732.399 , loss_anch 732.399 tau-train= 0.45
epoch: 600 , mse_ 716.716 , loss_anch 716.716 tau-train= 0.45
epoch: 800 , mse_ 702.477 , loss_anch 702.477 tau-train= 0.45
epoch: 1000 , mse_ 690.566 , loss_anch 690.566 tau-train= 0.45

NN: 1
epoch: 200 , mse_ 443.151 , loss_anch 443.151 tau-train= 0.67
epoch: 400 , mse_ 285.475 , loss_anch 285.475 tau-train= 0.85
epoch: 600 , mse_ 142.772 , loss_anch 142.772 tau-train= 0.89
epoch: 800 , mse_ 108.175 , loss_anch 108.175 tau-train= 0.89
epoch: 1000 , mse_ 97.425 , loss_anch 97.425 tau-train= 0.82

NN: 2
epoch: 200 , mse_ 724.769 , loss_anch 724.769 tau-train= 0.45
epoch: 400 , mse_ 702.84 , loss_anch 702.84 tau-train= 0.45
epoch: 600 , mse_ 690.581 , loss_anch 690.581 tau-train= 0.45
epoch: 800 , mse_ 679.263 , loss_anch 679.263 tau-train= 0.45
epoch: 1000 , mse_ 667.705 , loss_anch 667.705 tau-train= 0.45

NN: 3
epoch: 200 , mse_ 532.011 , loss_anch 532.011 tau-train= 0.56
epoch: 400 , mse_ 403.406 , loss_anch 403.406 tau-train= 0.60
epoch: 600 , mse_ 300.109 , loss_anch 300.109 tau-train= 0.67
epoch: 800 , mse_ 198.163 , loss_anch 198.163 tau-train= 0.71
epoch: 1000 , mse_ 149.392 , loss_anch 149.392 tau-train= 0.82

NN: 4
epoch: 200 , mse_ 456.723 , loss_anch 456.723 tau-train= 0.67
epoch: 400 , mse_ 308.785 , loss_anch 308.785 tau-train= 0.71
epoch: 600 , mse_ 164.248 , loss_anch 164.248 tau-train= 0.85
epoch: 800 , mse_ 132.177 , loss_anch 132.177 tau-train= 0.85
epoch: 1000 , mse_ 116.751 , loss_anch 116.751 tau-train= 0.82
tau-train-ens=0.7090909090909091
tau-archive=0.7090909090909091
eval=6 | not-eval=0 | tau= 0.82 | n_kendall=12 | std(means)/mean(stds)=  0.04 | std(means)=1.22e-04 | mean(stds)=3.21e-03
delta_f=5.7e-06
tau-population= 1.00 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=11.175175084367162 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1349.35 , loss_anch 1349.35 tau-train= 0.78
epoch: 400 , mse_ 1272.673 , loss_anch 1272.673 tau-train= 0.75
epoch: 600 , mse_ 1226.247 , loss_anch 1226.247 tau-train= 0.78
epoch: 800 , mse_ 1314.958 , loss_anch 1314.958 tau-train= 0.67
epoch: 1000 , mse_ 1150.679 , loss_anch 1150.679 tau-train= 0.75

NN: 1
epoch: 200 , mse_ 646.739 , loss_anch 646.739 tau-train= 0.78
epoch: 400 , mse_ 326.356 , loss_anch 326.356 tau-train= 0.82
epoch: 600 , mse_ 245.483 , loss_anch 245.483 tau-train= 0.82
epoch: 800 , mse_ 216.533 , loss_anch 216.533 tau-train= 0.82
epoch: 1000 , mse_ 197.255 , loss_anch 197.255 tau-train= 0.82

NN: 2
epoch: 200 , mse_ 1431.549 , loss_anch 1431.549 tau-train= 0.75
epoch: 400 , mse_ 1337.062 , loss_anch 1337.062 tau-train= 0.78
epoch: 600 , mse_ 1293.74 , loss_anch 1293.74 tau-train= 0.78
epoch: 800 , mse_ 1258.903 , loss_anch 1258.903 tau-train= 0.78
epoch: 1000 , mse_ 1228.566 , loss_anch 1228.566 tau-train= 0.75

NN: 3
epoch: 200 , mse_ 580.261 , loss_anch 580.261 tau-train= 0.75
epoch: 400 , mse_ 307.612 , loss_anch 307.612 tau-train= 0.78
epoch: 600 , mse_ 226.463 , loss_anch 226.463 tau-train= 0.85
epoch: 800 , mse_ 192.814 , loss_anch 192.814 tau-train= 0.85
epoch: 1000 , mse_ 175.347 , loss_anch 175.347 tau-train= 0.85

NN: 4
epoch: 200 , mse_ 660.441 , loss_anch 660.441 tau-train= 0.75
epoch: 400 , mse_ 339.06 , loss_anch 339.06 tau-train= 0.82
epoch: 600 , mse_ 253.905 , loss_anch 253.905 tau-train= 0.82
epoch: 800 , mse_ 222.615 , loss_anch 222.615 tau-train= 0.85
epoch: 1000 , mse_ 189.704 , loss_anch 189.704 tau-train= 0.85
tau-train-ens=0.8181818181818182
tau-archive=0.8181818181818182
eval=6 | not-eval=0 | tau= 0.42 | n_kendall=12 | std(means)/mean(stds)=  0.13 | std(means)=6.01e-05 | mean(stds)=4.47e-04
delta_f=3.3e-06
tau-population= 0.33 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=10.814383500509074 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 2230.394 , loss_anch 2230.394 tau-train= 0.49
epoch: 400 , mse_ 2110.693 , loss_anch 2110.693 tau-train= 0.53
epoch: 600 , mse_ 2026.837 , loss_anch 2026.837 tau-train= 0.60
epoch: 800 , mse_ 1958.645 , loss_anch 1958.645 tau-train= 0.60
epoch: 1000 , mse_ 1897.256 , loss_anch 1897.256 tau-train= 0.60

NN: 1
epoch: 200 , mse_ 1315.446 , loss_anch 1315.446 tau-train= 0.64
epoch: 400 , mse_ 627.857 , loss_anch 627.857 tau-train= 0.75
epoch: 600 , mse_ 260.372 , loss_anch 260.372 tau-train= 0.85
epoch: 800 , mse_ 176.856 , loss_anch 176.856 tau-train= 0.89
epoch: 1000 , mse_ 152.005 , loss_anch 152.005 tau-train= 0.93

NN: 2
epoch: 200 , mse_ 2297.994 , loss_anch 2297.994 tau-train= 0.56
epoch: 400 , mse_ 2128.456 , loss_anch 2128.456 tau-train= 0.60
epoch: 600 , mse_ 1996.629 , loss_anch 1996.629 tau-train= 0.60
epoch: 800 , mse_ 1895.148 , loss_anch 1895.148 tau-train= 0.60
epoch: 1000 , mse_ 1807.052 , loss_anch 1807.052 tau-train= 0.60

NN: 3
epoch: 200 , mse_ 1399.74 , loss_anch 1399.74 tau-train= 0.64
epoch: 400 , mse_ 868.361 , loss_anch 868.361 tau-train= 0.71
epoch: 600 , mse_ 541.67 , loss_anch 541.67 tau-train= 0.78
epoch: 800 , mse_ 339.634 , loss_anch 339.634 tau-train= 0.85
epoch: 1000 , mse_ 210.835 , loss_anch 210.835 tau-train= 0.85

NN: 4
epoch: 200 , mse_ 831.837 , loss_anch 831.837 tau-train= 0.71
epoch: 400 , mse_ 236.356 , loss_anch 236.356 tau-train= 0.93
epoch: 600 , mse_ 155.509 , loss_anch 155.509 tau-train= 0.96
epoch: 800 , mse_ 143.712 , loss_anch 143.712 tau-train= 1.00
epoch: 1000 , mse_ 131.462 , loss_anch 131.462 tau-train= 1.00
tau-train-ens=0.7818181818181819
tau-archive=0.7818181818181819
eval=6 | not-eval=0 | tau= 0.69 | n_kendall=12 | std(means)/mean(stds)=  0.06 | std(means)=1.99e-05 | mean(stds)=3.08e-04
delta_f=2.1e-06
tau-population= 0.60 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=11.49704006706268 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1545.053 , loss_anch 1545.053 tau-train= 0.60
epoch: 400 , mse_ 1422.34 , loss_anch 1422.34 tau-train= 0.64
epoch: 600 , mse_ 1336.209 , loss_anch 1336.209 tau-train= 0.71
epoch: 800 , mse_ 1274.802 , loss_anch 1274.802 tau-train= 0.60
epoch: 1000 , mse_ 1228.83 , loss_anch 1228.83 tau-train= 0.60

NN: 1
epoch: 200 , mse_ 654.439 , loss_anch 654.439 tau-train= 0.82
epoch: 400 , mse_ 404.056 , loss_anch 404.056 tau-train= 0.82
epoch: 600 , mse_ 290.352 , loss_anch 290.352 tau-train= 0.89
epoch: 800 , mse_ 222.412 , loss_anch 222.412 tau-train= 0.96
epoch: 1000 , mse_ 188.438 , loss_anch 188.438 tau-train= 0.96

NN: 2
epoch: 200 , mse_ 1439.341 , loss_anch 1439.341 tau-train= 0.64
epoch: 400 , mse_ 1320.417 , loss_anch 1320.417 tau-train= 0.64
epoch: 600 , mse_ 1242.484 , loss_anch 1242.484 tau-train= 0.64
epoch: 800 , mse_ 1187.286 , loss_anch 1187.286 tau-train= 0.64
epoch: 1000 , mse_ 1149.712 , loss_anch 1149.712 tau-train= 0.60

NN: 3
epoch: 200 , mse_ 950.587 , loss_anch 950.587 tau-train= 0.78
epoch: 400 , mse_ 585.587 , loss_anch 585.587 tau-train= 0.82
epoch: 600 , mse_ 419.031 , loss_anch 419.031 tau-train= 0.89
epoch: 800 , mse_ 339.786 , loss_anch 339.786 tau-train= 0.89
epoch: 1000 , mse_ 274.112 , loss_anch 274.112 tau-train= 0.93

NN: 4
epoch: 200 , mse_ 622.254 , loss_anch 622.254 tau-train= 0.89
epoch: 400 , mse_ 301.556 , loss_anch 301.556 tau-train= 0.96
epoch: 600 , mse_ 206.118 , loss_anch 206.118 tau-train= 0.93
epoch: 800 , mse_ 162.404 , loss_anch 162.404 tau-train= 0.96
epoch: 1000 , mse_ 136.93 , loss_anch 136.93 tau-train= 0.96
tau-train-ens=0.8909090909090909
tau-archive=0.8909090909090909
eval=6 | not-eval=0 | tau= 0.60 | n_kendall=12 | std(means)/mean(stds)=  1.09 | std(means)=1.19e-04 | mean(stds)=1.09e-04
delta_f=1.1e-06
tau-population= 0.47 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=9.244648600759513 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 831.971 , loss_anch 831.971 tau-train= 0.35
epoch: 400 , mse_ 801.15 , loss_anch 801.15 tau-train= 0.42
epoch: 600 , mse_ 771.689 , loss_anch 771.689 tau-train= 0.45
epoch: 800 , mse_ 749.438 , loss_anch 749.438 tau-train= 0.49
epoch: 1000 , mse_ 731.695 , loss_anch 731.695 tau-train= 0.45

NN: 1
epoch: 200 , mse_ 498.309 , loss_anch 498.309 tau-train= 0.67
epoch: 400 , mse_ 275.989 , loss_anch 275.989 tau-train= 0.82
epoch: 600 , mse_ 189.037 , loss_anch 189.037 tau-train= 0.82
epoch: 800 , mse_ 136.257 , loss_anch 136.257 tau-train= 0.85
epoch: 1000 , mse_ 105.532 , loss_anch 105.532 tau-train= 0.89

NN: 2
epoch: 200 , mse_ 838.914 , loss_anch 838.914 tau-train= 0.35
epoch: 400 , mse_ 817.071 , loss_anch 817.071 tau-train= 0.38
epoch: 600 , mse_ 797.969 , loss_anch 797.969 tau-train= 0.45
epoch: 800 , mse_ 780.186 , loss_anch 780.186 tau-train= 0.45
epoch: 1000 , mse_ 763.435 , loss_anch 763.435 tau-train= 0.49

NN: 3
epoch: 200 , mse_ 459.087 , loss_anch 459.087 tau-train= 0.71
epoch: 400 , mse_ 294.88 , loss_anch 294.88 tau-train= 0.78
epoch: 600 , mse_ 235.334 , loss_anch 235.334 tau-train= 0.82
epoch: 800 , mse_ 188.142 , loss_anch 188.142 tau-train= 0.82
epoch: 1000 , mse_ 150.853 , loss_anch 150.853 tau-train= 0.85

NN: 4
epoch: 200 , mse_ 467.767 , loss_anch 467.767 tau-train= 0.75
epoch: 400 , mse_ 272.899 , loss_anch 272.899 tau-train= 0.78
epoch: 600 , mse_ 207.316 , loss_anch 207.316 tau-train= 0.82
epoch: 800 , mse_ 154.107 , loss_anch 154.107 tau-train= 0.85
epoch: 1000 , mse_ 108.631 , loss_anch 108.631 tau-train= 0.85
tau-train-ens=0.8545454545454545
tau-archive=0.8545454545454545
eval=2 | not-eval=4 | tau= 0.91 | n_kendall=12 | std(means)/mean(stds)=  0.68 | std(means)=3.14e-05 | mean(stds)=4.62e-05
delta_f=1.1e-06
tau-population= 0.47 | tau-pop-offset= 0.20 | final-target-hit=False
subset-max-norm=6.813578947672563 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1416.679 , loss_anch 1416.679 tau-train= 0.56
epoch: 400 , mse_ 1313.408 , loss_anch 1313.408 tau-train= 0.67
epoch: 600 , mse_ 1243.322 , loss_anch 1243.322 tau-train= 0.75
epoch: 800 , mse_ 1188.272 , loss_anch 1188.272 tau-train= 0.75
epoch: 1000 , mse_ 1147.052 , loss_anch 1147.052 tau-train= 0.78

NN: 1
epoch: 200 , mse_ 864.287 , loss_anch 864.287 tau-train= 0.67
epoch: 400 , mse_ 534.034 , loss_anch 534.034 tau-train= 0.78
epoch: 600 , mse_ 400.951 , loss_anch 400.951 tau-train= 0.82
epoch: 800 , mse_ 339.771 , loss_anch 339.771 tau-train= 0.82
epoch: 1000 , mse_ 279.207 , loss_anch 279.207 tau-train= 0.89

NN: 2
epoch: 200 , mse_ 1448.219 , loss_anch 1448.219 tau-train= 0.64
epoch: 400 , mse_ 1286.745 , loss_anch 1286.745 tau-train= 0.75
epoch: 600 , mse_ 1206.459 , loss_anch 1206.459 tau-train= 0.71
epoch: 800 , mse_ 1140.451 , loss_anch 1140.451 tau-train= 0.71
epoch: 1000 , mse_ 1079.675 , loss_anch 1079.675 tau-train= 0.71

NN: 3
epoch: 200 , mse_ 1097.543 , loss_anch 1097.543 tau-train= 0.71
epoch: 400 , mse_ 750.384 , loss_anch 750.384 tau-train= 0.78
epoch: 600 , mse_ 528.866 , loss_anch 528.866 tau-train= 0.85
epoch: 800 , mse_ 448.327 , loss_anch 448.327 tau-train= 0.85
epoch: 1000 , mse_ 397.974 , loss_anch 397.974 tau-train= 0.82

NN: 4
epoch: 200 , mse_ 788.8 , loss_anch 788.8 tau-train= 0.64
epoch: 400 , mse_ 469.524 , loss_anch 469.524 tau-train= 0.82
epoch: 600 , mse_ 361.614 , loss_anch 361.614 tau-train= 0.85
epoch: 800 , mse_ 301.177 , loss_anch 301.177 tau-train= 0.85
epoch: 1000 , mse_ 249.918 , loss_anch 249.918 tau-train= 0.85
tau-train-ens=0.8545454545454545
tau-archive=0.8545454545454545
eval=6 | not-eval=0 | tau= 0.24 | n_kendall=12 | std(means)/mean(stds)=  1.75 | std(means)=6.20e-05 | mean(stds)=3.55e-05
delta_f=1.1e-06
tau-population= 0.07 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) 2.3118355585438621e-07
(Pdb) subset-max-norm=8.521810982094406 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1260.76 , loss_anch 1260.76 tau-train= 0.42
epoch: 400 , mse_ 1172.188 , loss_anch 1172.188 tau-train= 0.38
epoch: 600 , mse_ 1129.896 , loss_anch 1129.896 tau-train= 0.42
epoch: 800 , mse_ 1102.587 , loss_anch 1102.587 tau-train= 0.38
epoch: 1000 , mse_ 1080.221 , loss_anch 1080.221 tau-train= 0.35

NN: 1
epoch: 200 , mse_ 743.874 , loss_anch 743.874 tau-train= 0.53
epoch: 400 , mse_ 588.419 , loss_anch 588.419 tau-train= 0.56
epoch: 600 , mse_ 520.032 , loss_anch 520.032 tau-train= 0.64
epoch: 800 , mse_ 475.293 , loss_anch 475.293 tau-train= 0.64
epoch: 1000 , mse_ 430.656 , loss_anch 430.656 tau-train= 0.75

NN: 2
epoch: 200 , mse_ 1163.847 , loss_anch 1163.847 tau-train= 0.38
epoch: 400 , mse_ 1083.218 , loss_anch 1083.218 tau-train= 0.38
epoch: 600 , mse_ 1034.832 , loss_anch 1034.832 tau-train= 0.38
epoch: 800 , mse_ 995.783 , loss_anch 995.783 tau-train= 0.38
epoch: 1000 , mse_ 961.258 , loss_anch 961.258 tau-train= 0.38

NN: 3
epoch: 200 , mse_ 854.737 , loss_anch 854.737 tau-train= 0.42
epoch: 400 , mse_ 716.625 , loss_anch 716.625 tau-train= 0.49
epoch: 600 , mse_ 628.626 , loss_anch 628.626 tau-train= 0.53
epoch: 800 , mse_ 585.282 , loss_anch 585.282 tau-train= 0.56
epoch: 1000 , mse_ 554.705 , loss_anch 554.705 tau-train= 0.60

NN: 4
epoch: 200 , mse_ 793.187 , loss_anch 793.187 tau-train= 0.53
epoch: 400 , mse_ 681.552 , loss_anch 681.552 tau-train= 0.56
epoch: 600 , mse_ 608.3 , loss_anch 608.3 tau-train= 0.64
epoch: 800 , mse_ 546.972 , loss_anch 546.972 tau-train= 0.64
epoch: 1000 , mse_ 482.523 , loss_anch 482.523 tau-train= 0.71
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1077)__call__()
-> print(f"tau-train-ens={_tau}")
(Pdb) array([[ 1.38504752],
       [ 0.08079289],
       [ 2.36604879],
       [-0.19659171],
       [ 2.04406573],
       [ 0.96607145],
       [ 0.63216335],
       [ 2.26264176],
       [-0.75272748],
       [ 1.39114091],
       [ 1.18170573],
       [ 1.01824415],
       [ 0.87280353],
       [-0.65838632],
       [ 1.99978977],
       [ 1.48141069],
       [-0.7441916 ],
       [-1.15734469],
       [-1.42655791],
       [-1.4462522 ],
       [ 0.27302797],
       [-0.03147432],
       [-0.36671825],
       [-0.8735954 ],
       [-1.91585637],
       [-2.16247674],
       [ 1.3357641 ],
       [ 0.16481016],
       [-0.1181259 ],
       [-0.53315579],
       [-1.0307815 ],
       [-4.13134333],
       [-1.57763745],
       [-3.43819615],
       [ 0.96426541],
       [ 0.96380155],
       [ 0.16285178],
       [ 0.0611955 ],
       [-0.93724388],
       [-2.88888933]])
(Pdb) tau-train-ens=0.6000000000000001
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1079)__call__()
-> def raf(features):
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()
-> return raf
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()-><function Raf...x7fd7786ad040>
-> return raf
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1544)__call__()
-> model = (
(Pdb) array([[-54.93995899],
       [-54.93998817],
       [-54.93989224],
       [-54.9399908 ],
       [-54.93992164],
       [-54.9399727 ],
       [-54.93998017],
       [-54.93990273],
       [-54.93999431],
       [-54.93995875],
       [-54.93996636],
       [-54.93997129],
       [-54.93997504],
       [-54.93999384],
       [-54.93992499],
       [-54.93995494],
       [-54.93999427],
       [-54.93999588],
       [-54.93999663],
       [-54.93999667],
       [-54.93998586],
       [-54.93998932],
       [-54.93999209],
       [-54.93999485],
       [-54.93999756],
       [-54.93999788],
       [-54.93996092],
       [-54.93998721],
       [-54.93999013],
       [-54.93999315],
       [-54.93999546],
       [-54.93999887],
       [-54.93999696],
       [-54.93999871],
       [-54.93997274],
       [-54.93997276],
       [-54.93998724],
       [-54.93998838],
       [-54.93999511],
       [-54.93999848]])
(Pdb) tau-archive=0.6000000000000001
eval=6 | not-eval=0 | tau= 0.60 | n_kendall=12 | std(means)/mean(stds)=  0.13 | std(means)=1.92e-06 | mean(stds)=1.44e-05
delta_f=1.1e-06
tau-population= 0.47 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=5.766479576479682 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1235.136 , loss_anch 1235.136 tau-train= 0.38
epoch: 400 , mse_ 1144.501 , loss_anch 1144.501 tau-train= 0.49
epoch: 600 , mse_ 1096.793 , loss_anch 1096.793 tau-train= 0.49
epoch: 800 , mse_ 1059.096 , loss_anch 1059.096 tau-train= 0.49
epoch: 1000 , mse_ 1023.091 , loss_anch 1023.091 tau-train= 0.49

NN: 1
epoch: 200 , mse_ 846.926 , loss_anch 846.926 tau-train= 0.60
epoch: 400 , mse_ 706.557 , loss_anch 706.557 tau-train= 0.67
epoch: 600 , mse_ 626.533 , loss_anch 626.533 tau-train= 0.78
epoch: 800 , mse_ 583.237 , loss_anch 583.237 tau-train= 0.89
epoch: 1000 , mse_ 551.085 , loss_anch 551.085 tau-train= 0.89

NN: 2
epoch: 200 , mse_ 1146.262 , loss_anch 1146.262 tau-train= 0.45
epoch: 400 , mse_ 1078.552 , loss_anch 1078.552 tau-train= 0.45
epoch: 600 , mse_ 1026.139 , loss_anch 1026.139 tau-train= 0.45
epoch: 800 , mse_ 983.647 , loss_anch 983.647 tau-train= 0.45
epoch: 1000 , mse_ 935.318 , loss_anch 935.318 tau-train= 0.45

NN: 3
epoch: 200 , mse_ 948.392 , loss_anch 948.392 tau-train= 0.49
epoch: 400 , mse_ 767.024 , loss_anch 767.024 tau-train= 0.56
epoch: 600 , mse_ 636.817 , loss_anch 636.817 tau-train= 0.64
epoch: 800 , mse_ 584.887 , loss_anch 584.887 tau-train= 0.78
epoch: 1000 , mse_ 558.489 , loss_anch 558.489 tau-train= 0.82

NN: 4
epoch: 200 , mse_ 843.367 , loss_anch 843.367 tau-train= 0.56
epoch: 400 , mse_ 682.36 , loss_anch 682.36 tau-train= 0.78
epoch: 600 , mse_ 589.19 , loss_anch 589.19 tau-train= 0.85
epoch: 800 , mse_ 528.533 , loss_anch 528.533 tau-train= 0.85
epoch: 1000 , mse_ 462.413 , loss_anch 462.413 tau-train= 0.89
tau-train-ens=0.7454545454545454
tau-archive=0.7454545454545454
eval=6 | not-eval=0 | tau= 0.47 | n_kendall=12 | std(means)/mean(stds)=  0.48 | std(means)=5.24e-06 | mean(stds)=1.10e-05
delta_f=1.3e-07
tau-population= 0.33 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=2.5049999493157986 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 430.689 , loss_anch 430.689 tau-train= 0.60
epoch: 400 , mse_ 362.597 , loss_anch 362.597 tau-train= 0.67
epoch: 600 , mse_ 324.51 , loss_anch 324.51 tau-train= 0.64
epoch: 800 , mse_ 305.963 , loss_anch 305.963 tau-train= 0.64
epoch: 1000 , mse_ 304.786 , loss_anch 304.786 tau-train= 0.64

NN: 1
epoch: 200 , mse_ 304.489 , loss_anch 304.489 tau-train= 0.67
epoch: 400 , mse_ 257.893 , loss_anch 257.893 tau-train= 0.60
epoch: 600 , mse_ 238.674 , loss_anch 238.674 tau-train= 0.78
epoch: 800 , mse_ 231.185 , loss_anch 231.185 tau-train= 0.78
epoch: 1000 , mse_ 226.875 , loss_anch 226.875 tau-train= 0.82

NN: 2
epoch: 200 , mse_ 422.087 , loss_anch 422.087 tau-train= 0.64
epoch: 400 , mse_ 365.113 , loss_anch 365.113 tau-train= 0.67
epoch: 600 , mse_ 339.777 , loss_anch 339.777 tau-train= 0.64
epoch: 800 , mse_ 323.677 , loss_anch 323.677 tau-train= 0.60
epoch: 1000 , mse_ 310.95 , loss_anch 310.95 tau-train= 0.67

NN: 3
epoch: 200 , mse_ 326.771 , loss_anch 326.771 tau-train= 0.64
epoch: 400 , mse_ 284.265 , loss_anch 284.265 tau-train= 0.64
epoch: 600 , mse_ 260.767 , loss_anch 260.767 tau-train= 0.56
epoch: 800 , mse_ 241.55 , loss_anch 241.55 tau-train= 0.60
epoch: 1000 , mse_ 228.611 , loss_anch 228.611 tau-train= 0.71

NN: 4
epoch: 200 , mse_ 305.397 , loss_anch 305.397 tau-train= 0.64
epoch: 400 , mse_ 253.415 , loss_anch 253.415 tau-train= 0.78
epoch: 600 , mse_ 235.821 , loss_anch 235.821 tau-train= 0.82
epoch: 800 , mse_ 227.183 , loss_anch 227.183 tau-train= 0.82
epoch: 1000 , mse_ 222.767 , loss_anch 222.767 tau-train= 0.82
tau-train-ens=0.7818181818181819
tau-archive=0.7818181818181819
eval=6 | not-eval=0 | tau= 0.20 | n_kendall=12 | std(means)/mean(stds)=  0.61 | std(means)=3.95e-06 | mean(stds)=6.42e-06
delta_f=1.4e-08
tau-population=-0.33 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) -5.195844181571374e-07
(Pdb) subset-max-norm=2.112443176237441 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 688.501 , loss_anch 688.501 tau-train= 0.31
epoch: 400 , mse_ 620.234 , loss_anch 620.234 tau-train= 0.31
epoch: 600 , mse_ 546.271 , loss_anch 546.271 tau-train= 0.27
epoch: 800 , mse_ 468.142 , loss_anch 468.142 tau-train= 0.49
epoch: 1000 , mse_ 409.641 , loss_anch 409.641 tau-train= 0.49

NN: 1
epoch: 200 , mse_ 307.616 , loss_anch 307.616 tau-train= 0.60
epoch: 400 , mse_ 251.85 , loss_anch 251.85 tau-train= 0.60
epoch: 600 , mse_ 226.355 , loss_anch 226.355 tau-train= 0.60
epoch: 800 , mse_ 208.365 , loss_anch 208.365 tau-train= 0.64
epoch: 1000 , mse_ 193.87 , loss_anch 193.87 tau-train= 0.71

NN: 2
epoch: 200 , mse_ 595.174 , loss_anch 595.174 tau-train= 0.35
epoch: 400 , mse_ 452.272 , loss_anch 452.272 tau-train= 0.60
epoch: 600 , mse_ 363.967 , loss_anch 363.967 tau-train= 0.56
epoch: 800 , mse_ 324.659 , loss_anch 324.659 tau-train= 0.56
epoch: 1000 , mse_ 305.928 , loss_anch 305.928 tau-train= 0.56

NN: 3
epoch: 200 , mse_ 380.534 , loss_anch 380.534 tau-train= 0.67
epoch: 400 , mse_ 266.099 , loss_anch 266.099 tau-train= 0.64
epoch: 600 , mse_ 233.046 , loss_anch 233.046 tau-train= 0.64
epoch: 800 , mse_ 211.15 , loss_anch 211.15 tau-train= 0.64
epoch: 1000 , mse_ 195.66 , loss_anch 195.66 tau-train= 0.71

NN: 4
epoch: 200 , mse_ 320.033 , loss_anch 320.033 tau-train= 0.60
epoch: 400 , mse_ 263.097 , loss_anch 263.097 tau-train= 0.64
epoch: 600 , mse_ 233.069 , loss_anch 233.069 tau-train= 0.60
epoch: 800 , mse_ 202.519 , loss_anch 202.519 tau-train= 0.64
epoch: 1000 , mse_ 173.378 , loss_anch 173.378 tau-train= 0.71
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1077)__call__()
-> print(f"tau-train-ens={_tau}")
(Pdb) array([[ 1.06881933],
       [ 0.81967837],
       [ 1.58146902],
       [ 0.34560541],
       [ 0.42317936],
       [ 0.35257026],
       [ 0.02910102],
       [-0.16472496],
       [-0.17831853],
       [ 0.67064833],
       [ 0.24818884],
       [-0.47655421],
       [-0.6120437 ],
       [ 1.14558914],
       [ 0.88943042],
       [ 0.52808797],
       [ 0.12506954],
       [-1.20325558],
       [-0.26684547],
       [-1.08031389],
       [ 0.19783111],
       [-0.92384486],
       [ 0.57246095],
       [ 0.44334675],
       [ 0.35900106],
       [ 0.31479056],
       [-0.52456421],
       [-0.6045417 ],
       [ 0.48102711],
       [ 0.0269048 ],
       [-0.10298987],
       [-0.57201416],
       [-1.41838833],
       [-2.86824364],
       [ 0.45173789],
       [-0.04572621],
       [-0.5588917 ],
       [-0.58541975],
       [-0.78027953],
       [-3.56139082]])
(Pdb) tau-train-ens=0.6727272727272727
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1079)__call__()
-> def raf(features):
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()
-> return raf
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()-><function Raf...x7fd7a57e9b80>
-> return raf
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1544)__call__()
-> model = (
(Pdb) array([[-54.93998817],
       [-54.9399908 ],
       [-54.93998017],
       [-54.93999431],
       [-54.93999384],
       [-54.93999427],
       [-54.93999588],
       [-54.93999663],
       [-54.93999667],
       [-54.93999209],
       [-54.93999485],
       [-54.93999756],
       [-54.93999788],
       [-54.93998721],
       [-54.93999013],
       [-54.93999315],
       [-54.93999546],
       [-54.93999887],
       [-54.93999696],
       [-54.93999871],
       [-54.93999511],
       [-54.93999848],
       [-54.93999284],
       [-54.93999372],
       [-54.93999423],
       [-54.93999449],
       [-54.93999768],
       [-54.93999786],
       [-54.93999347],
       [-54.93999589],
       [-54.9399964 ],
       [-54.93999779],
       [-54.93999911],
       [-54.93999987],
       [-54.93999366],
       [-54.93999619],
       [-54.93999776],
       [-54.93999782],
       [-54.93999822],
       [-54.93999999]])
(Pdb) tau-archive=0.6727272727272727
eval=6 | not-eval=0 | tau=-0.02 | n_kendall=12 | std(means)/mean(stds)=  0.53 | std(means)=2.63e-06 | mean(stds)=5.01e-06
delta_f=1.4e-08
tau-population=-0.20 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) -1.794885214678743e-06
(Pdb) subset-max-norm=1.9711033017566395 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 779.727 , loss_anch 779.727 tau-train= 0.24
epoch: 400 , mse_ 726.368 , loss_anch 726.368 tau-train= 0.24
epoch: 600 , mse_ 696.209 , loss_anch 696.209 tau-train= 0.16
epoch: 800 , mse_ 671.827 , loss_anch 671.827 tau-train= 0.20
epoch: 1000 , mse_ 654.198 , loss_anch 654.198 tau-train= 0.16

NN: 1
epoch: 200 , mse_ 509.717 , loss_anch 509.717 tau-train= 0.24
epoch: 400 , mse_ 283.786 , loss_anch 283.786 tau-train= 0.64
epoch: 600 , mse_ 198.844 , loss_anch 198.844 tau-train= 0.67
epoch: 800 , mse_ 154.656 , loss_anch 154.656 tau-train= 0.71
epoch: 1000 , mse_ 128.463 , loss_anch 128.463 tau-train= 0.75

NN: 2
epoch: 200 , mse_ 658.785 , loss_anch 658.785 tau-train= 0.16
epoch: 400 , mse_ 582.755 , loss_anch 582.755 tau-train= 0.20
epoch: 600 , mse_ 533.505 , loss_anch 533.505 tau-train= 0.20
epoch: 800 , mse_ 479.371 , loss_anch 479.371 tau-train= 0.45
epoch: 1000 , mse_ 440.371 , loss_anch 440.371 tau-train= 0.45

NN: 3
epoch: 200 , mse_ 397.271 , loss_anch 397.271 tau-train= 0.60
epoch: 400 , mse_ 259.656 , loss_anch 259.656 tau-train= 0.71
epoch: 600 , mse_ 201.294 , loss_anch 201.294 tau-train= 0.71
epoch: 800 , mse_ 160.912 , loss_anch 160.912 tau-train= 0.71
epoch: 1000 , mse_ 137.215 , loss_anch 137.215 tau-train= 0.71

NN: 4
epoch: 200 , mse_ 376.524 , loss_anch 376.524 tau-train= 0.56
epoch: 400 , mse_ 299.034 , loss_anch 299.034 tau-train= 0.60
epoch: 600 , mse_ 232.909 , loss_anch 232.909 tau-train= 0.67
epoch: 800 , mse_ 194.911 , loss_anch 194.911 tau-train= 0.71
epoch: 1000 , mse_ 171.621 , loss_anch 171.621 tau-train= 0.67
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1077)__call__()
-> print(f"tau-train-ens={_tau}")
(Pdb) array([[ 1.47685369],
       [ 1.22771272],
       [ 1.98950337],
       [ 0.75363976],
       [ 0.76060462],
       [ 0.43713538],
       [ 0.22971583],
       [ 0.6562232 ],
       [-0.06851986],
       [-0.20400934],
       [ 1.5536235 ],
       [ 1.29746477],
       [ 0.93612233],
       [ 0.5331039 ],
       [-0.79522123],
       [ 0.14118889],
       [-0.67227953],
       [ 0.60586547],
       [-0.5158105 ],
       [ 0.85138111],
       [ 0.76703542],
       [-0.11652985],
       [-0.19650735],
       [ 0.88906147],
       [ 0.43493916],
       [ 0.30504449],
       [-0.1639798 ],
       [-1.01035397],
       [-2.46020928],
       [ 0.36230815],
       [-0.15085734],
       [-0.17738539],
       [-0.37224517],
       [-3.15335646],
       [-0.27692798],
       [-0.29681327],
       [-0.69784551],
       [-0.84443485],
       [-1.70614392],
       [-1.7763726 ]])
(Pdb) tau-train-ens=0.6363636363636364
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1079)__call__()
-> def raf(features):
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()
-> return raf
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()-><function Raf...x7fd7a4771c10>
-> return raf
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1544)__call__()
-> model = (
(Pdb) array([[-54.93998817],
       [-54.9399908 ],
       [-54.93998017],
       [-54.93999431],
       [-54.93999427],
       [-54.93999588],
       [-54.93999667],
       [-54.93999485],
       [-54.93999756],
       [-54.93999788],
       [-54.93998721],
       [-54.93999013],
       [-54.93999315],
       [-54.93999546],
       [-54.93999887],
       [-54.93999696],
       [-54.93999871],
       [-54.93999511],
       [-54.93999848],
       [-54.93999372],
       [-54.93999423],
       [-54.93999768],
       [-54.93999786],
       [-54.93999347],
       [-54.93999589],
       [-54.9399964 ],
       [-54.93999779],
       [-54.93999911],
       [-54.93999987],
       [-54.93999619],
       [-54.93999776],
       [-54.93999782],
       [-54.93999822],
       [-54.93999999],
       [-54.93999804],
       [-54.93999808],
       [-54.93999875],
       [-54.93999893],
       [-54.93999961],
       [-54.93999964]])
(Pdb) tau-archive=0.6363636363636364
eval=6 | not-eval=0 | tau= 0.47 | n_kendall=12 | std(means)/mean(stds)=  0.33 | std(means)=1.54e-06 | mean(stds)=4.72e-06
delta_f=1.4e-08
tau-population= 0.47 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=3.370897074159002 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 537.821 , loss_anch 537.821 tau-train= 0.56
epoch: 400 , mse_ 443.693 , loss_anch 443.693 tau-train= 0.67
epoch: 600 , mse_ 369.361 , loss_anch 369.361 tau-train= 0.64
epoch: 800 , mse_ 311.052 , loss_anch 311.052 tau-train= 0.67
epoch: 1000 , mse_ 262.736 , loss_anch 262.736 tau-train= 0.64

NN: 1
epoch: 200 , mse_ 180.223 , loss_anch 180.223 tau-train= 0.67
epoch: 400 , mse_ 106.608 , loss_anch 106.608 tau-train= 0.82
epoch: 600 , mse_ 76.801 , loss_anch 76.801 tau-train= 0.85
epoch: 800 , mse_ 69.488 , loss_anch 69.488 tau-train= 0.85
epoch: 1000 , mse_ 61.944 , loss_anch 61.944 tau-train= 0.85

NN: 2
epoch: 200 , mse_ 545.012 , loss_anch 545.012 tau-train= 0.60
epoch: 400 , mse_ 442.605 , loss_anch 442.605 tau-train= 0.56
epoch: 600 , mse_ 387.733 , loss_anch 387.733 tau-train= 0.53
epoch: 800 , mse_ 342.859 , loss_anch 342.859 tau-train= 0.60
epoch: 1000 , mse_ 509.663 , loss_anch 509.663 tau-train= 0.49

NN: 3
epoch: 200 , mse_ 269.461 , loss_anch 269.461 tau-train= 0.53
epoch: 400 , mse_ 153.904 , loss_anch 153.904 tau-train= 0.67
epoch: 600 , mse_ 104.837 , loss_anch 104.837 tau-train= 0.71
epoch: 800 , mse_ 83.041 , loss_anch 83.041 tau-train= 0.78
epoch: 1000 , mse_ 68.266 , loss_anch 68.266 tau-train= 0.85

NN: 4
epoch: 200 , mse_ 174.563 , loss_anch 174.563 tau-train= 0.75
epoch: 400 , mse_ 90.339 , loss_anch 90.339 tau-train= 0.82
epoch: 600 , mse_ 71.491 , loss_anch 71.491 tau-train= 0.85
epoch: 800 , mse_ 66.408 , loss_anch 66.408 tau-train= 0.85
epoch: 1000 , mse_ 62.773 , loss_anch 62.773 tau-train= 0.85
tau-train-ens=0.7818181818181819
tau-archive=0.5272727272727272
eval=6 | not-eval=0 | tau= 0.16 | n_kendall=12 | std(means)/mean(stds)=  0.61 | std(means)=1.74e-06 | mean(stds)=2.84e-06
delta_f=1.4e-08
tau-population=-0.07 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) -4.0894407504765695e-07
(Pdb) subset-max-norm=3.521452227918028 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 440.451 , loss_anch 440.451 tau-train= 0.20
epoch: 400 , mse_ 398.149 , loss_anch 398.149 tau-train= 0.24
epoch: 600 , mse_ 367.29 , loss_anch 367.29 tau-train= 0.24
epoch: 800 , mse_ 346.104 , loss_anch 346.104 tau-train= 0.27
epoch: 1000 , mse_ 331.252 , loss_anch 331.252 tau-train= 0.27

NN: 1
epoch: 200 , mse_ 222.65 , loss_anch 222.65 tau-train= 0.42
epoch: 400 , mse_ 107.569 , loss_anch 107.569 tau-train= 0.75
epoch: 600 , mse_ 88.109 , loss_anch 88.109 tau-train= 0.75
epoch: 800 , mse_ 78.407 , loss_anch 78.407 tau-train= 0.78
epoch: 1000 , mse_ 68.992 , loss_anch 68.992 tau-train= 0.82

NN: 2
epoch: 200 , mse_ 358.932 , loss_anch 358.932 tau-train= 0.31
epoch: 400 , mse_ 343.588 , loss_anch 343.588 tau-train= 0.35
epoch: 600 , mse_ 330.356 , loss_anch 330.356 tau-train= 0.38
epoch: 800 , mse_ 319.153 , loss_anch 319.153 tau-train= 0.35
epoch: 1000 , mse_ 308.654 , loss_anch 308.654 tau-train= 0.31

NN: 3
epoch: 200 , mse_ 172.562 , loss_anch 172.562 tau-train= 0.67
epoch: 400 , mse_ 108.976 , loss_anch 108.976 tau-train= 0.71
epoch: 600 , mse_ 92.235 , loss_anch 92.235 tau-train= 0.75
epoch: 800 , mse_ 80.816 , loss_anch 80.816 tau-train= 0.78
epoch: 1000 , mse_ 71.722 , loss_anch 71.722 tau-train= 0.82

NN: 4
epoch: 200 , mse_ 132.087 , loss_anch 132.087 tau-train= 0.71
epoch: 400 , mse_ 96.183 , loss_anch 96.183 tau-train= 0.75
epoch: 600 , mse_ 80.379 , loss_anch 80.379 tau-train= 0.78
epoch: 800 , mse_ 69.603 , loss_anch 69.603 tau-train= 0.82
epoch: 1000 , mse_ 61.458 , loss_anch 61.458 tau-train= 0.85
tau-train-ens=0.8545454545454545
tau-archive=0.7090909090909091
eval=6 | not-eval=0 | tau= 0.47 | n_kendall=12 | std(means)/mean(stds)=  0.20 | std(means)=8.25e-07 | mean(stds)=4.16e-06
delta_f=1.1e-08
tau-population= 0.47 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=3.1386694823831554 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1338.222 , loss_anch 1338.222 tau-train= 0.67
epoch: 400 , mse_ 1052.389 , loss_anch 1052.389 tau-train= 0.56
epoch: 600 , mse_ 863.077 , loss_anch 863.077 tau-train= 0.42
epoch: 800 , mse_ 739.445 , loss_anch 739.445 tau-train= 0.49
epoch: 1000 , mse_ 709.265 , loss_anch 709.265 tau-train= 0.49

NN: 1
epoch: 200 , mse_ 523.826 , loss_anch 523.826 tau-train= 0.56
epoch: 400 , mse_ 281.147 , loss_anch 281.147 tau-train= 0.60
epoch: 600 , mse_ 158.733 , loss_anch 158.733 tau-train= 0.71
epoch: 800 , mse_ 107.752 , loss_anch 107.752 tau-train= 0.75
epoch: 1000 , mse_ 79.857 , loss_anch 79.857 tau-train= 0.78

NN: 2
epoch: 200 , mse_ 1094.65 , loss_anch 1094.65 tau-train= 0.56
epoch: 400 , mse_ 861.794 , loss_anch 861.794 tau-train= 0.53
epoch: 600 , mse_ 707.762 , loss_anch 707.762 tau-train= 0.45
epoch: 800 , mse_ 654.512 , loss_anch 654.512 tau-train= 0.49
epoch: 1000 , mse_ 611.943 , loss_anch 611.943 tau-train= 0.45

NN: 3
epoch: 200 , mse_ 527.627 , loss_anch 527.627 tau-train= 0.60
epoch: 400 , mse_ 257.46 , loss_anch 257.46 tau-train= 0.67
epoch: 600 , mse_ 170.489 , loss_anch 170.489 tau-train= 0.78
epoch: 800 , mse_ 106.404 , loss_anch 106.404 tau-train= 0.75
epoch: 1000 , mse_ 82.424 , loss_anch 82.424 tau-train= 0.78

NN: 4
epoch: 200 , mse_ 602.936 , loss_anch 602.936 tau-train= 0.64
epoch: 400 , mse_ 301.24 , loss_anch 301.24 tau-train= 0.67
epoch: 600 , mse_ 141.522 , loss_anch 141.522 tau-train= 0.67
epoch: 800 , mse_ 99.699 , loss_anch 99.699 tau-train= 0.78
epoch: 1000 , mse_ 72.907 , loss_anch 72.907 tau-train= 0.78
tau-train-ens=0.7818181818181819
tau-archive=0.7818181818181819
eval=6 | not-eval=0 | tau= 0.29 | n_kendall=12 | std(means)/mean(stds)=  0.20 | std(means)=3.36e-07 | mean(stds)=1.65e-06
delta_f=1.1e-08
tau-population=-0.07 | tau-pop-offset= 1.00 | final-target-hit=False
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1855)__call__()
-> _preds = model(points)
(Pdb) -2.285356330844479e-07
(Pdb) subset-max-norm=3.036827387026877 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1208.928 , loss_anch 1208.928 tau-train= 0.42
epoch: 400 , mse_ 1109.678 , loss_anch 1109.678 tau-train= 0.27
epoch: 600 , mse_ 981.212 , loss_anch 981.212 tau-train= 0.20
epoch: 800 , mse_ 868.345 , loss_anch 868.345 tau-train= 0.31
epoch: 1000 , mse_ 847.129 , loss_anch 847.129 tau-train= 0.20

NN: 1
epoch: 200 , mse_ 702.881 , loss_anch 702.881 tau-train= 0.45
epoch: 400 , mse_ 408.687 , loss_anch 408.687 tau-train= 0.35
epoch: 600 , mse_ 300.357 , loss_anch 300.357 tau-train= 0.38
epoch: 800 , mse_ 257.262 , loss_anch 257.262 tau-train= 0.42
epoch: 1000 , mse_ 221.073 , loss_anch 221.073 tau-train= 0.53

NN: 2
epoch: 200 , mse_ 1269.964 , loss_anch 1269.964 tau-train= 0.35
epoch: 400 , mse_ 1187.387 , loss_anch 1187.387 tau-train= 0.31
epoch: 600 , mse_ 1122.309 , loss_anch 1122.309 tau-train= 0.42
epoch: 800 , mse_ 1057.922 , loss_anch 1057.922 tau-train= 0.35
epoch: 1000 , mse_ 988.234 , loss_anch 988.234 tau-train= 0.38

NN: 3
epoch: 200 , mse_ 1071.708 , loss_anch 1071.708 tau-train= 0.35
epoch: 400 , mse_ 739.337 , loss_anch 739.337 tau-train= 0.38
epoch: 600 , mse_ 453.932 , loss_anch 453.932 tau-train= 0.42
epoch: 800 , mse_ 292.458 , loss_anch 292.458 tau-train= 0.53
epoch: 1000 , mse_ 232.557 , loss_anch 232.557 tau-train= 0.49

NN: 4
epoch: 200 , mse_ 739.887 , loss_anch 739.887 tau-train= 0.45
epoch: 400 , mse_ 413.491 , loss_anch 413.491 tau-train= 0.35
epoch: 600 , mse_ 267.362 , loss_anch 267.362 tau-train= 0.35
epoch: 800 , mse_ 214.278 , loss_anch 214.278 tau-train= 0.45
epoch: 1000 , mse_ 175.046 , loss_anch 175.046 tau-train= 0.49
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1077)__call__()
-> print(f"tau-train-ens={_tau}")
(Pdb) array([[ 1.39446963],
       [ 1.07047491],
       [ 0.92833402],
       [ 0.29373518],
       [ 1.28878993],
       [ 0.42810401],
       [ 0.59707465],
       [ 0.97042804],
       [ 0.05446817],
       [-1.92594804],
       [ 0.98420859],
       [ 0.95634072],
       [ 0.75040184],
       [-5.07728148],
       [ 0.8303952 ],
       [ 0.40028637],
       [ 0.23949754],
       [-0.77698946],
       [-0.86853033],
       [ 0.46856879],
       [-0.30294741],
       [-0.89644637],
       [ 1.18033469],
       [ 0.10064919],
       [-0.05102178],
       [-0.32914318],
       [-0.81320214],
       [-1.21089142],
       [ 0.79479116],
       [-0.26618206],
       [-0.27265639],
       [-0.2942514 ],
       [-0.48414084],
       [-5.77042866],
       [ 0.09457776],
       [-0.17143198],
       [-0.24498211],
       [-0.28912288],
       [-1.38747943],
       [-1.59031271]])
(Pdb) tau-train-ens=0.4909090909090909
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1079)__call__()
-> def raf(features):
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()
-> return raf
(Pdb) --Return--
> /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1086)__call__()-><function Raf...x7fd7786ad160>
-> return raf
(Pdb) > /home/jarda/Desktop/thesis/nncmaes/code/nncmaes.py(1544)__call__()
-> model = (
(Pdb) array([[-54.93999663],
       [-54.93999756],
       [-54.93999788],
       [-54.93999887],
       [-54.93999696],
       [-54.93999871],
       [-54.93999848],
       [-54.93999779],
       [-54.93999911],
       [-54.93999987],
       [-54.93999776],
       [-54.93999782],
       [-54.93999822],
       [-54.93999999],
       [-54.93999808],
       [-54.93999875],
       [-54.93999893],
       [-54.93999961],
       [-54.93999964],
       [-54.93999866],
       [-54.93999937],
       [-54.93999965],
       [-54.93999727],
       [-54.93999907],
       [-54.9399992 ],
       [-54.93999939],
       [-54.93999962],
       [-54.93999974],
       [-54.93999814],
       [-54.93999935],
       [-54.93999936],
       [-54.93999937],
       [-54.93999948],
       [-54.93999999],
       [-54.93999907],
       [-54.93999929],
       [-54.93999934],
       [-54.93999937],
       [-54.93999978],
       [-54.93999982]])
(Pdb) tau-archive=0.4909090909090909
eval=6 | not-eval=0 | tau= 0.60 | n_kendall=12 | std(means)/mean(stds)=  0.42 | std(means)=1.00e-06 | mean(stds)=2.38e-06
delta_f=1.1e-08
tau-population= 0.60 | tau-pop-offset= 1.00 | final-target-hit=False
subset-max-norm=4.074395384319804 | norm-max=12.13941703508117
subset-idx-size=40

NN: 0
epoch: 200 , mse_ 1240.693 , loss_anch 1240.693 tau-train= 0.78
epoch: 400 , mse_ 1122.248 , loss_anch 1122.248 tau-train= 0.71
epoch: 600 , mse_ 1043.566 , loss_anch 1043.566 tau-train= 0.71
epoch: 800 , mse_ 979.503 , loss_anch 979.503 tau-train= 0.78
epoch: 1000 , mse_ 932.259 , loss_anch 932.259 tau-train= 0.78

NN: 1
epoch: 200 , mse_ 783.927 , loss_anch 783.927 tau-train= 0.67
epoch: 400 , mse_ 474.189 , loss_anch 474.189 tau-train= 0.82
epoch: 600 , mse_ 330.034 , loss_anch 330.034 tau-train= 0.82
epoch: 800 , mse_ 244.496 , loss_anch 244.496 tau-train= 0.85
epoch: 1000 , mse_ 188.225 , loss_anch 188.225 tau-train= 0.93

NN: 2
epoch: 200 , mse_ 1254.625 , loss_anch 1254.625 tau-train= 0.82
epoch: 400 , mse_ 1159.157 , loss_anch 1159.157 tau-train= 0.75
epoch: 600 , mse_ 1084.87 , loss_anch 1084.87 tau-train= 0.75
epoch: 800 , mse_ 1022.874 , loss_anch 1022.874 tau-train= 0.82
epoch: 1000 , mse_ 970.922 , loss_anch 970.922 tau-train= 0.82

NN: 3
epoch: 200 , mse_ 831.858 , loss_anch 831.858 tau-train= 0.67
epoch: 400 , mse_ 624.786 , loss_anch 624.786 tau-train= 0.67
epoch: 600 , mse_ 418.32 , loss_anch 418.32 tau-train= 0.71
epoch: 800 , mse_ 298.029 , loss_anch 298.029 tau-train= 0.71
epoch: 1000 , mse_ 231.337 , loss_anch 231.337 tau-train= 0.82

NN: 4
epoch: 200 , mse_ 883.572 , loss_anch 883.572 tau-train= 0.71
epoch: 400 , mse_ 643.1 , loss_anch 643.1 tau-train= 0.67
epoch: 600 , mse_ 446.299 , loss_anch 446.299 tau-train= 0.75
epoch: 800 , mse_ 311.722 , loss_anch 311.722 tau-train= 0.78
epoch: 1000 , mse_ 228.855 , loss_anch 228.855 tau-train= 0.85
tau-train-ens=0.8909090909090909
tau-archive=0.8909090909090909
eval=1 | not-eval=5 | tau= 0.91 | n_kendall=12 | std(means)/mean(stds)=  0.04 | std(means)=3.47e-07 | mean(stds)=7.97e-06
delta_f=7.1e-09
tau-population= 0.73 | tau-pop-offset= 0.60 | final-target-hit=True
 2D 10-fun   1-inst  500-budget  True-solved 315-evals  516-cma-evals 3470s 0-restarts  6-init-pop (Surrogate(model=Raf(data_noise=0.0), subset=ClosestToEachTestPoint(Mahalanobis, n_max_coef=20), x_tf=ShiftAndScaleByEs, y_tf=MinAdjustedLog), EvaluateUntilKendallThreshold(mean_criterion, tau_threshold=0.85, offset=True), n_min_fn=get_dim) 7.1e-09-delta-f          1-seed
